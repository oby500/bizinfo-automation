#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë¡œì»¬ PDF íŒŒì¼ ìš©ëŸ‰ ë¶„ì„
2025-09-10 09:30 ì‹¤í–‰
- ë‹¤ìš´ë¡œë“œí•œ ì›ë³¸ íŒŒì¼
- HWP ë³€í™˜ íŒŒì¼
- í‰ê·  ë° ì´ìƒì¹˜ ë¶„ì„
"""

import sys
sys.stdout.reconfigure(encoding='utf-8')
import os
from pathlib import Path
import statistics
import json
from datetime import datetime

def analyze_pdf_sizes():
    """PDF íŒŒì¼ ìš©ëŸ‰ ìƒì„¸ ë¶„ì„"""
    
    print("="*70)
    print("ğŸ“Š PDF íŒŒì¼ ìš©ëŸ‰ ë¶„ì„")
    print(f"ğŸ• ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*70)
    
    # ë¶„ì„í•  í´ë”ë“¤
    folders = {
        'downloads': Path(r'E:\gov-support-automation\downloads'),
        'converted': Path(r'E:\gov-support-automation\converted'),
        'kstartup': Path(r'E:\gov-support-automation\downloads\kstartup'),
        'bizinfo': Path(r'E:\gov-support-automation\downloads\bizinfo')
    }
    
    all_files = []
    stats_by_folder = {}
    
    # ê° í´ë”ë³„ íŒŒì¼ ìˆ˜ì§‘
    for folder_name, folder_path in folders.items():
        if not folder_path.exists():
            print(f"âš ï¸ {folder_name} í´ë” ì—†ìŒ: {folder_path}")
            continue
            
        folder_files = []
        
        # PDF íŒŒì¼ ì°¾ê¸° (ì¬ê·€ì )
        for pdf_file in folder_path.rglob('*.pdf'):
            size = pdf_file.stat().st_size
            folder_files.append({
                'path': str(pdf_file),
                'name': pdf_file.name,
                'size': size,
                'size_mb': round(size / (1024*1024), 2),
                'folder': folder_name
            })
        
        # HWP ë³€í™˜ íŒŒì¼ë„ ì²´í¬
        for hwp_file in folder_path.rglob('*.hwp'):
            size = hwp_file.stat().st_size
            folder_files.append({
                'path': str(hwp_file),
                'name': hwp_file.name,
                'size': size,
                'size_mb': round(size / (1024*1024), 2),
                'folder': folder_name,
                'type': 'hwp'
            })
            
        # HWPX íŒŒì¼
        for hwpx_file in folder_path.rglob('*.hwpx'):
            size = hwpx_file.stat().st_size
            folder_files.append({
                'path': str(hwpx_file),
                'name': hwpx_file.name,
                'size': size,
                'size_mb': round(size / (1024*1024), 2),
                'folder': folder_name,
                'type': 'hwpx'
            })
        
        all_files.extend(folder_files)
        stats_by_folder[folder_name] = folder_files
        
        print(f"\nğŸ“ {folder_name}: {len(folder_files)}ê°œ íŒŒì¼")
    
    if not all_files:
        print("\nâŒ ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì „ì²´ í†µê³„
    sizes_mb = [f['size_mb'] for f in all_files]
    
    print("\n" + "="*70)
    print("ğŸ“Š ì „ì²´ í†µê³„")
    print("="*70)
    print(f"ì´ íŒŒì¼ ìˆ˜: {len(all_files)}ê°œ")
    print(f"ì´ ìš©ëŸ‰: {sum(sizes_mb):.2f} MB ({sum(sizes_mb)/1024:.2f} GB)")
    print(f"í‰ê·  ìš©ëŸ‰: {statistics.mean(sizes_mb):.2f} MB")
    print(f"ì¤‘ì•™ê°’: {statistics.median(sizes_mb):.2f} MB")
    
    if len(sizes_mb) > 1:
        print(f"í‘œì¤€í¸ì°¨: {statistics.stdev(sizes_mb):.2f} MB")
    
    # ì´ìƒì¹˜ íƒì§€ (IQR ë°©ë²•)
    sorted_sizes = sorted(sizes_mb)
    q1 = sorted_sizes[len(sorted_sizes)//4]
    q3 = sorted_sizes[3*len(sorted_sizes)//4]
    iqr = q3 - q1
    
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    
    print(f"\nğŸ“ˆ ì‚¬ë¶„ìœ„ìˆ˜:")
    print(f"Q1 (25%): {q1:.2f} MB")
    print(f"Q3 (75%): {q3:.2f} MB")
    print(f"IQR: {iqr:.2f} MB")
    print(f"ì •ìƒ ë²”ìœ„: {max(0, lower_bound):.2f} ~ {upper_bound:.2f} MB")
    
    # ì´ìƒì¹˜ ì°¾ê¸°
    outliers = [f for f in all_files if f['size_mb'] < lower_bound or f['size_mb'] > upper_bound]
    normal_files = [f for f in all_files if lower_bound <= f['size_mb'] <= upper_bound]
    
    print(f"\nğŸ¯ ì´ìƒì¹˜ ë¶„ì„:")
    print(f"ì´ìƒì¹˜ íŒŒì¼: {len(outliers)}ê°œ")
    print(f"ì •ìƒ íŒŒì¼: {len(normal_files)}ê°œ")
    
    if outliers:
        print("\nğŸ“Œ íŠ¹ì´í•œ íŒŒì¼ë“¤ (ì´ìƒì¹˜):")
        # ê°€ì¥ í° íŒŒì¼ 5ê°œ
        largest = sorted(outliers, key=lambda x: x['size_mb'], reverse=True)[:5]
        for f in largest:
            print(f"  â€¢ {f['name'][:50]}: {f['size_mb']} MB")
        
        # ê°€ì¥ ì‘ì€ íŒŒì¼ 5ê°œ
        if len(outliers) > 5:
            smallest = sorted(outliers, key=lambda x: x['size_mb'])[:5]
            print("\n  ê°€ì¥ ì‘ì€ íŒŒì¼ë“¤:")
            for f in smallest:
                print(f"  â€¢ {f['name'][:50]}: {f['size_mb']} MB")
    
    # ì •ìƒ íŒŒì¼ë§Œì˜ í‰ê· 
    if normal_files:
        normal_sizes = [f['size_mb'] for f in normal_files]
        print(f"\nâœ… ì´ìƒì¹˜ ì œì™¸ í†µê³„:")
        print(f"ì •ìƒ íŒŒì¼ í‰ê· : {statistics.mean(normal_sizes):.2f} MB")
        print(f"ì •ìƒ íŒŒì¼ ì¤‘ì•™ê°’: {statistics.median(normal_sizes):.2f} MB")
        print(f"ì •ìƒ íŒŒì¼ ì´ ìš©ëŸ‰: {sum(normal_sizes):.2f} MB")
    
    # íŒŒì¼ íƒ€ì…ë³„ í†µê³„
    pdf_files = [f for f in all_files if not f.get('type')]
    hwp_files = [f for f in all_files if f.get('type') == 'hwp']
    hwpx_files = [f for f in all_files if f.get('type') == 'hwpx']
    
    print(f"\nğŸ“„ íŒŒì¼ íƒ€ì…ë³„:")
    if pdf_files:
        pdf_sizes = [f['size_mb'] for f in pdf_files]
        print(f"PDF: {len(pdf_files)}ê°œ, í‰ê·  {statistics.mean(pdf_sizes):.2f} MB")
    if hwp_files:
        hwp_sizes = [f['size_mb'] for f in hwp_files]
        print(f"HWP: {len(hwp_files)}ê°œ, í‰ê·  {statistics.mean(hwp_sizes):.2f} MB")
    if hwpx_files:
        hwpx_sizes = [f['size_mb'] for f in hwpx_files]
        print(f"HWPX: {len(hwpx_files)}ê°œ, í‰ê·  {statistics.mean(hwpx_sizes):.2f} MB")
    
    # í¬ê¸° ë¶„í¬
    print(f"\nğŸ“Š í¬ê¸° ë¶„í¬:")
    ranges = [
        (0, 0.5, "0~500KB"),
        (0.5, 1, "500KB~1MB"),
        (1, 2, "1~2MB"),
        (2, 5, "2~5MB"),
        (5, 10, "5~10MB"),
        (10, 20, "10~20MB"),
        (20, float('inf'), "20MB ì´ìƒ")
    ]
    
    for min_size, max_size, label in ranges:
        count = len([f for f in all_files if min_size <= f['size_mb'] < max_size])
        if count > 0:
            percentage = (count / len(all_files)) * 100
            print(f"{label:15} : {count:4}ê°œ ({percentage:5.1f}%) {'â–ˆ' * int(percentage/2)}")
    
    # ê²°ê³¼ ì €ì¥
    result = {
        'timestamp': datetime.now().isoformat(),
        'total_files': len(all_files),
        'total_size_mb': sum(sizes_mb),
        'average_size_mb': statistics.mean(sizes_mb),
        'median_size_mb': statistics.median(sizes_mb),
        'normal_average_mb': statistics.mean(normal_sizes) if normal_files else 0,
        'outliers_count': len(outliers),
        'normal_range': {
            'min': max(0, lower_bound),
            'max': upper_bound
        }
    }
    
    with open('file_size_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print("\n" + "="*70)
    print("ğŸ’¾ ë¶„ì„ ê²°ê³¼ê°€ file_size_analysis.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("="*70)

if __name__ == "__main__":
    analyze_pdf_sizes()