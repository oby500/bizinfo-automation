name: Bizinfo Auto Collection

on:
  schedule:
    - cron: '0 1 * * *'  # 매일 오전 10시 (KST)
  workflow_dispatch:

jobs:
  collect-bizinfo:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
    
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 supabase pandas openpyxl
        pip install selenium webdriver-manager
    
    - name: Step 1 - Excel Collection
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
      run: |
        echo "======================================"
        echo " STEP 1: 기업마당 엑셀 데이터 수집"
        echo "======================================"
        python scripts/bizinfo_excel_collector.py
      continue-on-error: true
    
    - name: Step 2 - Detail Page Crawling with Selenium
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
      run: |
        echo "======================================"
        echo " STEP 2: Selenium 상세페이지 크롤링"
        echo "======================================"
        python scripts/bizinfo_detail_crawler_selenium.py
      continue-on-error: true
    
    - name: Step 3 - Fast Attachment Crawling
      env:
        SUPABASE_URL: