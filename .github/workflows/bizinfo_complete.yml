name: ğŸ¢ Bizinfo Complete Workflow

on:
  workflow_dispatch:
    inputs:
      mode:
        description: 'ìˆ˜ì§‘ ëª¨ë“œ'
        required: true
        default: 'daily'
        type: choice
        options:
        - daily    # ìµœê·¼ 7ì¼ ë°ì´í„°ë§Œ (ë¹ ë¥¸ ì²˜ë¦¬)
        - full     # ì „ì²´ ë°ì´í„° ì²˜ë¦¬ (ì™„ì „ ì ê²€)
  schedule:
    - cron: '0 8 * * 1-5'  # í‰ì¼ ì˜¤í›„ 5ì‹œ (KST)

jobs:
  collect:
    name: ê¸°ì—…ë§ˆë‹¹ ì™„ì „ ìë™ ì²˜ë¦¬
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 supabase pandas openpyxl
        pip install selenium webdriver-manager
    
    - name: Determine Mode
      id: mode
      run: |
        if [ "${{ github.event_name }}" = "schedule" ]; then
          echo "mode=daily" >> $GITHUB_OUTPUT
          echo "ğŸ“… ìŠ¤ì¼€ì¤„ ì‹¤í–‰: daily ëª¨ë“œ"
        else
          echo "mode=${{ github.event.inputs.mode || 'daily' }}" >> $GITHUB_OUTPUT
          echo "ğŸ¯ ìˆ˜ë™ ì‹¤í–‰: ${{ github.event.inputs.mode || 'daily' }} ëª¨ë“œ"
        fi
    
    - name: Step 1 - Excel Collection
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
      run: |
        echo "======================================"
        echo "  STEP 1: ê¸°ì—…ë§ˆë‹¹ ì—‘ì…€ ë°ì´í„° ìˆ˜ì§‘"
        echo "======================================"
        echo "ğŸ” ëª¨ë“œ: ${{ steps.mode.outputs.mode }}"
        python scripts/bizinfo_excel_collector.py
    
    - name: Step 2 - Daily Mode Crawler
      if: steps.mode.outputs.mode == 'daily'
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
      run: |
        echo "======================================"
        echo "  STEP 2: Daily ëª¨ë“œ - ìµœê·¼ ë°ì´í„°ë§Œ ì²˜ë¦¬"
        echo "======================================"
        echo "ìµœê·¼ 7ì¼ ì´ë‚´ ë°ì´í„° ì¤‘ ìš”ì•½/ì²¨ë¶€íŒŒì¼ ëˆ„ë½ëœ í•­ëª©ë§Œ ì²˜ë¦¬..."
        
        # Daily ëª¨ë“œ: ìµœê·¼ 7ì¼ + í’ˆì§ˆ ë¯¸ë‹¬ ë°ì´í„°ë§Œ ì²˜ë¦¬
        cat << 'EOF' > daily_crawler.py
        import os
        import sys
        import requests
        from bs4 import BeautifulSoup
        from supabase import create_client
        from datetime import datetime, timedelta
        import time
        import threading
        from queue import Queue
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        # Supabase ì„¤ì •
        url = os.environ.get('SUPABASE_URL')
        key = os.environ.get('SUPABASE_SERVICE_KEY') or os.environ.get('SUPABASE_KEY')
        
        if not url or not key:
            print("í™˜ê²½ë³€ìˆ˜ ì˜¤ë¥˜")
            exit(1)
            
        supabase = create_client(url, key)
        
        # 7ì¼ ì „ ë‚ ì§œ
        seven_days_ago = (datetime.now() - timedelta(days=7)).isoformat()
        
        print("ğŸ“… Daily ëª¨ë“œ: ìµœê·¼ 7ì¼ ë°ì´í„° ì²˜ë¦¬")
        print(f"ê¸°ì¤€ ë‚ ì§œ: {seven_days_ago}")
        
        # ìµœê·¼ 7ì¼ ì´ë‚´ ë°ì´í„° ì¤‘ ìš”ì•½ì´ ë¶€ì‹¤í•˜ê±°ë‚˜ ì²¨ë¶€íŒŒì¼ì´ ì—†ëŠ” ê²ƒ
        response = supabase.table('bizinfo_complete').select('*').gte('created_at', seven_days_ago).execute()
        
        to_process = []
        for item in response.data:
            # ìš”ì•½ì´ 150ì ë¯¸ë§Œì´ê±°ë‚˜ ì²¨ë¶€íŒŒì¼ì´ ì—†ìœ¼ë©´ ì²˜ë¦¬ ëŒ€ìƒ
            if not item.get('bsns_sumry') or len(item.get('bsns_sumry', '')) < 150 or not item.get('attachment_urls'):
                to_process.append(item)
        
        print(f"ì²˜ë¦¬ ëŒ€ìƒ: {len(to_process)}ê°œ")
        
        if len(to_process) == 0:
            print("âœ… ëª¨ë“  ìµœê·¼ ë°ì´í„°ê°€ ì •ìƒì…ë‹ˆë‹¤.")
            exit(0)
        
        # ì—¬ê¸°ì„œë¶€í„°ëŠ” bizinfo_attachment_crawler.py ë¡œì§ í™œìš©
        def process_item(item):
            try:
                dtl_url = item.get('dtl_url')
                if not dtl_url:
                    return None
                    
                response = requests.get(dtl_url, timeout=10)
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ìš”ì•½ ì¶”ì¶œ
                summary_parts = []
                for row in soup.select('table tbody tr'):
                    th = row.select_one('th')
                    td = row.select_one('td')
                    if th and td:
                        label = th.get_text(strip=True)
                        value = td.get_text(strip=True)
                        if value and value != '-':
                            summary_parts.append(f"{label}: {value}")
                
                summary = ' | '.join(summary_parts[:10]) if summary_parts else None
                
                # ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ
                attachment_urls = []
                for link in soup.select('a[href*="atchFileId"]'):
                    href = link.get('href', '')
                    if 'atchFileId' in href and 'fileSn' in href:
                        file_url = f"https://www.bizinfo.go.kr{href}" if href.startswith('/') else href
                        attachment_urls.append(file_url)
                
                # ì—…ë°ì´íŠ¸
                if summary or attachment_urls:
                    update_data = {}
                    if summary and len(summary) > 150:
                        update_data['bsns_sumry'] = summary
                    if attachment_urls:
                        update_data['attachment_urls'] = attachment_urls
                    
                    if update_data:
                        supabase.table('bizinfo_complete').update(update_data).eq('id', item['id']).execute()
                        return True
                        
            except Exception as e:
                print(f"ì˜¤ë¥˜ {item['id']}: {e}")
                return False
        
        # ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ ì²˜ë¦¬
        success_count = 0
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(process_item, item) for item in to_process]
            for future in as_completed(futures):
                if future.result():
                    success_count += 1
        
        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {success_count}/{len(to_process)}ê°œ")
        EOF
        
        python daily_crawler.py
    
    - name: Step 2 - Full Mode Crawler  
      if: steps.mode.outputs.mode == 'full'
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
      run: |
        echo "======================================"
        echo "  STEP 2: Full ëª¨ë“œ - ì „ì²´ ë°ì´í„° ì²˜ë¦¬"
        echo "======================================"
        echo "ëª¨ë“  ë°ì´í„° ì ê²€ ë° ëˆ„ë½ëœ ìš”ì•½/ì²¨ë¶€íŒŒì¼ ë³µêµ¬..."
        python scripts/bizinfo_attachment_crawler.py
    
    - name: Step 3 - Attachment Processing
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
      run: |
        echo "======================================"
        echo "  STEP 3: ì²¨ë¶€íŒŒì¼ ì •ë¦¬"
        echo "======================================"
        python scripts/bizinfo_complete_processor_fast.py
    
    - name: Generate Final Report
      if: always()
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
      run: |
        cat << 'EOF' > report.py
        import os
        from supabase import create_client
        from datetime import datetime
        
        url = os.environ.get('SUPABASE_URL')
        key = os.environ.get('SUPABASE_SERVICE_KEY')
        
        if not url or not key:
            print("í™˜ê²½ë³€ìˆ˜ ì˜¤ë¥˜: SUPABASE_URL ë˜ëŠ” SUPABASE_SERVICE_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            exit(1)
            
        supabase = create_client(url, key)
        
        # ì‹¤í–‰ ëª¨ë“œ í™•ì¸
        mode = os.environ.get('MODE', 'unknown')
        
        try:
            # ì „ì²´ í†µê³„
            total = supabase.table('bizinfo_complete').select('id').execute()
            total_count = len(total.data) if total.data else 0
            
            # ì˜¤ëŠ˜ ì¶”ê°€ëœ ë°ì´í„°
            today = datetime.now().date().isoformat()
            today_new = supabase.table('bizinfo_complete').select('id').gte('created_at', today).execute()
            today_count = len(today_new.data) if today_new.data else 0
            
            # ì •ìƒ ìš”ì•½ ë³´ìœ  ë°ì´í„° (150ì ì´ìƒ)
            all_data = supabase.table('bizinfo_complete').select('id,bsns_sumry').limit(1000).execute()
            if all_data.data:
                with_summary = sum(1 for item in all_data.data 
                                 if item.get('bsns_sumry') and len(item['bsns_sumry']) > 150)
            else:
                with_summary = 0
            
            # ì²¨ë¶€íŒŒì¼ ë³´ìœ  ë°ì´í„°
            with_attach = supabase.table('bizinfo_complete').select('id,attachment_urls').limit(1000).execute()
            attach_count = sum(1 for item in with_attach.data 
                             if item.get('attachment_urls') and item['attachment_urls'] != [])
            
            print('\n' + '='*60)
            print('      ğŸ¢ ê¸°ì—…ë§ˆë‹¹ ì²˜ë¦¬ ê²°ê³¼ ë³´ê³ ì„œ')
            print('='*60)
            print(f'ğŸ” ì‹¤í–‰ ëª¨ë“œ: {mode.upper()}')
            print(f'ğŸ“Š ì „ì²´ ë°ì´í„°: {total_count}ê°œ')
            print(f'ğŸ“Š ì˜¤ëŠ˜ ì‹ ê·œ ì¶”ê°€: {today_count}ê°œ')
            print(f'ğŸ“Š ì •ìƒ ìš”ì•½ ë³´ìœ  (ìƒ˜í”Œ 1000ê°œ): {with_summary}ê°œ ({with_summary*100/min(1000, total_count):.1f}%)')
            print(f'ğŸ“Š ì²¨ë¶€íŒŒì¼ ë³´ìœ  (ìƒ˜í”Œ 1000ê°œ): {attach_count}ê°œ ({attach_count*100/min(1000, total_count):.1f}%)')
            
            # ìµœê·¼ ë°ì´í„° ìƒíƒœ ì ê²€
            recent = supabase.table('bizinfo_complete').select('id,attachment_urls,bsns_sumry,created_at').order('created_at', desc=True).limit(100).execute()
            if recent.data:
                recent_with_attach = sum(1 for item in recent.data 
                                       if item.get('attachment_urls') and item['attachment_urls'] != [])
                recent_with_summary = sum(1 for item in recent.data 
                                        if item.get('bsns_sumry') and len(item['bsns_sumry']) > 150)
                print(f'\nğŸ“Œ ìµœê·¼ 100ê°œ ë°ì´í„°:')
                print(f'   - ì²¨ë¶€íŒŒì¼ ë³´ìœ : {recent_with_attach}ê°œ ({recent_with_attach}%)')
                print(f'   - ì •ìƒ ìš”ì•½: {recent_with_summary}ê°œ ({recent_with_summary}%)')
                if recent_with_attach < 70:
                    print('   âš ï¸ ê²½ê³ : ìµœê·¼ ë°ì´í„° ì²¨ë¶€íŒŒì¼ ìˆ˜ì§‘ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤!')
                if recent_with_summary < 70:
                    print('   âš ï¸ ê²½ê³ : ìµœê·¼ ë°ì´í„° ìš”ì•½ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤!')
            
            # í’ˆì§ˆ ì²´í¬
            quality_score = (with_summary / min(1000, total_count) * 100) if total_count > 0 else 0
            attach_score = (attach_count / min(1000, total_count) * 100) if total_count > 0 else 0
            
            print('\nğŸ“ˆ í’ˆì§ˆ í‰ê°€:')
            if quality_score >= 90:
                print('  âœ… ìš”ì•½ í’ˆì§ˆ: ìš°ìˆ˜ (90% ì´ìƒ)')
            elif quality_score >= 70:
                print('  âš ï¸ ìš”ì•½ í’ˆì§ˆ: ë³´í†µ (70-90%)')
            else:
                print('  âŒ ìš”ì•½ í’ˆì§ˆ: ê°œì„  í•„ìš” (70% ë¯¸ë§Œ)')
            
            if attach_score >= 90:
                print('  âœ… ì²¨ë¶€íŒŒì¼: ìš°ìˆ˜ (90% ì´ìƒ)')
            elif attach_score >= 70:
                print('  âš ï¸ ì²¨ë¶€íŒŒì¼: ë³´í†µ (70-90%)')
            else:
                print('  âŒ ì²¨ë¶€íŒŒì¼: ê°œì„  í•„ìš” (70% ë¯¸ë§Œ)')
            
            # ëª¨ë“œë³„ ì²˜ë¦¬ ë°©ì‹ ì•ˆë‚´
            print('\nğŸ”§ ì²˜ë¦¬ ë°©ì‹:')
            if mode == 'daily':
                print('  - Daily ëª¨ë“œ: ìµœê·¼ 7ì¼ ë°ì´í„°ë§Œ ì²˜ë¦¬')
                print('  - ìš”ì•½/ì²¨ë¶€íŒŒì¼ ëˆ„ë½ í•­ëª© ì„ ë³„ ì²˜ë¦¬')
                print('  - ë¹ ë¥¸ ì‹¤í–‰ (2-5ë¶„)')
            else:
                print('  - Full ëª¨ë“œ: ì „ì²´ ë°ì´í„° ì ê²€')
                print('  - 8ì›” 8ì¼ ì •ìƒ ì‘ë™ ë²„ì „ ì‚¬ìš©')
                print('  - HTTP í¬ë¡¤ë§ + BeautifulSoup')
            
            if today_count > 0:
                print(f'\nâœ… ì˜¤ëŠ˜ {today_count}ê°œ ì²˜ë¦¬ ì„±ê³µ!')
            else:
                print('\nâš ï¸ ì˜¤ëŠ˜ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤')
            
            print('='*60)
            
        except Exception as e:
            print(f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            exit(1)
        EOF
        MODE=${{ steps.mode.outputs.mode }} python report.py
