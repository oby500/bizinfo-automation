#!/usr/bin/env python3
"""
K-Startup ì›¹ ìŠ¤í¬ë˜í•‘ ìˆ˜ì§‘ê¸° (API ë³€ê²½ ëŒ€ì‘)
ì›¹í˜ì´ì§€ë¥¼ ì§ì ‘ íŒŒì‹±í•˜ì—¬ ë°ì´í„° ìˆ˜ì§‘
"""
import sys
sys.stdout.reconfigure(encoding='utf-8')
import os
import requests
from bs4 import BeautifulSoup
import json
from supabase import create_client
from dotenv import load_dotenv
from datetime import datetime
import re
import time

load_dotenv()

# Supabase ì„¤ì •
url = os.environ.get('SUPABASE_URL')
key = os.environ.get('SUPABASE_KEY')
supabase = create_client(url, key)

# ìˆ˜ì§‘ ëª¨ë“œ
COLLECTION_MODE = os.environ.get('COLLECTION_MODE', 'daily')

# ì„¸ì…˜ ì„¤ì •
session = requests.Session()
session.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
    'Referer': 'https://www.k-startup.go.kr/'
})

def parse_list_page(page_num, status='ongoing'):
    """ëª©ë¡ í˜ì´ì§€ íŒŒì‹±"""
    if status == 'ongoing':
        url = f'https://www.k-startup.go.kr/web/contents/bizpbanc-ongoing.do?schM=list&page={page_num}'
    else:
        url = f'https://www.k-startup.go.kr/web/contents/bizpbanc-deadline.do?schM=list&page={page_num}'
    
    try:
        response = session.get(url, timeout=30)
        if response.status_code != 200:
            print(f"[ERROR] í˜ì´ì§€ {page_num} ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")
            return []
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # JavaScriptì—ì„œ ë°ì´í„° ì¶”ì¶œ
        announcements = []
        scripts = soup.find_all('script')
        
        for script in scripts:
            if script.string and 'pbancSn' in script.string:
                # ì •ê·œì‹ìœ¼ë¡œ ê³µê³  ë°ì´í„° ì¶”ì¶œ
                # pbancSn íŒ¨í„´ ì°¾ê¸°
                pbanc_pattern = r'pbancSn["\s]*:["\s]*"?(\d+)"?'
                title_pattern = r'bizPbancNm["\s]*:["\s]*"([^"]+)"'
                deadline_pattern = r'pbancDdlnDt["\s]*:["\s]*"([^"]+)"'
                
                pbanc_matches = re.findall(pbanc_pattern, script.string)
                title_matches = re.findall(title_pattern, script.string)
                deadline_matches = re.findall(deadline_pattern, script.string)
                
                # ë§¤ì¹­ëœ ë°ì´í„° ì¡°í•©
                for i in range(len(pbanc_matches)):
                    if i < len(title_matches):
                        ann = {
                            'pbancSn': pbanc_matches[i],
                            'bizPbancNm': title_matches[i] if i < len(title_matches) else '',
                            'pbancDdlnDt': deadline_matches[i] if i < len(deadline_matches) else '',
                            'status': 'ëª¨ì§‘ì¤‘' if status == 'ongoing' else 'ë§ˆê°'
                        }
                        announcements.append(ann)
        
        # HTMLì—ì„œ ì§ì ‘ ì¶”ì¶œ ì‹œë„ (ëŒ€ì•ˆ)
        if not announcements:
            # ëª©ë¡ ì•„ì´í…œ ì°¾ê¸°
            list_items = soup.select('.list-item, .board-list li, .notice-list li, .biz-list li')
            
            for item in list_items:
                # ë§í¬ì—ì„œ pbancSn ì¶”ì¶œ
                link = item.find('a', href=re.compile(r'pbancSn=(\d+)'))
                if link:
                    pbanc_sn = re.search(r'pbancSn=(\d+)', link.get('href', '')).group(1)
                    title_elem = item.select_one('.tit, .title, h3, h4')
                    deadline_elem = item.select_one('.date, .deadline, .period')
                    
                    ann = {
                        'pbancSn': pbanc_sn,
                        'bizPbancNm': title_elem.text.strip() if title_elem else '',
                        'pbancDdlnDt': deadline_elem.text.strip() if deadline_elem else '',
                        'status': 'ëª¨ì§‘ì¤‘' if status == 'ongoing' else 'ë§ˆê°'
                    }
                    announcements.append(ann)
        
        return announcements
        
    except Exception as e:
        print(f"[ERROR] í˜ì´ì§€ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return []

def parse_detail_page(pbanc_sn, status='ongoing'):
    """ìƒì„¸ í˜ì´ì§€ íŒŒì‹±"""
    if status == 'ëª¨ì§‘ì¤‘':
        url = f'https://www.k-startup.go.kr/web/contents/bizpbanc-ongoing.do?schM=view&pbancSn={pbanc_sn}'
    else:
        url = f'https://www.k-startup.go.kr/web/contents/bizpbanc-deadline.do?schM=view&pbancSn={pbanc_sn}'
    
    try:
        response = session.get(url, timeout=30)
        if response.status_code != 200:
            return None, []
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ì‚¬ì—… ìš”ì•½ ì¶”ì¶œ
        content_elem = soup.select_one('.content-wrap, .detail-content, .board-view, .view-content')
        bsns_sumry = content_elem.get_text(strip=True)[:5000] if content_elem else ''
        
        # ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ
        attachments = []
        file_links = soup.find_all('a', href=re.compile(r'/afile/fileDownload/|download\.do'))
        
        for link in file_links:
            href = link.get('href', '')
            if href.startswith('/'):
                href = f'https://www.k-startup.go.kr{href}'
            
            text = link.get_text(strip=True) or 'ì²¨ë¶€íŒŒì¼'
            attachments.append({
                'url': href,
                'text': text,
                'type': 'FILE'
            })
        
        return bsns_sumry, attachments
        
    except Exception as e:
        print(f"[ERROR] ìƒì„¸í˜ì´ì§€ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None, []

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("="*60)
    print(f"ğŸš€ K-Startup ì›¹ ìŠ¤í¬ë˜í•‘ ìˆ˜ì§‘ ì‹œì‘ ({COLLECTION_MODE} ëª¨ë“œ)")
    print("="*60)
    
    # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ
    existing = supabase.table('kstartup_complete').select('announcement_id').execute()
    existing_ids = {item['announcement_id'] for item in existing.data} if existing.data else set()
    print(f"âœ… ê¸°ì¡´ ë°ì´í„°: {len(existing_ids)}ê°œ\n")
    
    all_announcements = []
    
    # ëª¨ë“œë³„ í˜ì´ì§€ ì„¤ì •
    if COLLECTION_MODE == 'full':
        max_pages = 50  # ì „ì²´ í˜ì´ì§€
        statuses = ['ongoing', 'deadline']
    else:
        max_pages = 5  # dailyëŠ” ìµœê·¼ 5í˜ì´ì§€ë§Œ
        statuses = ['ongoing']  # ì§„í–‰ì¤‘ë§Œ
    
    # ê° ìƒíƒœë³„ë¡œ ìˆ˜ì§‘
    for status in statuses:
        print(f"\nğŸ“‹ {status.upper()} ê³µê³  ìˆ˜ì§‘")
        
        for page in range(1, max_pages + 1):
            print(f"  í˜ì´ì§€ {page} ì²˜ë¦¬ì¤‘...")
            
            announcements = parse_list_page(page, status)
            
            if not announcements:
                print(f"    ë°ì´í„° ì—†ìŒ - ì¢…ë£Œ")
                break
            
            # ì¤‘ë³µ ì²´í¬
            new_items = []
            for ann in announcements:
                ann_id = f"KS_{ann['pbancSn']}"
                if ann_id not in existing_ids:
                    ann['announcement_id'] = ann_id
                    new_items.append(ann)
            
            if new_items:
                all_announcements.extend(new_items)
                print(f"    {len(new_items)}ê°œ ì‹ ê·œ ë°œê²¬")
            else:
                print(f"    ëª¨ë‘ ì¤‘ë³µ")
                if COLLECTION_MODE == 'daily':
                    break  # daily ëª¨ë“œì—ì„œëŠ” ì¤‘ë³µ í˜ì´ì§€ ë§Œë‚˜ë©´ ì¢…ë£Œ
            
            time.sleep(0.5)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
    
    if not all_announcements:
        print("\nâœ… ìƒˆë¡œìš´ ë°ì´í„° ì—†ìŒ")
        return
    
    print(f"\nğŸ“Š ì²˜ë¦¬í•  ì‹ ê·œ ë°ì´í„°: {len(all_announcements)}ê°œ")
    print("ğŸ”„ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘...\n")
    
    # ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ë° ì €ì¥
    success = 0
    errors = 0
    
    for i, ann in enumerate(all_announcements, 1):
        try:
            print(f"  [{i}/{len(all_announcements)}] {ann['announcement_id']} ì²˜ë¦¬ì¤‘...")
            
            # ìƒì„¸ í˜ì´ì§€ íŒŒì‹±
            bsns_sumry, attachments = parse_detail_page(ann['pbancSn'], ann['status'])
            
            # ë°ì´í„° ì¤€ë¹„
            data = {
                'announcement_id': ann['announcement_id'],
                'pbanc_sn': ann['pbancSn'],
                'biz_pbanc_nm': ann['bizPbancNm'],
                'pbanc_ddln_dt': ann.get('pbancDdlnDt', ''),
                'status': ann['status'],
                'bsns_sumry': bsns_sumry or '',
                'attachment_urls': attachments,
                'attachment_count': len(attachments),
                'created_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat()
            }
            
            # ìƒì„¸ URL ì„¤ì •
            if ann['status'] == 'ëª¨ì§‘ì¤‘':
                data['detl_pg_url'] = f"https://www.k-startup.go.kr/web/contents/bizpbanc-ongoing.do?schM=view&pbancSn={ann['pbancSn']}"
            else:
                data['detl_pg_url'] = f"https://www.k-startup.go.kr/web/contents/bizpbanc-deadline.do?schM=view&pbancSn={ann['pbancSn']}"
            
            # DB ì €ì¥
            result = supabase.table('kstartup_complete').upsert(
                data,
                on_conflict='announcement_id'
            ).execute()
            
            if result.data:
                success += 1
                print(f"    [OK] ì €ì¥ ì™„ë£Œ")
            else:
                errors += 1
                print(f"    [ERROR] ì €ì¥ ì‹¤íŒ¨")
            
            time.sleep(1)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
            
        except Exception as e:
            errors += 1
            print(f"    [ERROR] ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    # ìµœì¢… ë³´ê³ 
    print("\n" + "="*60)
    print("ğŸ“Š K-Startup ì›¹ ìŠ¤í¬ë˜í•‘ ìˆ˜ì§‘ ì™„ë£Œ")
    print("="*60)
    print(f"âœ… ì„±ê³µ: {success}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {errors}ê°œ")
    print(f"ğŸ“Š ì „ì²´: {success + errors}ê°œ")
    print("="*60)

if __name__ == "__main__":
    main()