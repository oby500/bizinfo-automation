import requests
import xml.etree.ElementTree as ET
import json
from datetime import datetime

def fetch_maximum_government_data():
    """ì •ë¶€ì§€ì›ì‚¬ì—… APIì—ì„œ ìµœëŒ€í•œ ë§ì€ ì •ë³´ ìˆ˜ì§‘"""
    print("=== ì •ë¶€ì§€ì›ì‚¬ì—… API ìµœëŒ€ ì •ë³´ ìˆ˜ì§‘ ===")
    print("=" * 70)
    
    all_data = []
    all_fields = set()
    
    # 1. K-Startup API í˜¸ì¶œ
    print("\nğŸ“¡ 1. K-Startup API í˜¸ì¶œ")
    print("-" * 50)
    kstartup_data = fetch_bizinfo_complete()
    all_data.extend(kstartup_data)
    
    # 2. ê¸°ì—…ë§ˆë‹¹ API ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ API í‚¤ ì—†ì´)
    print("\nğŸ“¡ 2. ê¸°ì—…ë§ˆë‹¹ API í•„ë“œ ë¶„ì„")
    print("-" * 50)
    bizinfo_fields = analyze_bizinfo_schema()
    
    # 3. ëª¨ë“  í•„ë“œ í†µí•© ë¶„ì„
    print("\nğŸ“Š 3. ì „ì²´ í•„ë“œ í†µí•© ë¶„ì„")
    print("-" * 50)
    
    # K-Startup í•„ë“œ ìˆ˜ì§‘
    for item in all_data:
        for field in item.keys():
            all_fields.add(f"kstartup_{field}")
    
    # ê¸°ì—…ë§ˆë‹¹ í•„ë“œ ì¶”ê°€
    for field in bizinfo_fields:
        all_fields.add(f"bizinfo_{field}")
    
    print(f"ğŸ“‹ ì´ ë°œê²¬ëœ í•„ë“œ: {len(all_fields)}ê°œ")
    print(f"  - K-Startup í•„ë“œ: {len([f for f in all_fields if f.startswith('kstartup_')])}ê°œ")
    print(f"  - ê¸°ì—…ë§ˆë‹¹ í•„ë“œ: {len([f for f in all_fields if f.startswith('bizinfo_')])}ê°œ")
    
    # 4. ìƒì„¸ ë°ì´í„° ì¶œë ¥
    print("\nğŸ” 4. ìˆ˜ì§‘ëœ ë°ì´í„° ìƒ˜í”Œ")
    print("-" * 50)
    
    for i, item in enumerate(all_data[:3], 1):
        print(f"\nğŸ“„ {i}ë²ˆì§¸ ì§€ì›ì‚¬ì—…:")
        print("-" * 30)
        for key, value in item.items():
            if value and str(value).strip():
                display_value = str(value).strip()
                if len(display_value) > 100:
                    display_value = display_value[:100] + "..."
                print(f"  {key}: {display_value}")
    
    # 5. ê²°ê³¼ ì €ì¥
    result = {
        'collection_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'total_fields': len(all_fields),
        'all_fields': sorted(list(all_fields)),
        'kstartup_fields': sorted([f.replace('kstartup_', '') for f in all_fields if f.startswith('kstartup_')]),
        'bizinfo_fields': sorted([f.replace('bizinfo_', '') for f in all_fields if f.startswith('bizinfo_')]),
        'sample_data': all_data[:5],
        'field_mapping': {
            'kstartup_api_url': 'https://www.k-startup.go.kr/api/apisvc/xml/GetPblancListSvc',
            'bizinfo_api_url': 'http://apis.data.go.kr/B552015/NpsBplcInfoInqireService/getBplcInfoList'
        }
    }
    
    with open('complete_government_api_data.json', 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ì™„ì „í•œ ë¶„ì„ ê²°ê³¼ê°€ 'complete_government_api_data.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return result

def fetch_bizinfo_complete():
    """K-Startup APIì—ì„œ ìµœëŒ€í•œ ì™„ì „í•œ ë°ì´í„° ìˆ˜ì§‘"""
    print("K-Startup API ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    
    base_url = "https://www.k-startup.go.kr/api/apisvc/xml/GetPblancListSvc"
    
    # ë‹¤ì–‘í•œ ì¡°ê±´ìœ¼ë¡œ í˜¸ì¶œí•´ì„œ ë” ë§ì€ í•„ë“œ ë°œê²¬í•˜ê¸°
    test_params = [
        {
            'perPage': '10',
            'page': '1',
            'sortColumn': 'REG_YMD',
            'sortDirection': 'DESC'
        },
        {
            'perPage': '10', 
            'page': '1',
            'sortColumn': 'PBLANC_YMD',
            'sortDirection': 'DESC'
        },
        {
            'perPage': '10',
            'page': '1',
            'sortColumn': 'REQST_END_YMD', 
            'sortDirection': 'DESC'
        }
    ]
    
    all_items = []
    
    for params in test_params:
        try:
            response = requests.get(base_url, params=params, timeout=30)
            
            if response.status_code == 200:
                root = ET.fromstring(response.text)
                
                # ëª¨ë“  item ìš”ì†Œ ì°¾ê¸°
                items = []
                for elem in root.iter():
                    if elem.tag.lower().endswith('item'):
                        items.append(elem)
                
                print(f"  íŒŒë¼ë¯¸í„° {params['sortColumn']}: {len(items)}ê°œ ì•„ì´í…œ ë°œê²¬")
                
                # ê° ì•„ì´í…œì˜ ëª¨ë“  ìì‹ ìš”ì†Œë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                for item in items:
                    item_data = {'source': 'k-startup'}
                    for child in item:
                        if child.text and child.text.strip():
                            item_data[child.tag] = child.text.strip()
                    
                    if len(item_data) > 1:  # source ì™¸ì— ë°ì´í„°ê°€ ìˆìœ¼ë©´
                        all_items.append(item_data)
                        
        except Exception as e:
            print(f"  ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ì¤‘ë³µ ì œê±° (ê³µê³ ID ê¸°ì¤€)
    unique_items = []
    seen_ids = set()
    
    for item in all_items:
        item_id = item.get('pblancId') or item.get('pblancNo') or item.get('seq', '')
        if item_id and item_id not in seen_ids:
            seen_ids.add(item_id)
            unique_items.append(item)
    
    print(f"âœ… K-Startup ì´ {len(unique_items)}ê°œ ìœ ë‹ˆí¬ ì•„ì´í…œ ìˆ˜ì§‘ ì™„ë£Œ")
    return unique_items

def analyze_bizinfo_schema():
    """ì œê³µëœ ê¸°ì—…ë§ˆë‹¹ API ìŠ¤í‚¤ë§ˆ ë¶„ì„"""
    print("ê¸°ì—…ë§ˆë‹¹ API ìŠ¤í‚¤ë§ˆ ë¶„ì„ ì¤‘...")
    
    # ë¬¸ì„œì—ì„œ ì œê³µëœ ëª¨ë“  í•„ë“œë“¤
    bizinfo_fields = [
        # RSS ê¸°ë³¸ ì •ë³´
        'title', 'link', 'description', 'language', 'copyright',
        'managingEditor', 'webMaster', 'pubDate', 'lastBuildDate',
        'category', 'ttl',
        
        # ì•„ì´í…œ ê¸°ë³¸ ì •ë³´
        'title', 'link', 'seq', 'author', 'excInsttNm',
        'description', 'lcategory', 'pubDate', 'reqstDt',
        'trgetNm', 'inqireCo',
        
        # íŒŒì¼ ê´€ë ¨
        'flpthNm', 'fileNm', 'printFlpthNm', 'printFileNm',
        
        # ë©”íƒ€ ì •ë³´
        'hashTags', 'totCnt',
        
        # ê³µê³  ìƒì„¸ ì •ë³´ (ì¤‘ë³µ ì œê±°ëœ ë²„ì „)
        'pblancNm', 'pblancUrl', 'pblancId', 'jrsdInsttNm',
        'bsnsSumryCn', 'reqstMthPapersCn', 'refrncNm',
        'rceptEngnHmpgUrl', 'pldirSportRealmLclasCodeNm',
        'creatPnttm', 'reqstBeginEndDe'
    ]
    
    # ì¤‘ë³µ ì œê±°
    unique_fields = list(set(bizinfo_fields))
    
    print(f"âœ… ê¸°ì—…ë§ˆë‹¹ API {len(unique_fields)}ê°œ í•„ë“œ ë¶„ì„ ì™„ë£Œ")
    
    # í•„ë“œë³„ ì„¤ëª…ë„ í¬í•¨
    field_descriptions = {
        'pblancNm': 'ê³µê³ ëª…',
        'pblancUrl': 'ê³µê³ URL', 
        'pblancId': 'ê³µê³ ID',
        'jrsdInsttNm': 'ì†Œê´€ê¸°ê´€ëª…',
        'excInsttNm': 'ìˆ˜í–‰ê¸°ê´€ëª…',
        'bsnsSumryCn': 'ì‚¬ì—…ê°œìš”ë‚´ìš©',
        'reqstMthPapersCn': 'ì‚¬ì—…ì‹ ì²­ë°©ë²•',
        'refrncNm': 'ë¬¸ì˜ì²˜',
        'rceptEngnHmpgUrl': 'ì‚¬ì—…ì‹ ì²­URL',
        'pldirSportRealmLclasCodeNm': 'ì§€ì›ë¶„ì•¼ ëŒ€ë¶„ë¥˜',
        'creatPnttm': 'ë“±ë¡ì¼ì',
        'reqstBeginEndDe': 'ì‹ ì²­ê¸°ê°„',
        'trgetNm': 'ì§€ì›ëŒ€ìƒ',
        'hashTags': 'í•´ì‹œíƒœê·¸',
        'inqireCo': 'ì¡°íšŒìˆ˜',
        'flpthNm': 'ì²¨ë¶€íŒŒì¼ê²½ë¡œëª…',
        'fileNm': 'ì²¨ë¶€íŒŒì¼ëª…',
        'printFlpthNm': 'ë³¸ë¬¸ì¶œë ¥íŒŒì¼ê²½ë¡œëª…',
        'printFileNm': 'ë³¸ë¬¸ì¶œë ¥íŒŒì¼ëª…'
    }
    
    print("\nğŸ“‹ ì£¼ìš” ê¸°ì—…ë§ˆë‹¹ API í•„ë“œë“¤:")
    for field in sorted(unique_fields)[:15]:  # ì²˜ìŒ 15ê°œë§Œ ì¶œë ¥
        desc = field_descriptions.get(field, 'ì„¤ëª… ì—†ìŒ')
        print(f"  {field}: {desc}")
    
    return unique_fields

def create_unified_collector():
    """í†µí•© ìˆ˜ì§‘ê¸° ìƒì„±"""
    print("\nğŸ”§ í†µí•© ë°ì´í„° ìˆ˜ì§‘ê¸° ìƒì„±")
    print("-" * 50)
    
    collector_code = '''
# í†µí•© ì •ë¶€ì§€ì›ì‚¬ì—… ë°ì´í„° ìˆ˜ì§‘ê¸°
# K-Startup + ê¸°ì—…ë§ˆë‹¹ API ëª¨ë“  í•„ë“œ ìˆ˜ì§‘

import requests
import xml.etree.ElementTree as ET
import json
from datetime import datetime

def collect_all_government_data():
    """ëª¨ë“  ì •ë¶€ì§€ì›ì‚¬ì—… ë°ì´í„° ìˆ˜ì§‘"""
    
    all_data = []
    
    # 1. K-Startup API ìˆ˜ì§‘
    kstartup_data = collect_kstartup_data()
    all_data.extend(kstartup_data)
    
    # 2. ê¸°ì—…ë§ˆë‹¹ API ìˆ˜ì§‘ (API í‚¤ í•„ìš”)
    # bizinfo_data = collect_bizinfo_data()
    # all_data.extend(bizinfo_data)
    
    return all_data

def collect_kstartup_data():
    """K-Startup ëª¨ë“  í•„ë“œ ìˆ˜ì§‘"""
    # ... (ìœ„ ì½”ë“œì™€ ë™ì¼)
    pass

def collect_bizinfo_data():
    """ê¸°ì—…ë§ˆë‹¹ ëª¨ë“  í•„ë“œ ìˆ˜ì§‘ (API í‚¤ í•„ìš”)"""
    # API í‚¤ê°€ ìˆì„ ë•Œ ì‚¬ìš©
    pass

if __name__ == "__main__":
    data = collect_all_government_data()
    print(f"ì´ {len(data)}ê°œ ì§€ì›ì‚¬ì—… ìˆ˜ì§‘ ì™„ë£Œ!")
'''
    
    with open('unified_government_collector.py', 'w', encoding='utf-8') as f:
        f.write(collector_code)
    
    print("âœ… í†µí•© ìˆ˜ì§‘ê¸° ì½”ë“œê°€ 'unified_government_collector.py'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    print(f"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ìµœëŒ€ ì •ë³´ ìˆ˜ì§‘ ì‹¤í–‰
    result = fetch_maximum_government_data()
    
    # í†µí•© ìˆ˜ì§‘ê¸° ìƒì„±
    create_unified_collector()
    
    print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“Š ì´ {result['total_fields']}ê°œ í•„ë“œ ë°œê²¬")
    print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼:")
    print(f"  - complete_government_api_data.json (ì „ì²´ ë¶„ì„ ê²°ê³¼)")
    print(f"  - unified_government_collector.py (í†µí•© ìˆ˜ì§‘ê¸°)")
