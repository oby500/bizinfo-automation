#!/usr/bin/env python3
"""
K-Startup ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ (GitHub Actionsìš©)
ì˜¤ì „ 7ì‹œ ìë™ ì‹¤í–‰
"""
import os
import sys
import requests
import json
from datetime import datetime, timedelta
from urllib.parse import urljoin
from supabase import create_client, Client
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)

class KStartupCollector:
    def __init__(self):
        """ì´ˆê¸°í™”"""
        # Supabase ì—°ê²°
        url = os.environ.get('SUPABASE_URL')
        key = os.environ.get('SUPABASE_KEY') or os.environ.get('SUPABASE_SERVICE_KEY')
        
        if not url or not key:
            logging.error("í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            sys.exit(1)
            
        self.supabase: Client = create_client(url, key)
        
        # API ì„¤ì • - HTTP ì‚¬ìš© (HTTPS ì•„ë‹˜)
        self.api_base_url = "http://www.k-startup.go.kr/web/module/bizpbanc-list.do"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Content-Type': 'application/json'
        }
        
        logging.info("=== K-Startup ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ===")
    
    def fetch_announcements(self):
        """K-Startup ê³µê³  ëª©ë¡ ì¡°íšŒ"""
        try:
            # API íŒŒë¼ë¯¸í„° ì„¤ì •
            params = {
                'page': 1,
                'pageSize': 50,  # í•œ ë²ˆì— 50ê°œ
                'searchType': 'all',
                'searchPbancSttsCd': '01',  # ëª¨ì§‘ì¤‘
                'orderBy': 'recent'  # ìµœì‹ ìˆœ
            }
            
            # HTTP ì‚¬ìš© (HTTPS ì•„ë‹˜)
            response = requests.post(
                self.api_base_url,
                headers=self.headers,
                json=params,
                timeout=30
            )
            
            logging.info(f"API ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            
            if response.status_code == 200:
                try:
                    # ì‘ë‹µ í…ìŠ¤íŠ¸ í™•ì¸
                    response_text = response.text
                    if not response_text:
                        logging.warning("ë¹ˆ ì‘ë‹µ ë°›ìŒ")
                        return self.scrape_announcements()
                    
                    data = response.json()
                    if 'resultList' in data:
                        logging.info(f"K-Startup API ì¡°íšŒ ì„±ê³µ: {len(data['resultList'])}ê°œ")
                        return data['resultList']
                    else:
                        logging.info("ì¡°íšŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                        return self.scrape_announcements()
                except json.JSONDecodeError as e:
                    logging.error(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                    logging.error(f"ì‘ë‹µ ë‚´ìš©: {response.text[:500]}")
                    return self.scrape_announcements()
            else:
                logging.error(f"API ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                return self.scrape_announcements()
                
        except Exception as e:
            logging.error(f"API ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return self.scrape_announcements()
    
    def scrape_announcements(self):
        """ì›¹ ìŠ¤í¬ë˜í•‘ (API ì‹¤íŒ¨ ì‹œ ëŒ€ì²´)"""
        try:
            from bs4 import BeautifulSoup
            
            logging.info("ì›¹ ìŠ¤í¬ë˜í•‘ ì‹œì‘...")
            # ì›¹í˜ì´ì§€ëŠ” HTTPS ì‚¬ìš©
            url = "https://www.k-startup.go.kr/web/contents/bizpbanc-ongoing.do"
            response = requests.get(url, headers=self.headers, timeout=30)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                announcements = []
                
                # ê³µê³  ëª©ë¡ íŒŒì‹± - ë” ë‹¤ì–‘í•œ ì„ íƒì ì‹œë„
                items = (soup.find_all('div', class_='ann_list_item') or 
                        soup.find_all('li', class_='item') or
                        soup.find_all('div', class_='list_item') or
                        soup.find_all('article', class_='item'))
                
                if not items:
                    # í…Œì´ë¸” í˜•ì‹ì¼ ê²½ìš°
                    table = soup.find('table', class_=['table', 'list', 'board'])
                    if table:
                        items = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸
                
                logging.info(f"ë°œê²¬ëœ í•­ëª© ìˆ˜: {len(items)}")
                
                for idx, item in enumerate(items[:50], 1):  # ìµœëŒ€ 50ê°œ
                    try:
                        # ì œëª© ì°¾ê¸°
                        title_elem = (item.find('a', class_=['title', 'tit', 'subject']) or
                                     item.find('h3') or item.find('h4') or 
                                     item.find('a'))
                        
                        if not title_elem:
                            continue
                        
                        title = title_elem.get_text(strip=True)
                        href = title_elem.get('href', '')
                        
                        # ID ìƒì„±
                        item_id = item.get('data-id') or item.get('id') or f"{datetime.now().strftime('%Y%m%d')}_{idx}"
                        
                        announcement = {
                            'bizPbancSn': item_id,
                            'bizPbancNm': title,
                            'pbancNtrpNm': self.extract_text(item, ['org', 'agency', 'company']),
                            'pbancRcptBgngDt': self.extract_date(item, 'start'),
                            'pbancRcptEndDt': self.extract_date(item, 'end'),
                            'detlPgUrl': urljoin(url, href) if href else ''
                        }
                        
                        if announcement['bizPbancNm']:  # ì œëª©ì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                            announcements.append(announcement)
                            logging.info(f"  ìŠ¤í¬ë˜í•‘: {announcement['bizPbancNm'][:30]}...")
                            
                    except Exception as e:
                        logging.error(f"í•­ëª© íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
                
                logging.info(f"ì›¹ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(announcements)}ê°œ")
                return announcements
            else:
                logging.error(f"ì›¹ í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨: {response.status_code}")
                return []
                
        except Exception as e:
            logging.error(f"ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
            return []
    
    def extract_text(self, element, class_names):
        """í…ìŠ¤íŠ¸ ì¶”ì¶œ í—¬í¼"""
        for class_name in class_names:
            elem = element.find(['span', 'div', 'td'], class_=class_name)
            if elem:
                return elem.get_text(strip=True)
        return ''
    
    def extract_date(self, element, date_type):
        """ë‚ ì§œ ì¶”ì¶œ í—¬í¼"""
        try:
            date_elem = element.find(['span', 'div', 'td'], class_=['date', 'period', 'term'])
            if date_elem:
                date_text = date_elem.get_text(strip=True)
                if '~' in date_text:
                    dates = date_text.split('~')
                    if date_type == 'start':
                        return dates[0].strip().replace('.', '-')
                    else:
                        return dates[1].strip().replace('.', '-')
            return None
        except:
            return None
    
    def save_to_database(self, announcements):
        """ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ (ìµœì í™”)"""
        if not announcements:
            logging.info("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return 0
        
        # 1. ê¸°ì¡´ ID í•œ ë²ˆì— ì¡°íšŒ
        logging.info("ê¸°ì¡´ ë°ì´í„° í™•ì¸ ì¤‘...")
        existing_result = self.supabase.table('kstartup_complete').select('announcement_id').execute()
        existing_ids = {item['announcement_id'] for item in existing_result.data} if existing_result.data else set()
        logging.info(f"ê¸°ì¡´ ë°ì´í„°: {len(existing_ids)}ê°œ")
        
        # 2. ì‹ ê·œ ë°ì´í„°ë§Œ í•„í„°ë§
        new_records = []
        duplicate_count = 0
        
        for ann in announcements:
            # announcement_id ìƒì„±
            announcement_id = f"KS_{ann.get('bizPbancSn', '')}"
            
            # ë©”ëª¨ë¦¬ì—ì„œ ì¤‘ë³µ ì²´í¬
            if announcement_id in existing_ids:
                duplicate_count += 1
                if duplicate_count <= 5:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
                    logging.info(f"  â­ï¸ ì¤‘ë³µ: {ann.get('bizPbancNm', '')[:30]}...")
                continue
            
            # ì‹ ê·œ ë ˆì½”ë“œ ìƒì„±
            record = {
                'announcement_id': announcement_id,
                'biz_pbanc_nm': ann.get('bizPbancNm', ''),
                'pbanc_ctnt': ann.get('pbancCtnt', ''),
                'supt_biz_clsfc': ann.get('suptBizClsfc', ''),
                'aply_trgt_ctnt': ann.get('aplyTrgtCtnt', ''),
                'supt_regin': ann.get('suptRegin', ''),
                'pbanc_rcpt_bgng_dt': self.parse_date(ann.get('pbancRcptBgngDt')),
                'pbanc_rcpt_end_dt': self.parse_date(ann.get('pbancRcptEndDt')),
                'pbanc_ntrp_nm': ann.get('pbancNtrpNm', ''),
                'biz_gdnc_url': ann.get('bizGdncUrl', ''),
                'biz_aply_url': ann.get('bizAplyUrl', ''),
                'detl_pg_url': ann.get('detlPgUrl', ''),
                'attachment_urls': [],
                'attachment_count': 0,
                'created_at': datetime.now().isoformat()
            }
            
            new_records.append(record)
            logging.info(f"  âœ… ì‹ ê·œ: {record['biz_pbanc_nm'][:30]}...")
        
        # 3. ë°°ì¹˜ ì €ì¥
        success_count = 0
        error_count = 0
        
        if new_records:
            logging.info(f"\në°°ì¹˜ ì €ì¥ ì¤‘... ({len(new_records)}ê°œ)")
            try:
                # K-Startupì€ ë³´í†µ 50ê°œ ì´í•˜ë¼ í•œ ë²ˆì— ì €ì¥ ê°€ëŠ¥
                result = self.supabase.table('kstartup_complete').insert(new_records).execute()
                if result.data:
                    success_count = len(result.data)
                    logging.info(f"  ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {success_count}ê°œ")
            except Exception as e:
                # ì‹¤íŒ¨ ì‹œ ê°œë³„ ì €ì¥ìœ¼ë¡œ fallback
                logging.error(f"ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨, ê°œë³„ ì €ì¥ ì‹œë„: {e}")
                for record in new_records:
                    try:
                        result = self.supabase.table('kstartup_complete').insert(record).execute()
                        if result.data:
                            success_count += 1
                    except Exception as e2:
                        error_count += 1
                        logging.error(f"  ê°œë³„ ì €ì¥ ì˜¤ë¥˜: {e2}")
        
        # ê²°ê³¼ ìš”ì•½
        logging.info("\n=== ìˆ˜ì§‘ ê²°ê³¼ ===")
        logging.info(f"âœ… ì‹ ê·œ ì €ì¥: {success_count}ê°œ")
        logging.info(f"â­ï¸ ì¤‘ë³µ ì œì™¸: {duplicate_count}ê°œ")
        if error_count > 0:
            logging.info(f"âŒ ì˜¤ë¥˜: {error_count}ê°œ")
        logging.info(f"ğŸ“Š ì „ì²´ ì²˜ë¦¬: {len(announcements)}ê°œ")
        
        return success_count
    
    def parse_date(self, date_str):
        """ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹±"""
        if not date_str:
            return None
        
        try:
            # ë‹¤ì–‘í•œ í˜•ì‹ ì²˜ë¦¬
            date_str = date_str.strip()
            
            # 2025-08-08 í˜•ì‹
            if '-' in date_str:
                return datetime.strptime(date_str[:10], '%Y-%m-%d').date().isoformat()
            
            # 2025.08.08 í˜•ì‹
            elif '.' in date_str:
                date_str = date_str.replace('.', '-')
                return datetime.strptime(date_str[:10], '%Y-%m-%d').date().isoformat()
            
            # 20250808 í˜•ì‹
            elif len(date_str) == 8 and date_str.isdigit():
                return datetime.strptime(date_str, '%Y%m%d').date().isoformat()
            
            return None
        except:
            return None
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        try:
            # 1. ê³µê³  ëª©ë¡ ì¡°íšŒ
            announcements = self.fetch_announcements()
            
            if not announcements:
                logging.info("ìˆ˜ì§‘í•  ìƒˆë¡œìš´ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
                # ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¼ë„ ì •ìƒ ì¢…ë£Œ
                return True
            
            # 2. DB ì €ì¥
            saved_count = self.save_to_database(announcements)
            
            # 3. ì„±ê³µ ì—¬ë¶€ ë°˜í™˜
            return True  # ì—ëŸ¬ê°€ ì—†ìœ¼ë©´ ì„±ê³µ
            
        except Exception as e:
            logging.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

if __name__ == "__main__":
    collector = KStartupCollector()
    success = collector.run()
    sys.exit(0 if success else 1)
