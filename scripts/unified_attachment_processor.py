#!/usr/bin/env python3
"""
í†µí•© ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ê¸° (Unified Attachment Processor)
K-Startupê³¼ BizInfo ëª¨ë‘ ì²˜ë¦¬ ê°€ëŠ¥í•œ ë‹¨ì¼ ëª¨ë“ˆ

ì£¼ìš” ê¸°ëŠ¥:
- ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§
- ì²¨ë¶€íŒŒì¼ ì •ë³´ ì¶”ì¶œ (íŒŒì¼ëª…, URL, íƒ€ì…, í¬ê¸°)
- HEAD ìš”ì²­ìœ¼ë¡œ ì‹¤ì œ íŒŒì¼ ì •ë³´ í™•ì¸
- íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ë¡œ ì •í™•í•œ íƒ€ì… íŒë³„
- ì¸ì½”ë”© ë¬¸ì œ ìë™ ì²˜ë¦¬
- ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
"""

import os
import sys
import json
import time
import re
import requests
import logging
from datetime import datetime, timedelta
from urllib.parse import unquote, urlparse, urljoin
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from typing import List, Dict, Optional, Tuple
from supabase import create_client
from dotenv import load_dotenv

# UTF-8 ì¶œë ¥ ì„¤ì •
sys.stdout.reconfigure(encoding='utf-8')

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
log_filename = f'unified_attachment_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(threadName)s] - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filename, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ì „ì—­ ì§„í–‰ ìƒí™©
lock = threading.Lock()
stats = {
    'total': 0,
    'processed': 0,
    'success': 0,
    'error': 0,
    'skip': 0,
    'attachments_found': 0,
    'attachments_updated': 0
}


class UnifiedAttachmentProcessor:
    """í†µí•© ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, source_type: str = 'auto'):
        """
        ì´ˆê¸°í™”
        
        Args:
            source_type: 'kstartup', 'bizinfo', ë˜ëŠ” 'auto' (ìë™ ê°ì§€)
        """
        self.source_type = source_type
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # Supabase ì—°ê²°
        url = os.environ.get('SUPABASE_URL')
        key = os.environ.get('SUPABASE_KEY') or os.environ.get('SUPABASE_SERVICE_KEY')
        
        if not url or not key:
            raise ValueError("SUPABASE_URLê³¼ SUPABASE_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        self.supabase = create_client(url, key)
        
    def get_file_signature(self, url: str, max_bytes: int = 1024) -> Optional[bytes]:
        """íŒŒì¼ì˜ ì²˜ìŒ ë¶€ë¶„ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì‹œê·¸ë‹ˆì²˜ í™•ì¸"""
        try:
            # Range í—¤ë”ë¡œ ë¶€ë¶„ ë‹¤ìš´ë¡œë“œ
            headers = {'Range': f'bytes=0-{max_bytes}'}
            response = self.session.get(url, headers=headers, timeout=10, stream=True)
            
            if response.status_code in [200, 206]:
                return response.content[:max_bytes]
        except Exception as e:
            logger.debug(f"ì‹œê·¸ë‹ˆì²˜ í™•ì¸ ì‹¤íŒ¨: {url} - {e}")
        
        return None
    
    def detect_file_type(self, content: bytes) -> str:
        """íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ë¡œ íƒ€ì… íŒë³„"""
        signatures = {
            # ë¬¸ì„œ íŒŒì¼
            b'%PDF': 'PDF',
            b'\xd0\xcf\x11\xe0': 'DOC',  # MS Office
            b'PK\x03\x04': 'ZIP',  # ZIP ê¸°ë°˜ (DOCX, XLSX, PPTX, ZIP ë“±)
            b'HWP Document': 'HWP',
            b'{\rtf': 'RTF',  # Rich Text Format
            
            # ì´ë¯¸ì§€ íŒŒì¼
            b'\x89PNG': 'PNG',
            b'\xff\xd8\xff': 'JPG',
            b'GIF87a': 'GIF',
            b'GIF89a': 'GIF',
            b'BM': 'BMP',
            b'II\x2a\x00': 'TIFF',  # Little-endian
            b'MM\x00\x2a': 'TIFF',  # Big-endian
            b'RIFF': 'WEBP',  # WebP ì´ë¯¸ì§€
            
            # ì••ì¶• íŒŒì¼
            b'Rar!': 'RAR',
            b'7z\xbc\xaf': '7Z',
            b'\x1f\x8b': 'GZ',  # GZIP
            b'BZh': 'BZ2',  # BZIP2
            b'\x50\x4b\x03\x04': 'ZIP',  # ì¼ë°˜ ZIP
            b'\x50\x4b\x05\x06': 'ZIP',  # ë¹ˆ ZIP
            b'\x50\x4b\x07\x08': 'ZIP',  # Spanned ZIP
            
            # ë™ì˜ìƒ íŒŒì¼
            b'\x00\x00\x00\x14ftypM4V': 'MP4',
            b'\x00\x00\x00\x18ftypmp4': 'MP4',
            b'\x00\x00\x00\x20ftypM4V': 'M4V',
            b'\x1a\x45\xdf\xa3': 'MKV',  # Matroska
            b'RIFF': 'AVI',  # AVI (RIFF ê¸°ë°˜)
            b'FLV': 'FLV',  # Flash Video
            
            # ì˜¤ë””ì˜¤ íŒŒì¼
            b'ID3': 'MP3',
            b'\xff\xfb': 'MP3',  # MP3 without ID3
            b'OggS': 'OGG',
            b'fLaC': 'FLAC',
            b'FORM': 'AIFF',
            
            # ì›¹ íŒŒì¼
            b'<?xml': 'XML',
            b'<html': 'HTML',
            b'<!DOCTYPE': 'HTML',
            b'<HTML': 'HTML',
            b'<!doctype': 'HTML',
            
            # ì‹¤í–‰ íŒŒì¼
            b'MZ': 'EXE',  # Windows executable
            b'\x7fELF': 'ELF',  # Linux executable
            b'\xca\xfe\xba\xbe': 'CLASS',  # Java class
            b'\xfe\xed\xfa': 'MACH-O',  # Mac executable
        }
        
        # ì‹œê·¸ë‹ˆì²˜ ì²´í¬
        for sig, file_type in signatures.items():
            if content.startswith(sig):
                # ZIP ê¸°ë°˜ íŒŒì¼ ì„¸ë¶„í™”
                if file_type == 'ZIP':
                    # Office 2007+ íŒŒì¼ë“¤
                    if b'word/' in content or b'docProps' in content:
                        return 'DOCX'
                    elif b'xl/' in content or b'worksheets' in content:
                        return 'XLSX'
                    elif b'ppt/' in content or b'slides' in content:
                        return 'PPTX'
                    # í•œì»´ ì˜¤í”¼ìŠ¤
                    elif b'mimetype' in content[:100]:
                        if b'hwp+zip' in content[:200]:
                            return 'HWPX'
                        elif b'hcell' in content[:200]:
                            return 'CELL'
                        elif b'hshow' in content[:200]:
                            return 'SHOW'
                    # JAR íŒŒì¼
                    elif b'META-INF/' in content[:100]:
                        return 'JAR'
                    # APK íŒŒì¼
                    elif b'AndroidManifest.xml' in content[:1000]:
                        return 'APK'
                    return 'ZIP'
                
                # RIFF ê¸°ë°˜ íŒŒì¼ êµ¬ë¶„
                elif file_type == 'WEBP':
                    if content[8:12] == b'WEBP':
                        return 'WEBP'
                    elif content[8:12] == b'AVI ':
                        return 'AVI'
                    elif content[8:12] == b'WAVE':
                        return 'WAV'
                
                return file_type
        
        # HWP ì¶”ê°€ ì²´í¬ (êµ¬ë²„ì „)
        if b'HWP' in content[:1000] or b'Hwp' in content[:1000]:
            return 'HWP'
        
        # CSV ì²´í¬ (ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ í…ìŠ¤íŠ¸)
        try:
            text = content[:500].decode('utf-8')
            if text.count(',') > 5 and '\n' in text:
                return 'CSV'
            # JSON ì²´í¬
            if text.strip().startswith(('{', '[')):
                import json
                try:
                    json.loads(text)
                    return 'JSON'
                except:
                    pass
            # ì¼ë°˜ í…ìŠ¤íŠ¸
            return 'TXT'
        except:
            pass
        
        return 'UNKNOWN'
    
    def extract_filename_from_header(self, headers: dict) -> Optional[str]:
        """ì‘ë‹µ í—¤ë”ì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ"""
        disposition = headers.get('Content-Disposition', '')
        if not disposition:
            return None
        
        filename = None
        
        # filename*=UTF-8'' í˜•ì‹ (RFC 5987)
        if "filename*=" in disposition:
            match = re.search(r"filename\*=UTF-8''([^;]+)", disposition, re.IGNORECASE)
            if match:
                filename = unquote(match.group(1))
        
        # filename="..." í˜•ì‹
        if not filename and 'filename=' in disposition:
            match = re.search(r'filename="?([^";\\n]+)"?', disposition, re.IGNORECASE)
            if match:
                filename = match.group(1)
                # ì¸ì½”ë”© ì²˜ë¦¬
                try:
                    # UTF-8 í™•ì¸
                    filename.encode('utf-8')
                except:
                    # Latin-1 â†’ UTF-8 ë³€í™˜
                    try:
                        filename = filename.encode('latin-1').decode('utf-8')
                    except:
                        # EUC-KR â†’ UTF-8 ë³€í™˜
                        try:
                            filename = filename.encode('latin-1').decode('euc-kr')
                        except:
                            pass
        
        return filename
    
    def get_file_info_from_url(self, url: str) -> Dict:
        """URLì—ì„œ íŒŒì¼ ì •ë³´ ì¶”ì¶œ (Content-Type ìš°ì„ )"""
        info = {
            'url': url,
            'name': None,
            'type': 'UNKNOWN',
            'size': None,
            'content_type': None,
            'error': None
        }
        
        try:
            # HEAD ìš”ì²­ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° í™•ì¸
            response = self.session.head(url, timeout=10, allow_redirects=True)
            
            # 1ë‹¨ê³„: Content-Type í—¤ë”ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì²´í¬
            content_type = response.headers.get('Content-Type', '').lower()
            info['content_type'] = content_type  # ë””ë²„ê¹…ìš© ì €ì¥
            
            # í™•ì¥ëœ MIME íƒ€ì… ë§¤í•‘ (ë” ë§ì€ ë³€í˜• í¬í•¨)
            mime_to_type = {
                # ë¬¸ì„œ - ê°€ì¥ ì¼ë°˜ì ì¸ ê²ƒë“¤
                'application/pdf': 'PDF',
                'application/x-pdf': 'PDF',
                'application/x-hwp': 'HWP',
                'application/haansoft-hwp': 'HWP',
                'application/hwp': 'HWP',
                'application/x-hwpml': 'HWPX',
                'application/msword': 'DOC',
                'application/vnd.openxmlformats-officedocument.wordprocessingml': 'DOCX',
                'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'DOCX',
                'application/vnd.ms-excel': 'XLS',
                'application/vnd.openxmlformats-officedocument.spreadsheetml': 'XLSX',
                'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': 'XLSX',
                'application/vnd.ms-powerpoint': 'PPT',
                'application/vnd.openxmlformats-officedocument.presentationml': 'PPTX',
                'application/vnd.openxmlformats-officedocument.presentationml.presentation': 'PPTX',
                'text/plain': 'TXT',
                'text/csv': 'CSV',
                'application/csv': 'CSV',
                'application/xml': 'XML',
                'text/xml': 'XML',
                'application/json': 'JSON',
                'text/json': 'JSON',
                'text/html': 'HTML',
                'application/rtf': 'RTF',
                'text/rtf': 'RTF',
                
                # ì´ë¯¸ì§€
                'image/jpeg': 'JPG',
                'image/jpg': 'JPG',
                'image/pjpeg': 'JPG',  # Progressive JPEG
                'image/png': 'PNG',
                'image/x-png': 'PNG',
                'image/gif': 'GIF',
                'image/bmp': 'BMP',
                'image/x-ms-bmp': 'BMP',
                'image/tiff': 'TIFF',
                'image/x-tiff': 'TIFF',
                'image/webp': 'WEBP',
                'image/svg+xml': 'SVG',
                'image/svg': 'SVG',
                'image/x-icon': 'ICO',
                'image/vnd.microsoft.icon': 'ICO',
                
                # ì••ì¶•
                'application/zip': 'ZIP',
                'application/x-zip-compressed': 'ZIP',
                'application/x-zip': 'ZIP',
                'multipart/x-zip': 'ZIP',
                'application/x-rar-compressed': 'RAR',
                'application/vnd.rar': 'RAR',
                'application/x-rar': 'RAR',
                'application/x-7z-compressed': '7Z',
                'application/x-tar': 'TAR',
                'application/gzip': 'GZ',
                'application/x-gzip': 'GZ',
                'application/x-bzip2': 'BZ2',
                'application/x-bzip': 'BZ2',
                'application/x-xz': 'XZ',
                
                # ë™ì˜ìƒ
                'video/mp4': 'MP4',
                'video/x-m4v': 'MP4',
                'video/x-msvideo': 'AVI',
                'video/avi': 'AVI',
                'video/x-matroska': 'MKV',
                'video/quicktime': 'MOV',
                'video/x-quicktime': 'MOV',
                'video/webm': 'WEBM',
                'video/x-flv': 'FLV',
                'video/x-ms-wmv': 'WMV',
                'video/mpeg': 'MPEG',
                
                # ì˜¤ë””ì˜¤
                'audio/mpeg': 'MP3',
                'audio/mp3': 'MP3',
                'audio/wav': 'WAV',
                'audio/x-wav': 'WAV',
                'audio/wave': 'WAV',
                'audio/flac': 'FLAC',
                'audio/x-flac': 'FLAC',
                'audio/aac': 'AAC',
                'audio/ogg': 'OGG',
                'audio/vorbis': 'OGG',
                'audio/x-ms-wma': 'WMA',
                'audio/mp4': 'M4A',
                'audio/x-m4a': 'M4A',
            }
            
            # Content-Typeìœ¼ë¡œ ì •í™•í•œ íƒ€ì… íŒë³„
            if content_type:
                # charset ì œê±° (ì˜ˆ: "application/pdf; charset=utf-8" â†’ "application/pdf")
                content_type_clean = content_type.split(';')[0].strip()
                
                # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
                if content_type_clean in mime_to_type:
                    info['type'] = mime_to_type[content_type_clean]
                else:
                    # ë¶€ë¶„ ë§¤ì¹­ìœ¼ë¡œ í´ë°±
                    for mime, file_type in mime_to_type.items():
                        if mime in content_type:
                            info['type'] = file_type
                            break
            
                # ì¼ë°˜ì ì¸ íŒ¨í„´ìœ¼ë¡œ ì¶”ê°€ íŒë³„
                if info['type'] == 'UNKNOWN':
                    if 'pdf' in content_type:
                        info['type'] = 'PDF'
                    elif 'hwp' in content_type or 'haansoft' in content_type:
                        info['type'] = 'HWP'
                    elif 'word' in content_type:
                        info['type'] = 'DOCX' if 'openxml' in content_type else 'DOC'
                    elif 'excel' in content_type or 'spreadsheet' in content_type:
                        info['type'] = 'XLSX' if 'openxml' in content_type else 'XLS'
                    elif 'powerpoint' in content_type or 'presentation' in content_type:
                        info['type'] = 'PPTX' if 'openxml' in content_type else 'PPT'
                    elif 'image/' in content_type:
                        info['type'] = 'IMAGE'
                    elif 'video/' in content_type:
                        info['type'] = 'VIDEO'
                    elif 'audio/' in content_type:
                        info['type'] = 'AUDIO'
                    elif 'text/' in content_type:
                        info['type'] = 'TXT'
                    elif 'application/octet-stream' in content_type:
                        # ë°”ì´ë„ˆë¦¬ ìŠ¤íŠ¸ë¦¼ì¸ ê²½ìš° í™•ì¥ìë‚˜ ì‹œê·¸ë‹ˆì²˜ë¡œ íŒë‹¨ í•„ìš”
                        info['type'] = 'BINARY'
            
            # 2ë‹¨ê³„: íŒŒì¼ëª… ì¶”ì¶œ ë° í™•ì¥ì ì²´í¬
            filename = self.extract_filename_from_header(response.headers)
            if filename:
                info['name'] = filename
                
                # Content-Typeì´ ë¶ˆëª…í™•í•œ ê²½ìš° í™•ì¥ìë¡œ ë³´ì™„
                if info['type'] in ['UNKNOWN', 'BINARY']:
                    ext = filename.split('.')[-1].upper() if '.' in filename else ''
                    
                    # ì§€ì›í•˜ëŠ” ëª¨ë“  í™•ì¥ì
                    ext_to_type = {
                        # ë¬¸ì„œ
                        'PDF': 'PDF', 'HWP': 'HWP', 'HWPX': 'HWPX', 'DOC': 'DOC', 'DOCX': 'DOCX',
                        'XLS': 'XLS', 'XLSX': 'XLSX', 'PPT': 'PPT', 'PPTX': 'PPTX',
                        'TXT': 'TXT', 'RTF': 'RTF', 'CSV': 'CSV', 'XML': 'XML', 'JSON': 'JSON',
                        'HTML': 'HTML', 'HTM': 'HTML', 'CELL': 'CELL', 'SHOW': 'SHOW',
                        # ì´ë¯¸ì§€
                        'JPG': 'JPG', 'JPEG': 'JPG', 'PNG': 'PNG', 'GIF': 'GIF', 'BMP': 'BMP',
                        'TIFF': 'TIFF', 'TIF': 'TIFF', 'WEBP': 'WEBP', 'SVG': 'SVG', 'ICO': 'ICO',
                        # ì••ì¶•
                        'ZIP': 'ZIP', 'RAR': 'RAR', '7Z': '7Z', 'TAR': 'TAR', 'GZ': 'GZ',
                        'BZ2': 'BZ2', 'XZ': 'XZ', 'ARJ': 'ARJ', 'CAB': 'CAB', 'ISO': 'ISO',
                        # ë™ì˜ìƒ
                        'MP4': 'MP4', 'AVI': 'AVI', 'MKV': 'MKV', 'MOV': 'MOV', 'WMV': 'WMV',
                        'FLV': 'FLV', 'WEBM': 'WEBM', 'M4V': 'MP4', 'MPG': 'MPEG', 'MPEG': 'MPEG',
                        # ì˜¤ë””ì˜¤
                        'MP3': 'MP3', 'WAV': 'WAV', 'FLAC': 'FLAC', 'AAC': 'AAC', 'OGG': 'OGG',
                        'WMA': 'WMA', 'M4A': 'M4A', 'AIFF': 'AIFF', 'APE': 'APE',
                    }
                    
                    if ext in ext_to_type:
                        info['type'] = ext_to_type[ext]
            
            # íŒŒì¼ í¬ê¸°
            content_length = response.headers.get('Content-Length')
            if content_length:
                info['size'] = int(content_length)
            
            # 3ë‹¨ê³„: ì—¬ì „íˆ UNKNOWNì´ë©´ íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ë¡œ ì •í™•í•œ íƒ€ì… í™•ì¸
            if info['type'] in ['UNKNOWN', 'BINARY']:
                content = self.get_file_signature(url)
                if content:
                    detected_type = self.detect_file_type(content)
                    if detected_type != 'UNKNOWN':
                        info['type'] = detected_type
            
            # íŒŒì¼ëª…ì´ ì—†ìœ¼ë©´ URLì—ì„œ ì¶”ì¶œ
            if not info['name']:
                parsed_url = urlparse(url)
                path_parts = parsed_url.path.split('/')
                if path_parts and path_parts[-1]:
                    info['name'] = unquote(path_parts[-1])
            
        except Exception as e:
            info['error'] = str(e)
            logger.debug(f"íŒŒì¼ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {url} - {e}")
        
        return info
    
    def extract_kstartup_attachments(self, detail_url: str) -> List[Dict]:
        """K-Startup ìƒì„¸ í˜ì´ì§€ì—ì„œ ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ"""
        attachments = []
        
        try:
            response = self.session.get(detail_url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ì²¨ë¶€íŒŒì¼ ì˜ì—­ ì°¾ê¸° (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
            patterns = [
                soup.find_all('a', {'class': re.compile('file|attach|download', re.I)}),
                soup.find_all('a', href=re.compile(r'\.(pdf|hwp|doc|docx|xls|xlsx|ppt|pptx|zip)', re.I)),
                soup.select('.file-list a, .attach-list a, .download-list a'),
                soup.find_all('a', text=re.compile(r'\.(pdf|hwp|doc|docx|xls|xlsx|ppt|pptx|zip)', re.I))
            ]
            
            found_links = set()
            for links in patterns:
                for link in links:
                    href = link.get('href')
                    if href and href not in found_links:
                        found_links.add(href)
                        
                        # ì ˆëŒ€ URLë¡œ ë³€í™˜
                        file_url = urljoin(detail_url, href)
                        
                        # íŒŒì¼ ì •ë³´ ì¶”ì¶œ
                        file_info = self.get_file_info_from_url(file_url)
                        
                        # ë§í¬ í…ìŠ¤íŠ¸ì—ì„œ íŒŒì¼ëª… íŒíŠ¸
                        if not file_info['name']:
                            link_text = link.get_text(strip=True)
                            if link_text and not link_text.startswith('http'):
                                file_info['name'] = link_text
                        
                        attachments.append(file_info)
            
        except Exception as e:
            logger.error(f"K-Startup ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ ì‹¤íŒ¨: {detail_url} - {e}")
        
        return attachments
    
    def extract_bizinfo_attachments(self, detail_url: str) -> List[Dict]:
        """BizInfo ìƒì„¸ í˜ì´ì§€ì—ì„œ ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ"""
        attachments = []
        
        try:
            response = self.session.get(detail_url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # BizInfo íŠ¹ìœ ì˜ ì²¨ë¶€íŒŒì¼ êµ¬ì¡°
            # 1. div.file_nameì—ì„œ ì •í™•í•œ íŒŒì¼ëª…
            file_divs = soup.find_all('div', class_='file_name')
            for div in file_divs:
                filename = div.get_text(strip=True)
                # ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ê¸°
                parent = div.parent
                if parent:
                    link = parent.find('a', href=True)
                    if link:
                        file_url = urljoin(detail_url, link['href'])
                        file_info = self.get_file_info_from_url(file_url)
                        if filename:
                            file_info['name'] = filename
                        attachments.append(file_info)
            
            # 2. viewer.do í˜•ì‹ ë§í¬
            viewer_links = soup.find_all('a', href=re.compile(r'viewer\.do\?', re.I))
            for link in viewer_links:
                file_url = urljoin(detail_url, link['href'])
                file_info = self.get_file_info_from_url(file_url)
                
                # title ì†ì„±ì—ì„œ íŒŒì¼ëª…
                if link.get('title'):
                    file_info['name'] = link['title']
                elif not file_info['name']:
                    file_info['name'] = link.get_text(strip=True)
                
                attachments.append(file_info)
            
            # 3. ì¼ë°˜ ë‹¤ìš´ë¡œë“œ ë§í¬
            download_links = soup.find_all('a', href=re.compile(r'download|fileDown', re.I))
            for link in download_links:
                file_url = urljoin(detail_url, link['href'])
                if not any(att['url'] == file_url for att in attachments):
                    file_info = self.get_file_info_from_url(file_url)
                    if not file_info['name']:
                        file_info['name'] = link.get_text(strip=True)
                    attachments.append(file_info)
            
        except Exception as e:
            logger.error(f"BizInfo ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ ì‹¤íŒ¨: {detail_url} - {e}")
        
        return attachments
    
    def process_record(self, record: Dict) -> bool:
        """ë‹¨ì¼ ë ˆì½”ë“œ ì²˜ë¦¬"""
        try:
            record_id = record.get('id')
            announcement_id = record.get('announcement_id') or record.get('pblanc_sn')
            detail_url = record.get('pblanc_url') or record.get('detl_pg_url')
            
            if not detail_url:
                logger.debug(f"ìƒì„¸ URL ì—†ìŒ: ID {record_id}")
                return False
            
            # ì´ë¯¸ ì²˜ë¦¬ëœ ê²½ìš° ìŠ¤í‚µ
            if record.get('attachment_processing_status') == 'completed':
                existing_urls = record.get('attachment_urls')
                if existing_urls:
                    try:
                        parsed = json.loads(existing_urls) if isinstance(existing_urls, str) else existing_urls
                        if isinstance(parsed, list) and len(parsed) > 0:
                            with lock:
                                stats['skip'] += 1
                            return False
                    except:
                        pass
            
            # ì†ŒìŠ¤ íƒ€ì… ìë™ ê°ì§€
            if self.source_type == 'auto':
                if 'k-startup' in detail_url.lower():
                    source = 'kstartup'
                elif 'bizinfo' in detail_url.lower():
                    source = 'bizinfo'
                else:
                    # í…Œì´ë¸”ëª…ìœ¼ë¡œ íŒë‹¨
                    source = 'kstartup' if 'KS_' in str(announcement_id) else 'bizinfo'
            else:
                source = self.source_type
            
            # ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ
            if source == 'kstartup':
                attachments = self.extract_kstartup_attachments(detail_url)
            else:
                attachments = self.extract_bizinfo_attachments(detail_url)
            
            # ê²°ê³¼ ì €ì¥
            update_data = {
                'attachment_urls': json.dumps(attachments, ensure_ascii=False),
                'attachment_processing_status': 'completed' if attachments else 'no_attachments',
                'attachment_processed_at': datetime.now().isoformat(),
                'attachment_count': len(attachments)
            }
            
            # í…Œì´ë¸” ì„ íƒ
            table_name = 'kstartup_complete' if source == 'kstartup' else 'bizinfo_complete'
            
            # ì—…ë°ì´íŠ¸
            self.supabase.table(table_name).update(update_data).eq('id', record_id).execute()
            
            with lock:
                stats['success'] += 1
                if attachments:
                    stats['attachments_found'] += len(attachments)
                    stats['attachments_updated'] += 1
            
            logger.info(f"ì²˜ë¦¬ ì™„ë£Œ: ID {record_id} - {len(attachments)}ê°œ ì²¨ë¶€íŒŒì¼")
            return True
            
        except Exception as e:
            logger.error(f"ë ˆì½”ë“œ ì²˜ë¦¬ ì‹¤íŒ¨: {record.get('id')} - {e}")
            with lock:
                stats['error'] += 1
            return False
    
    def process_batch(self, source: str = 'both', mode: str = 'daily', max_workers: int = 5):
        """ë°°ì¹˜ ì²˜ë¦¬"""
        logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: source={source}, mode={mode}")
        
        # ì²˜ë¦¬í•  ë ˆì½”ë“œ ì¡°íšŒ
        records = []
        
        if source in ['kstartup', 'both']:
            query = self.supabase.table('kstartup_complete').select('*')
            
            # ì²˜ë¦¬ ì•ˆ ëœ ê²ƒ ìš°ì„ 
            query = query.is_('attachment_processing_status', None)
            
            if mode == 'daily':
                # ìµœê·¼ 7ì¼
                week_ago = (datetime.now() - timedelta(days=7)).isoformat()
                query = query.gte('created_at', week_ago)
            
            result = query.limit(1000).execute()
            if result.data:
                records.extend(result.data)
                logger.info(f"K-Startup: {len(result.data)}ê°œ ë ˆì½”ë“œ")
        
        if source in ['bizinfo', 'both']:
            query = self.supabase.table('bizinfo_complete').select('*')
            
            # ì²˜ë¦¬ ì•ˆ ëœ ê²ƒ ìš°ì„ 
            query = query.is_('attachment_processing_status', None)
            
            if mode == 'daily':
                # ìµœê·¼ 7ì¼
                week_ago = (datetime.now() - timedelta(days=7)).isoformat()
                query = query.gte('created_at', week_ago)
            
            result = query.limit(1000).execute()
            if result.data:
                records.extend(result.data)
                logger.info(f"BizInfo: {len(result.data)}ê°œ ë ˆì½”ë“œ")
        
        if not records:
            logger.info("ì²˜ë¦¬í•  ë ˆì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        stats['total'] = len(records)
        logger.info(f"ì´ {len(records)}ê°œ ë ˆì½”ë“œ ì²˜ë¦¬ ì‹œì‘")
        
        # ë³‘ë ¬ ì²˜ë¦¬
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = []
            for record in records:
                future = executor.submit(self.process_record, record)
                futures.append(future)
            
            # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
            for future in as_completed(futures):
                with lock:
                    stats['processed'] += 1
                    if stats['processed'] % 10 == 0:
                        logger.info(f"ì§„í–‰: {stats['processed']}/{stats['total']} "
                                  f"(ì„±ê³µ: {stats['success']}, ì‹¤íŒ¨: {stats['error']}, "
                                  f"ìŠ¤í‚µ: {stats['skip']})")
        
        # ìµœì¢… ë³´ê³ 
        logger.info("="*60)
        logger.info("ğŸ“Š ì²˜ë¦¬ ì™„ë£Œ ë³´ê³ ì„œ")
        logger.info("="*60)
        logger.info(f"ì´ ë ˆì½”ë“œ: {stats['total']}ê°œ")
        logger.info(f"ì²˜ë¦¬ ì™„ë£Œ: {stats['processed']}ê°œ")
        logger.info(f"ì„±ê³µ: {stats['success']}ê°œ")
        logger.info(f"ì‹¤íŒ¨: {stats['error']}ê°œ")
        logger.info(f"ìŠ¤í‚µ: {stats['skip']}ê°œ")
        logger.info(f"ë°œê²¬ëœ ì²¨ë¶€íŒŒì¼: {stats['attachments_found']}ê°œ")
        logger.info(f"ì—…ë°ì´íŠ¸ëœ ë ˆì½”ë“œ: {stats['attachments_updated']}ê°œ")
        logger.info("="*60)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='í†µí•© ì²¨ë¶€íŒŒì¼ ì²˜ë¦¬ê¸°')
    parser.add_argument('--source', choices=['kstartup', 'bizinfo', 'both'], 
                       default='both', help='ì²˜ë¦¬í•  ì†ŒìŠ¤')
    parser.add_argument('--mode', choices=['daily', 'full'], 
                       default='daily', help='ì²˜ë¦¬ ëª¨ë“œ')
    parser.add_argument('--workers', type=int, default=5, 
                       help='ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜')
    
    args = parser.parse_args()
    
    # ì²˜ë¦¬ê¸° ì‹¤í–‰
    processor = UnifiedAttachmentProcessor(source_type='auto')
    processor.process_batch(
        source=args.source,
        mode=args.mode,
        max_workers=args.workers
    )


if __name__ == '__main__':
    main()