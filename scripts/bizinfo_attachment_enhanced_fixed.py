#!/usr/bin/env python3
"""
BizInfo ì²¨ë¶€íŒŒì¼ URL ìˆ˜ì§‘ - URLë§Œ ìˆ˜ì§‘
- ì²¨ë¶€íŒŒì¼ URLë§Œ ìˆ˜ì§‘
- íŒŒì¼ëª…ê³¼ íƒ€ì… ì •ë³´ëŠ” ë‹¤ìš´ë¡œë“œ ì‹œ HTTP í—¤ë”ì—ì„œ ì¶”ì¶œ
"""
import sys
sys.stdout.reconfigure(encoding='utf-8')
import os
import requests
from bs4 import BeautifulSoup
import re
from supabase import create_client
from dotenv import load_dotenv
from urllib.parse import urljoin, unquote, urlparse, parse_qs
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

load_dotenv()

# Supabase ì„¤ì • (SERVICE_KEY ìš°ì„  ì‚¬ìš©)
url = os.environ.get('SUPABASE_URL', 'https://csuziaogycciwgxxmahm.supabase.co')
key = os.environ.get('SUPABASE_SERVICE_KEY') or os.environ.get('SUPABASE_KEY')

# í‚¤ê°€ ì—†ìœ¼ë©´ í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©
if not key:
    key = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImNzdXppYW9neWNjaXdneHhtYWhtIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MzYxNTc4MCwiZXhwIjoyMDY5MTkxNzgwfQ.HnhM7zSLzi7lHVPd2IVQKIACDq_YA05mBMgZbSN1c9Q'

supabase = create_client(url, key)

lock = threading.Lock()
progress = {
    'success': 0, 
    'error': 0, 
    'total': 0, 
    'new_files': 0
}


session = requests.Session()
session.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': '*/*',
    'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
    'Referer': 'https://www.bizinfo.go.kr/'
})


def extract_bizinfo_attachments(detail_url, pblanc_id, announcement_title=None):
    """BizInfo ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ"""
    all_attachments = []
    
    try:
        response = session.get(detail_url, timeout=15)
        if response.status_code != 200:
            return []
            
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # BizInfo ì²¨ë¶€íŒŒì¼ íŒ¨í„´ ì°¾ê¸°
        # 1. .fileDown í´ë˜ìŠ¤ ë§í¬ë“¤
        file_links = soup.find_all('a', class_='fileDown')
        
        # 2. onclick="javascript:fnFileDown" íŒ¨í„´
        if not file_links:
            file_links = soup.find_all('a', onclick=re.compile(r'fnFileDown'))
        
        # 3. ì¼ë°˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë§í¬ (href="/jsp/down.jsp" ë“±)
        if not file_links:
            file_links = soup.find_all('a', href=re.compile(r'(down\.jsp|download|file)'))
        
        attachments = []
        
        for idx, link in enumerate(file_links, 1):
            href = link.get('href', '')
            text = link.get_text(strip=True) or ''
            onclick = link.get('onclick', '')
            
            # URL ê²°ì •
            full_url = None
            if href and href.startswith('/'):
                full_url = urljoin('https://www.bizinfo.go.kr', href)
            elif href and href.startswith('http'):
                full_url = href
            elif onclick and 'fnFileDown' in onclick:
                # onclickì—ì„œ íŒŒì¼ ì •ë³´ ì¶”ì¶œ
                match = re.search(r"fnFileDown\('([^']+)'", onclick)
                if match:
                    file_param = match.group(1)
                    full_url = f"https://www.bizinfo.go.kr/jsp/down.jsp?file={file_param}"
            
            if not full_url:
                continue
            
            # URLë§Œ ì €ì¥ (íŒŒì¼ëª…ê³¼ íƒ€ì… ì •ë³´ëŠ” ë‹¤ìš´ë¡œë“œ ì‹œ HTTP í—¤ë”ì—ì„œ ì¶”ì¶œ)
            attachment = {
                'url': full_url
            }
            
            attachments.append(attachment)
        
        all_attachments.extend(attachments)
        
    except Exception as e:
        pass
    
    # ì¤‘ë³µ ì œê±°
    unique_attachments = []
    seen_urls = set()
    for att in all_attachments:
        if att['url'] not in seen_urls:
            seen_urls.add(att['url'])
            unique_attachments.append(att)
    
    return unique_attachments

def process_bizinfo_record(record):
    """BizInfo ë ˆì½”ë“œ ì²˜ë¦¬"""
    pblanc_id = record['pblanc_id']
    detail_url = record.get('detail_url') or record.get('dtl_url')
    title = record.get('pblanc_nm') or record.get('bsns_title', '')
    
    if not detail_url:
        with lock:
            progress['error'] += 1
        return False
    
    try:
        attachments = extract_bizinfo_attachments(detail_url, pblanc_id, title)
        
        if attachments:
            update_data = {'attachment_urls': attachments}
            
            result = supabase.table('bizinfo_complete')\
                .update(update_data)\
                .eq('pblanc_id', pblanc_id)\
                .execute()
            
            if result.data:
                with lock:
                    progress['success'] += 1
                    progress['new_files'] += len(attachments)
                return True
        
        with lock:
            progress['error'] += 1
        return False
        
    except Exception:
        with lock:
            progress['error'] += 1
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("="*70)
    print("ğŸ“ BizInfo ì²¨ë¶€íŒŒì¼ ìˆ˜ì§‘ (ì •í™•í•œ ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜)")
    print("="*70)
    
    # ì²˜ë¦¬ ì œí•œ í™•ì¸
    processing_limit = int(os.environ.get('PROCESSING_LIMIT', '0'))
    
    # ì²˜ë¦¬ ëŒ€ìƒ ì¡°íšŒ - í•­ìƒ ì „ì²´ ì²˜ë¦¬ (í˜ì´ì§€ë„¤ì´ì…˜)
    all_data = []
    page_size = 1000
    offset = 0
    
    while True:
        batch = supabase.table('bizinfo_complete')\
            .select('pblanc_id, pblanc_nm, bsns_title, detail_url, dtl_url, attachment_urls')\
            .range(offset, offset + page_size - 1)\
            .execute()
        
        if not batch.data:
            break
            
        all_data.extend(batch.data)
        print(f"  ë¡œë”©: {len(all_data)}ê°œ...")
        
        if len(batch.data) < page_size:
            break
        offset += page_size
    
    all_records = type('obj', (object,), {'data': all_data})()
    print(f"ğŸ“Œ Full ëª¨ë“œ: ì „ì²´ ë°ì´í„° ì²˜ë¦¬ ({len(all_records.data)}ê°œ)")
    
    needs_processing = []
    
    for record in all_records.data:
        # ì²¨ë¶€íŒŒì¼ì´ ì—†ê±°ë‚˜ FILE íƒ€ì…ì´ ë§ì€ ê²½ìš°
        detail_url = record.get('detail_url') or record.get('dtl_url')
        
        if not detail_url:
            continue  # URLì´ ì—†ìœ¼ë©´ ì²˜ë¦¬ ë¶ˆê°€
            
        if not record.get('attachment_urls'):
            needs_processing.append(record)
        else:
            # FILEì´ë‚˜ ì˜ëª»ëœ íƒ€ì…ì´ ìˆëŠ”ì§€ í™•ì¸
            has_issues = False
            for att in record['attachment_urls']:
                if isinstance(att, dict):
                    if att.get('type') == 'FILE' or not att.get('file_extension'):
                        has_issues = True
                        break
            
            if has_issues:
                needs_processing.append(record)
    
    # ì œí•œ ì—†ì´ ì „ì²´ ì²˜ë¦¬
    # if processing_limit > 0 and len(needs_processing) > processing_limit:
    #     needs_processing = needs_processing[:processing_limit]
    #     print(f"ğŸ“Œ ì œí•œ ëª¨ë“œ: ìµœëŒ€ {processing_limit}ê°œë§Œ ì²˜ë¦¬")
    
    progress['total'] = len(needs_processing)
    
    print(f"âœ… ê²€í†  ëŒ€ìƒ: {len(all_records.data)}ê°œ")
    print(f"ğŸ“ ì²˜ë¦¬ í•„ìš”: {progress['total']}ê°œ")
    
    if progress['total'] == 0:
        print("ğŸ‰ ëª¨ë“  ë ˆì½”ë“œê°€ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
        return
    
    print(f"ğŸ”¥ {progress['total']}ê°œ ì²˜ë¦¬ ì‹œì‘ (15 workers)...\n")
    
    # ë³‘ë ¬ ì²˜ë¦¬ (BizInfoëŠ” K-Startupë³´ë‹¤ ëŠë ¤ì„œ worker ìˆ˜ ì¤„ì„)
    with ThreadPoolExecutor(max_workers=15) as executor:
        futures = {executor.submit(process_bizinfo_record, record): record for record in needs_processing}
        
        for i, future in enumerate(as_completed(futures), 1):
            try:
                future.result()
                if i % 100 == 0:
                    print(f"ì§„í–‰: {i}/{progress['total']} | ì„±ê³µ: {progress['success']} | íŒŒì¼: {progress['new_files']}ê°œ")
            except:
                pass
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*70)
    print("ğŸ“Š ì²˜ë¦¬ ì™„ë£Œ")
    print("="*70)
    print(f"âœ… ì„±ê³µ: {progress['success']}/{progress['total']}")
    print(f"ğŸ“ ìˆ˜ì§‘ëœ URL: {progress['new_files']}ê°œ")
    print("="*70)

if __name__ == "__main__":
    main()