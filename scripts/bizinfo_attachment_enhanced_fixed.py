#!/usr/bin/env python3
"""
BizInfo ì²¨ë¶€íŒŒì¼ URL ìˆ˜ì§‘ - ë‹¨ìˆœí™” ë²„ì „
- ì²¨ë¶€íŒŒì¼ URLë§Œ ìˆ˜ì§‘
- íŒŒì¼ëª…ê³¼ íƒ€ì… ì •ë³´ëŠ” ë‹¤ìš´ë¡œë“œ ì‹œ HTTP í—¤ë”ì—ì„œ ì¶”ì¶œ
"""
import sys
sys.stdout.reconfigure(encoding='utf-8')
import os
import requests
from bs4 import BeautifulSoup
import re
from supabase import create_client
from dotenv import load_dotenv
from urllib.parse import urljoin, unquote, urlparse, parse_qs
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

load_dotenv()

url = os.environ.get('SUPABASE_URL')
key = os.environ.get('SUPABASE_KEY')
supabase = create_client(url, key)

lock = threading.Lock()
progress = {
    'success': 0, 
    'error': 0, 
    'total': 0,
    'new_files': 0
}

session = requests.Session()
session.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': '*/*',
    'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
    'Referer': 'https://www.bizinfo.go.kr/'
})
# SSL ê²€ì¦ ë¹„í™œì„±í™” (í…ŒìŠ¤íŠ¸ ëª©ì )
session.verify = False
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def extract_attachment_urls_simple(page_url, pblanc_id):
    """ì²¨ë¶€íŒŒì¼ URLë§Œ ë‹¨ìˆœ ì¶”ì¶œ"""
    attachment_urls = []
    
    try:
        response = session.get(page_url, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # BizInfo ì²¨ë¶€íŒŒì¼ ë§í¬ ì°¾ê¸°
        file_links = soup.find_all('a')
        
        for link in file_links:
            href = link.get('href', '')
            onclick = link.get('onclick', '')
            
            # ë‹¤ìš´ë¡œë“œ ë§í¬ íŒ¨í„´ ì°¾ê¸°
            download_url = None
            
            # 1. hrefì—ì„œ ë‹¤ìš´ë¡œë“œ ë§í¬
            if '/fileDown.do' in href or 'download' in href.lower():
                if href.startswith('http'):
                    download_url = href
                elif href.startswith('/'):
                    download_url = 'https://www.bizinfo.go.kr' + href
            
            # 2. onclickì—ì„œ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
            elif 'fileDown(' in onclick:
                # fileDown() í•¨ìˆ˜ì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                match = re.search(r"fileDown\(['\"]([^'\"]+)['\"](?:,['\"]([^'\"]*)['\"])*\)", onclick)
                if match:
                    file_param = match.group(1)
                    download_url = f'https://www.bizinfo.go.kr/web/file/fileDown.do?{file_param}'
            
            # 3. ê¸°íƒ€ ë‹¤ìš´ë¡œë“œ ê´€ë ¨ onclick
            elif 'javascript:' in onclick and ('down' in onclick.lower() or 'file' in onclick.lower()):
                # ë” ë³µì¡í•œ íŒ¨í„´ì€ í•„ìš”ì‹œ ì¶”ê°€
                pass
            
            if download_url:
                # URLë§Œ ì €ì¥ - íŒŒì¼ëª…ê³¼ íƒ€ì… ì •ë³´ ì—†ìŒ
                attachment_urls.append({'url': download_url})
        
        return attachment_urls
        
    except Exception as e:
        print(f"URL ì¶”ì¶œ ì‹¤íŒ¨ {page_url}: {str(e)}")
        return []

def process_record(record):
    """ë ˆì½”ë“œ ì²˜ë¦¬ - URLë§Œ ìˆ˜ì§‘"""
    try:
        pblanc_id = record['pblanc_id']
        title = record.get('pblanc_nm', '')
        page_url = record.get('detail_url', '')
        
        if not page_url:
            # detail_urlì´ ì—†ìœ¼ë©´ pblanc_idë¡œ êµ¬ì„±
            page_url = f'https://www.bizinfo.go.kr/web/lay1/biz/S1T122C128/AS/S1T122C128AS01/S1T122C128AS01_02_View.do?pblanc_id={pblanc_id}'
        
        print(f"ì²˜ë¦¬ ì¤‘: {pblanc_id} - {title[:50]}...")
        
        # ì²¨ë¶€íŒŒì¼ URLë§Œ ì¶”ì¶œ
        attachments = extract_attachment_urls_simple(page_url, pblanc_id)
        
        if attachments:
            # ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ - URLë§Œ ì €ì¥
            result = supabase.table('bizinfo_complete')\
                .update({
                    'attachment_urls': attachments
                })\
                .eq('pblanc_id', pblanc_id)\
                .execute()
            
            if result.data:
                with lock:
                    progress['success'] += 1
                    progress['new_files'] += len(attachments)
                print(f"  âœ… {len(attachments)}ê°œ URL ìˆ˜ì§‘ ì™„ë£Œ")
                return True
        else:
            # ì²¨ë¶€íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°ë„ ì—…ë°ì´íŠ¸
            result = supabase.table('bizinfo_complete')\
                .update({
                    'attachment_urls': []
                })\
                .eq('pblanc_id', pblanc_id)\
                .execute()
            
            if result.data:
                with lock:
                    progress['success'] += 1
                print(f"  ğŸ“ ì²¨ë¶€íŒŒì¼ ì—†ìŒ")
                return True
        
        with lock:
            progress['error'] += 1
        return False
        
    except Exception as e:
        print(f"  âŒ ì˜¤ë¥˜: {str(e)}")
        with lock:
            progress['error'] += 1
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("="*70)
    print("ğŸ“ BizInfo ì²¨ë¶€íŒŒì¼ URL ìˆ˜ì§‘ (ë‹¨ìˆœí™” ë²„ì „)")
    print("="*70)
    
    # ì²˜ë¦¬ ì œí•œ í™•ì¸ (í™˜ê²½ë³€ìˆ˜ë¡œ ë°›ìŒ)
    processing_limit = int(os.environ.get('PROCESSING_LIMIT', '0'))
    
    # ì²˜ë¦¬ ëŒ€ìƒ ì¡°íšŒ - ì²¨ë¶€íŒŒì¼ì´ ì—†ê±°ë‚˜ ì¬ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²ƒë“¤
    if processing_limit > 0:
        # Daily ëª¨ë“œ: ìµœê·¼ Nê°œë§Œ
        all_records = supabase.table('bizinfo_complete')\
            .select('pblanc_id, pblanc_nm, detail_url, attachment_urls')\
            .order('created_at', desc=True)\
            .limit(processing_limit * 2)\
            .execute()
        print(f"ğŸ“Œ Daily ëª¨ë“œ: ìµœê·¼ {processing_limit*2}ê°œ ì¤‘ì—ì„œ ì²˜ë¦¬ í•„ìš”í•œ ê²ƒë§Œ ì„ íƒ")
    else:
        # Full ëª¨ë“œ: ì „ì²´
        all_records = supabase.table('bizinfo_complete')\
            .select('pblanc_id, pblanc_nm, detail_url, attachment_urls')\
            .execute()
        print("ğŸ“Œ Full ëª¨ë“œ: ì „ì²´ ë°ì´í„° ì²˜ë¦¬")
    
    needs_processing = []
    
    for record in all_records.data:
        # ì²¨ë¶€íŒŒì¼ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ì¬ì²˜ë¦¬
        if not record.get('attachment_urls'):
            needs_processing.append(record)
    
    # Daily ëª¨ë“œì—ì„œëŠ” ìµœëŒ€ Nê°œë§Œ ì²˜ë¦¬
    if processing_limit > 0 and len(needs_processing) > processing_limit:
        needs_processing = needs_processing[:processing_limit]
        print(f"ğŸ“Œ Daily ëª¨ë“œ ì œí•œ: ìµœëŒ€ {processing_limit}ê°œë§Œ ì²˜ë¦¬")
    
    progress['total'] = len(needs_processing)
    
    print(f"âœ… ê²€í†  ëŒ€ìƒ: {len(all_records.data)}ê°œ")
    print(f"ğŸ“ ì²˜ë¦¬ í•„ìš”: {progress['total']}ê°œ")
    
    if progress['total'] == 0:
        print("ğŸ‰ ëª¨ë“  ë ˆì½”ë“œê°€ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
        return
    
    print(f"ğŸ”¥ {progress['total']}ê°œ ì²˜ë¦¬ ì‹œì‘ (20 workers)...\n")
    
    # ë³‘ë ¬ ì²˜ë¦¬
    with ThreadPoolExecutor(max_workers=20) as executor:
        futures = {executor.submit(process_record, record): record for record in needs_processing}
        
        for i, future in enumerate(as_completed(futures), 1):
            try:
                future.result()
                if i % 50 == 0:
                    print(f"ì§„í–‰: {i}/{progress['total']} | ì„±ê³µ: {progress['success']} | URL: {progress['new_files']}ê°œ")
            except:
                pass
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*70)
    print("ğŸ“Š ì²˜ë¦¬ ì™„ë£Œ")
    print("="*70)
    print(f"âœ… ì„±ê³µ: {progress['success']}/{progress['total']}")
    print(f"ğŸ“ ìˆ˜ì§‘ëœ URL: {progress['new_files']}ê°œ")
    print("\nğŸ“ ë³€ê²½ì‚¬í•­:")
    print("  - íŒŒì¼ëª…ê³¼ íƒ€ì… ì •ë³´ ì œê±°")
    print("  - ìˆœìˆ˜ ë‹¤ìš´ë¡œë“œ URLë§Œ ì €ì¥")
    print("  - íŒŒì¼ëª…ì€ ë‹¤ìš´ë¡œë“œ ì‹œ HTTP í—¤ë”ì—ì„œ ì¶”ì¶œ")
    print("="*70)

if __name__ == "__main__":
    main()