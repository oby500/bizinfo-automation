#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
K-Startup ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ê¸° - êµ¬ê¸€ ì‹œíŠ¸ ë¡œì§ ê¸°ë°˜
GitHub Actionsìš©
"""

import sys
sys.stdout.reconfigure(encoding='utf-8')

import os
import requests
import xml.etree.ElementTree as ET
from datetime import datetime
from dotenv import load_dotenv
from supabase import create_client
import time
import re
import urllib3

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

def format_date_time(dt):
    """ë‚ ì§œ+ì‹œê°„ í¬ë§· YYYY-MM-DD HH:MM:SS"""
    return dt.strftime('%Y-%m-%d %H:%M:%S')

def pad_number(n):
    """ìˆ«ì ë³´ì • (1 â†’ 01)"""
    return str(n).zfill(2)

def clean_text(html_text):
    """HTML íƒœê·¸ ì œê±° + ì •ë¦¬"""
    if not html_text:
        return ""
    # HTML íƒœê·¸ ì œê±°
    clean = re.sub(r'<[^>]*>', '', str(html_text))
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    clean = re.sub(r'\s+', ' ', clean)
    return clean.strip()

def fetch_detail_info(detail_url):
    """ìƒì„¸í˜ì´ì§€ì—ì„œ ì‹ ì²­ê¸°ê°„, ì§€ì›ë‚´ìš©, ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ"""
    try:
        response = requests.get(detail_url, timeout=10)
        html = response.text
        
        info = {
            'pbanc_rcpt_bgng_dt': None,
            'pbanc_rcpt_end_dt': None, 
            'sprt_cnts': None,
            'attachment_urls': []
        }
        
        # ê¸°ê°„ ì¶”ì¶œ (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
        date_patterns = [
            r'ì ‘ìˆ˜ê¸°ê°„.*?(\d{4}[-\.]\d{2}[-\.]\d{2}).*?(\d{4}[-\.]\d{2}[-\.]\d{2})',
            r'ì‹ ì²­ê¸°ê°„.*?(\d{4}[-\.]\d{2}[-\.]\d{2}).*?(\d{4}[-\.]\d{2}[-\.]\d{2})',
            r'(\d{4}[-\.]\d{2}[-\.]\d{2}).*?~.*?(\d{4}[-\.]\d{2}[-\.]\d{2})'
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, html, re.DOTALL)
            if match:
                start_date = match.group(1).replace('.', '-')
                end_date = match.group(2).replace('.', '-')
                info['pbanc_rcpt_bgng_dt'] = start_date
                info['pbanc_rcpt_end_dt'] = end_date
                break
        
        # ì§€ì›ë‚´ìš© ì¶”ì¶œ
        sprt_patterns = [
            r'ì§€ì›ë‚´ìš©[:\s]*([^<\n]{20,200})',
            r'ì§€ì›ê·œëª¨[:\s]*([^<\n]{20,200})',
            r'ì§€ì›ê¸ˆì•¡[:\s]*([^<\n]{20,200})'
        ]
        
        for pattern in sprt_patterns:
            match = re.search(pattern, html, re.IGNORECASE)
            if match:
                info['sprt_cnts'] = clean_text(match.group(1))
                break
        
        # ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ
        file_patterns = [
            r'href="([^"]*\.(pdf|hwp|doc|docx|xls|xlsx)[^"]*)"[^>]*>([^<]+)',
            r'onclick="[^"]*download[^"]*\([\'"]([^\'"]*)[\'"][^>]*>([^<]+)'
        ]
        
        for pattern in file_patterns:
            matches = re.findall(pattern, html, re.IGNORECASE)
            for match in matches:
                if len(match) >= 2:
                    url = match[0] if match[0].startswith('http') else f"https://www.k-startup.go.kr{match[0]}"
                    filename = match[2] if len(match) > 2 else match[1]
                    file_ext = url.split('.')[-1].upper() if '.' in url else 'UNKNOWN'
                    
                    info['attachment_urls'].append({
                        'url': url,
                        'filename': clean_text(filename),
                        'type': file_ext
                    })
        
        return info
        
    except Exception as e:
        print(f"    âŒ ìƒì„¸ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸš€ K-Startup ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    print("=" * 60)
    
    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    SUPABASE_URL = os.getenv('SUPABASE_URL')
    SUPABASE_KEY = os.getenv('SUPABASE_KEY')
    COLLECTION_MODE = os.getenv('COLLECTION_MODE', 'daily').lower()
    
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âŒ í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: SUPABASE_URL, SUPABASE_KEY")
        return
    
    print(f"ğŸ“Š ìˆ˜ì§‘ ëª¨ë“œ: {COLLECTION_MODE}")
    print(f"ğŸ”— Supabase URL: {SUPABASE_URL[:30]}...")
    
    # Supabase ì—°ê²°
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        print("âœ… Supabase ì—°ê²° ì„±ê³µ")
    except Exception as e:
        print(f"âŒ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")
        return
    
    # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ (ì¤‘ë³µ ì²´í¬ìš©)
    try:
        existing_result = supabase.table('kstartup_complete').select('announcement_id').execute()
        # ë’¤ 6ìë¦¬ë§Œ ì¶”ì¶œí•˜ì—¬ ì§‘í•©ìœ¼ë¡œ ì €ì¥
        existing_ids = set()
        for row in existing_result.data:
            aid = str(row['announcement_id'])
            # ë’¤ 6ìë¦¬ ìˆ«ìë§Œ ì¶”ì¶œ (KS_ ì ‘ë‘ì‚¬ ì œê±°)
            if len(aid) >= 6:
                last_6 = aid[-6:] if aid[-6:].isdigit() else aid
                existing_ids.add(last_6)
        
        print(f"ğŸ“‹ ê¸°ì¡´ ë°ì´í„°: {len(existing_ids)}ê°œ (ë’¤ 6ìë¦¬ ê¸°ì¤€)")
    except Exception as e:
        print(f"âŒ ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        existing_ids = set()
    
    # ìˆ˜ì§‘ ëª¨ë“œë³„ ì„¤ì •
    if COLLECTION_MODE == 'daily':
        print("ğŸ“… Daily ëª¨ë“œ: ìµœì‹  ë°ì´í„° í™•ì¸")
        max_duplicate_count = 50  # ì—°ì† ì¤‘ë³µ 50ê°œë©´ ì¢…ë£Œ
        max_pages = 5  # 5í˜ì´ì§€ê¹Œì§€ í™•ì¸ (1000ê°œ)
        min_check_count = 0  # ìµœì†Œ ê²€í†  ê°œìˆ˜ ì œí•œ ì—†ìŒ
    else:
        print("ğŸ”„ Full ëª¨ë“œ: ì „ì²´ ë°ì´í„° ìˆ˜ì§‘")
        max_duplicate_count = 200  # ì—°ì† ì¤‘ë³µ 200ê°œë©´ ì¢…ë£Œ
        max_pages = 50  # 50í˜ì´ì§€ê¹Œì§€ í™•ì¸ (10000ê°œ)
        min_check_count = 100  # ìµœì†Œ 100ê°œëŠ” ê²€í† 
    
    # ë°ì´í„° ìˆ˜ì§‘
    base_url = "https://www.k-startup.go.kr/api/apisvc/xml/GetPblancListSvc"
    new_items = []
    duplicate_count = 0
    total_checked = 0
    
    print(f"\nğŸ” ìµœëŒ€ {max_pages}í˜ì´ì§€, ì—°ì† ì¤‘ë³µ {max_duplicate_count}ê°œê¹Œì§€ í™•ì¸")
    
    for page in range(1, max_pages + 1):
        print(f"\nğŸ“„ í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘...")
        
        try:
            params = {
                'page': page,
                'perPage': 200,  # êµ¬ê¸€ì‹œíŠ¸ì™€ ë™ì¼í•˜ê²Œ 200ê°œ
                'sortColumn': 'REG_YMD',
                'sortDirection': 'DESC'
            }
            
            response = requests.get(base_url, params=params, timeout=30, verify=False)
            
            if response.status_code != 200:
                print(f"  âŒ HTTP ì˜¤ë¥˜: {response.status_code}")
                continue
            
            # XML íŒŒì‹±
            root = ET.fromstring(response.text)
            items = []
            
            # ì•„ì´í…œ ì°¾ê¸° (ë‹¤ì–‘í•œ íƒœê·¸ëª… ì‹œë„)
            for tag in ['item', 'items', 'pblanc']:
                found_items = root.findall(f".//{tag}")
                if found_items:
                    items = found_items
                    break
            
            if not items:
                print(f"  âš ï¸ í˜ì´ì§€ {page}: ì•„ì´í…œ ì—†ìŒ")
                continue
            
            print(f"  ğŸ“Š í˜ì´ì§€ {page}: {len(items)}ê°œ ì•„ì´í…œ ë°œê²¬")
            
            # ê° ì•„ì´í…œ ì²˜ë¦¬
            for item in items:
                total_checked += 1
                
                # ID ì¶”ì¶œ
                id_elem = item.find('pblancId') or item.find('pblanc_id') or item.find('id')
                if id_elem is None or not id_elem.text:
                    continue
                
                id_text = str(id_elem.text).strip()
                # ë’¤ 6ìë¦¬ë§Œ ì¶”ì¶œ
                id_trimmed = id_text.replace('KS_', '').replace('ks_', '')
                id_last_6 = id_trimmed[-6:] if len(id_trimmed) >= 6 and id_trimmed[-6:].isdigit() else id_trimmed
                
                if id_last_6 in existing_ids:
                    duplicate_count += 1
                    print(f"  âš ï¸ ì¤‘ë³µ: {id_trimmed} â†’ {id_last_6} ({duplicate_count}ì—°ì†)")
                    
                    # ì—°ì† ì¤‘ë³µì´ max_duplicate_countì— ë„ë‹¬í•˜ë©´ ì¢…ë£Œ
                    if duplicate_count >= max_duplicate_count:
                        print(f"ğŸ”„ ì—°ì† ì¤‘ë³µ {max_duplicate_count}ê±´ ë„ë‹¬ - ìˆ˜ì§‘ ì¢…ë£Œ")
                        break
                    continue
                
                duplicate_count = 0  # ìƒˆ ë°ì´í„° ë°œê²¬ ì‹œ ë¦¬ì…‹
                
                # ìƒˆ ë°ì´í„° ì²˜ë¦¬
                title_elem = item.find('pblancNm') or item.find('pblanc_nm') or item.find('title')
                title = title_elem.text if title_elem is not None else "ì œëª© ì—†ìŒ"
                
                print(f"  âœ… ìƒˆ ë°ì´í„°: {id_trimmed} - {title[:30]}...")
                
                # ìƒì„¸ URL ìƒì„±
                detail_url = f"https://www.k-startup.go.kr/homepage/businessManage/businessManageDetail.do?bizPblancId={id_text}"
                
                # ìƒì„¸ì •ë³´ ì¶”ì¶œ
                detail_info = fetch_detail_info(detail_url)
                
                # ê¸°ë³¸ ë°ì´í„° êµ¬ì„±
                item_data = {
                    'announcement_id': id_text,
                    'biz_pbanc_nm': clean_text(title),
                    'detail_url': detail_url,
                    'collected_at': format_date_time(datetime.now())
                }
                
                # ìƒì„¸ì •ë³´ ë³‘í•©
                if detail_info:
                    item_data.update(detail_info)
                
                new_items.append(item_data)
                existing_ids.add(id_last_6)  # ì¤‘ë³µ ì²´í¬ìš© ì¶”ê°€
                
                if len(new_items) >= 100:  # í•œ ë²ˆì— ë„ˆë¬´ ë§ì´ ìˆ˜ì§‘ ë°©ì§€
                    print(f"  ğŸ¯ 100ê°œ ìˆ˜ì§‘ ì™„ë£Œ - ë°°ì¹˜ ì €ì¥")
                    break
            
            # ì—°ì† ì¤‘ë³µìœ¼ë¡œ ì¢…ë£Œëœ ê²½ìš°
            if duplicate_count >= max_duplicate_count:
                break
                
        except Exception as e:
            print(f"  âŒ í˜ì´ì§€ {page} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼")
    print("=" * 60)
    print(f"ğŸ” ì´ ê²€í† : {total_checked}ê°œ")
    print(f"âœ… ìƒˆ ë°ì´í„°: {len(new_items)}ê°œ")
    print(f"âš ï¸ ìµœì¢… ì¤‘ë³µ: {duplicate_count}ì—°ì†")
    
    # ë°ì´í„° ì €ì¥
    if new_items:
        print(f"\nğŸ’¾ Supabaseì— {len(new_items)}ê°œ ì €ì¥ ì¤‘...")
        try:
            # ë°°ì¹˜ë¡œ ì €ì¥ (100ê°œì”©)
            batch_size = 100
            saved_count = 0
            
            for i in range(0, len(new_items), batch_size):
                batch = new_items[i:i + batch_size]
                result = supabase.table('kstartup_complete').insert(batch).execute()
                saved_count += len(batch)
                print(f"  ğŸ“¦ ë°°ì¹˜ {i//batch_size + 1}: {len(batch)}ê°œ ì €ì¥")
            
            print(f"âœ… ì´ {saved_count}ê°œ ì €ì¥ ì™„ë£Œ!")
            
            # ìµœì‹  ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥
            print(f"\nğŸ“‹ ì €ì¥ëœ ë°ì´í„° ìƒ˜í”Œ:")
            for i, item in enumerate(new_items[:3]):
                print(f"  {i+1}. {item['announcement_id']} - {item['biz_pbanc_nm'][:40]}...")
                if item.get('attachment_urls'):
                    print(f"     ğŸ“ ì²¨ë¶€íŒŒì¼: {len(item['attachment_urls'])}ê°œ")
            
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
    else:
        print("â„¹ï¸ ì €ì¥í•  ìƒˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ!")
    print("=" * 60)

if __name__ == "__main__":
    main()