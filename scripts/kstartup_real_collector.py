#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
K-Startup ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ê¸° - êµ¬ê¸€ ì‹œíŠ¸ ë¡œì§ ê¸°ë°˜
GitHub Actionsìš©
"""

import sys
sys.stdout.reconfigure(encoding='utf-8')

import os
import requests
import xml.etree.ElementTree as ET
from datetime import datetime
from dotenv import load_dotenv
from supabase import create_client
import time
import re
import urllib3

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

def format_date_time(dt):
    """ë‚ ì§œ+ì‹œê°„ í¬ë§· YYYY-MM-DD HH:MM:SS"""
    return dt.strftime('%Y-%m-%d %H:%M:%S')

def pad_number(n):
    """ìˆ«ì ë³´ì • (1 â†’ 01)"""
    return str(n).zfill(2)

def clean_text(html_text):
    """HTML íƒœê·¸ ì œê±° + ì •ë¦¬"""
    if not html_text:
        return ""
    # HTML íƒœê·¸ ì œê±°
    clean = re.sub(r'<[^>]*>', '', str(html_text))
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    clean = re.sub(r'\s+', ' ', clean)
    return clean.strip()

def fetch_detail_info(detail_url):
    """ìƒì„¸í˜ì´ì§€ì—ì„œ ì‹ ì²­ê¸°ê°„, ì§€ì›ë‚´ìš©, ì²¨ë¶€íŒŒì¼ ì¶”ì¶œ"""
    try:
        response = requests.get(detail_url, timeout=10)
        html = response.text
        
        # ê¸°ë³¸ê°’
        result = {
            'applicationStartDate': '',
            'applicationEndDate': '',
            'supportTarget': '',
            'supportContent': '',
            'attachmentLinks': ''
        }
        
        # 1. JavaScript ë³€ìˆ˜ì—ì„œ ë‚ ì§œ ì¶”ì¶œ (ê°€ì¥ ì •í™•í•œ ë°©ë²•)
        js_dates = re.findall(r"getDayOfTheWeek\('(\d{4})\.(\d{1,2})\.(\d{1,2})", html)
        if len(js_dates) >= 2:
            # ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ ëª¨ë‘ ì°¾ì€ ê²½ìš°
            year1, month1, day1 = js_dates[0]
            year2, month2, day2 = js_dates[1]
            result['applicationStartDate'] = f"{year1}-{pad_number(month1)}-{pad_number(day1)}"
            result['applicationEndDate'] = f"{year2}-{pad_number(month2)}-{pad_number(day2)}"
        elif len(js_dates) == 1:
            # í•˜ë‚˜ë§Œ ì°¾ì€ ê²½ìš° ì‹œì‘ì¼ë¡œ ì„¤ì •
            year1, month1, day1 = js_dates[0]
            result['applicationStartDate'] = f"{year1}-{pad_number(month1)}-{pad_number(day1)}"
            
            # ì¶”ê°€ ë‚ ì§œ íŒ¨í„´ ê²€ìƒ‰
            additional_dates = re.findall(r"(\d{4})\.(\d{1,2})\.(\d{1,2})", html)
            if len(additional_dates) >= 2:
                year2, month2, day2 = additional_dates[1]
                result['applicationEndDate'] = f"{year2}-{pad_number(month2)}-{pad_number(day2)}"
        
        # JavaScriptì—ì„œ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ ê¸°ì¡´ HTML íŒ¨í„´ ì‚¬ìš©
        if not result['applicationStartDate']:
            # ê³µë°± ì œê±°
            cleaned_html = re.sub(r'\s+', '', html).replace('&nbsp;', '')
            
            # 2. HTMLì—ì„œ YYYY.MM.DD ~ YYYY.MM.DD íŒ¨í„´
            date_match = re.search(r'(20\d{2})[.\-/ë…„](\d{1,2})[.\-/ì›”](\d{1,2})[ì¼]?[^\d]*(20\d{2})[.\-/ë…„](\d{1,2})[.\-/ì›”](\d{1,2})[ì¼]?', cleaned_html)
            if date_match:
                result['applicationStartDate'] = f"{date_match.group(1)}-{pad_number(date_match.group(2))}-{pad_number(date_match.group(3))}"
                result['applicationEndDate'] = f"{date_match.group(4)}-{pad_number(date_match.group(5))}-{pad_number(date_match.group(6))}"
            else:
                # 3. MM.DD ~ MM.DD íŒ¨í„´ (í˜„ì¬ ì—°ë„)
                date_match2 = re.search(r'(\d{1,2})[.\-/ì›”](\d{1,2})[ì¼]?[~\-](\d{1,2})[.\-/ì›”](\d{1,2})[ì¼]?', cleaned_html)
                if date_match2:
                    current_year = datetime.now().year
                    result['applicationStartDate'] = f"{current_year}-{pad_number(date_match2.group(1))}-{pad_number(date_match2.group(2))}"
                    result['applicationEndDate'] = f"{current_year}-{pad_number(date_match2.group(3))}-{pad_number(date_match2.group(4))}"
        
        # ì§€ì›ëŒ€ìƒ ì¶”ì¶œ
        target_match = re.search(r'ì§€ì›ëŒ€ìƒ\s*:?([\s\S]*?)</div>', html, re.IGNORECASE)
        if target_match:
            result['supportTarget'] = clean_text(target_match.group(1))
        
        # ì§€ì›ë‚´ìš© ì¶”ì¶œ
        content_match = re.search(r'ì§€ì›ë‚´ìš©\s*:?([\s\S]*?)</div>', html, re.IGNORECASE)
        if content_match:
            result['supportContent'] = clean_text(content_match.group(1))
        
        # ì²¨ë¶€íŒŒì¼ ë§í¬ ì¶”ì¶œ
        attachment_matches = re.findall(r'<a[^>]*href="([^"]+)"[^>]*download', html, re.IGNORECASE)
        if attachment_matches:
            base_url = "https://www.k-startup.go.kr"
            result['attachmentLinks'] = ", ".join([base_url + link for link in attachment_matches])
        
        return result
        
    except Exception as e:
        print(f"âŒ ìƒì„¸í˜ì´ì§€ íŒŒì‹± ì‹¤íŒ¨: {detail_url} - {e}")
        return {
            'applicationStartDate': '',
            'applicationEndDate': '',
            'supportTarget': '',
            'supportContent': '',
            'attachmentLinks': ''
        }

def collect_kstartup_data():
    """K-Startup ë°ì´í„° ìˆ˜ì§‘ ë©”ì¸ í•¨ìˆ˜"""
    print("="*60)
    print("ğŸš€ K-Startup ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    print("="*60)
    
    # ìˆ˜ì§‘ ëª¨ë“œ í™•ì¸
    collection_mode = os.getenv('COLLECTION_MODE', 'daily')
    print(f"ğŸ“‹ ìˆ˜ì§‘ ëª¨ë“œ: {collection_mode}")
    
    if collection_mode == 'daily':
        print("ğŸ“… Daily ëª¨ë“œ: ìµœëŒ€ 10í˜ì´ì§€ê¹Œì§€ ë°ì´í„° ìˆ˜ì§‘")
        max_duplicate_count = 50  # ì—°ì† ì¤‘ë³µ 50ê°œê¹Œì§€ í—ˆìš©
        max_pages = 10  # 10í˜ì´ì§€ê¹Œì§€ ì‹œë„
        min_check_count = 100  # ìµœì†Œ 100ê°œ ê²€í† 
    else:
        print("ğŸ”„ Full ëª¨ë“œ: ì „ì²´ ë°ì´í„° ìˆ˜ì§‘")
        max_duplicate_count = 50  # ì¤‘ë³µ 50ê±´ì—ì„œ ì¤‘ì§€ 
        max_pages = 100  # ìµœëŒ€ 100í˜ì´ì§€
        min_check_count = 0  # ì œí•œ ì—†ìŒ
    
    # Supabase ì—°ê²°
    SUPABASE_URL = os.getenv('SUPABASE_URL')
    SUPABASE_KEY = os.getenv('SUPABASE_KEY')
    
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âŒ Supabase í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    print("âœ… Supabase ì—°ê²° ì„±ê³µ")
    
    # ê¸°ì¡´ ê³µê³ ID ì¡°íšŒ (ë’¤ 6ìë¦¬ë§Œ ì¶”ì¶œí•˜ì—¬ ë¹„êµ)
    try:
        existing_result = supabase.table('kstartup_complete').select('announcement_id').execute()
        existing_ids = set()
        if existing_result.data:
            # announcement_idì—ì„œ ë’¤ 6ìë¦¬ ìˆ«ìë§Œ ì¶”ì¶œ (KS_ ì ‘ë‘ì‚¬ ë¬´ì‹œ)
            for item in existing_result.data:
                if item.get('announcement_id'):
                    full_id = str(item['announcement_id']).strip()
                    # ë’¤ì—ì„œ 6ìë¦¬ ìˆ«ì ì¶”ì¶œ (ì˜ˆ: "KS_174689" â†’ "174689", "174689" â†’ "174689")
                    if len(full_id) >= 6:
                        last_6_digits = full_id[-6:]
                        if last_6_digits.isdigit():
                            existing_ids.add(last_6_digits)
        print(f"ğŸ“‹ ê¸°ì¡´ ê³µê³  ìˆ˜: {len(existing_ids)}ê°œ (ë’¤ 6ìë¦¬ ê¸°ì¤€)")
    except Exception as e:
        print(f"âš ï¸ ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨, ê³„ì† ì§„í–‰: {e}")
        existing_ids = set()
    
    # API ì„¤ì • - HTTPë¡œ ì‹œë„
    service_key = "rHwfm51FIrtIJjqRL2fJFJFvNsVEng7v7Ud0T44EKQpgKoMEJmN06LZ+KQ2wbTfW29XZSm8OzMuNCUQi+MTlsQ=="
    base_url = "http://apis.data.go.kr/B552735/kisedKstartupService01/getAnnouncementInformation01"
    
    # ë°ì´í„° ìˆ˜ì§‘
    page = 1
    per_page = 100  # APIê°€ ì‹¤ì œë¡œ ì§€ì›í•˜ëŠ” í¬ê¸°
    duplicate_count = 0
    new_items = []
    total_checked = 0  # ì´ ê²€í† í•œ ë°ì´í„° ìˆ˜
    
    while True:
        print(f"\nğŸ“„ í˜ì´ì§€ {page} ìˆ˜ì§‘ ì¤‘...")
        
        params = {
            'ServiceKey': service_key,  # ëŒ€ë¬¸ì S
            'page': page,               # pageë¡œ ìˆ˜ì • (pageNoê°€ ì•„ë‹˜)
            'perPage': per_page         # perPageë¡œ ìˆ˜ì • (numOfRowsê°€ ì•„ë‹˜)
        }
        
        try:
            # SSL ê²€ì¦ ìš°íšŒ ë° í—¤ë” ì¶”ê°€
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'application/xml, text/xml, */*',
                'Connection': 'keep-alive'
            }
            
            response = requests.get(base_url, params=params, headers=headers, timeout=30, verify=False)
            
            if response.status_code != 200:
                print(f"âŒ HTTP ì˜¤ë¥˜: {response.status_code}")
                break
            
            # XML íŒŒì‹±
            root = ET.fromstring(response.text)
            
            # data/item êµ¬ì¡° í™•ì¸
            data_element = root.find('data')
            if data_element is None:
                print("âŒ XMLì—ì„œ data ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                break
                
            items = data_element.findall('item')
            
            if len(items) == 0:
                print(f"âœ… í˜ì´ì§€ {page}: ë°ì´í„° ì—†ìŒ - ìˆ˜ì§‘ ì™„ë£Œ")
                break
            
            print(f"ğŸ“Š í˜ì´ì§€ {page}: {len(items)}ê°œ í•­ëª© ë°œê²¬")
            
            for item in items:
                cols = item.findall('col')
                total_checked += 1  # ê²€í† í•œ ë°ì´í„° ìˆ˜ ì¦ê°€
                
                # ë°ì´í„° ì¶”ì¶œ
                row_data = {
                    'id': '',
                    'title': '',
                    'org': '',
                    'supervisor': '',
                    'executor': '',
                    'url': ''
                }
                
                for col in cols:
                    name_attr = col.get('name')
                    value = col.text or ''
                    
                    if name_attr == 'pbanc_sn':
                        row_data['id'] = value
                    elif name_attr == 'biz_pbanc_nm':
                        row_data['title'] = value
                    elif name_attr == 'pbanc_ntrp_nm':
                        row_data['org'] = value
                    elif name_attr == 'sprv_inst':
                        row_data['supervisor'] = value
                    elif name_attr == 'biz_prch_dprt_nm':
                        row_data['executor'] = value
                    elif name_attr == 'detl_pg_url':
                        row_data['url'] = value
                
                # ì¤‘ë³µ ì²´í¬ (ë’¤ 6ìë¦¬ë§Œ ë¹„êµ)
                id_trimmed = str(row_data['id']).strip()
                # API IDì—ì„œë„ ë’¤ 6ìë¦¬ë§Œ ì¶”ì¶œ
                id_last_6 = id_trimmed[-6:] if len(id_trimmed) >= 6 and id_trimmed[-6:].isdigit() else id_trimmed
                
                if id_last_6 in existing_ids:
                    duplicate_count += 1
                    print(f"âš ï¸ ì¤‘ë³µ: {id_trimmed} â†’ {id_last_6} ({duplicate_count}ì—°ì†, ì´ {total_checked}ê°œ ê²€í† )")
                    
                    # ìµœì†Œ ê²€í†  ê°œìˆ˜ë¥¼ ë§Œì¡±í–ˆê³  ì—°ì† ì¤‘ë³µì´ ë§ì„ ë•Œë§Œ ì¢…ë£Œ
                    if total_checked >= min_check_count and duplicate_count >= max_duplicate_count:
                        print(f"ğŸ”„ ìµœì†Œ {min_check_count}ê°œ ê²€í†  ì™„ë£Œ + ì—°ì† ì¤‘ë³µ {max_duplicate_count}ê±´ ë„ë‹¬ - ìˆ˜ì§‘ ì¢…ë£Œ")
                        break
                    continue
                
                # URL ê²€ì¦
                if not row_data['url'] or not row_data['url'].strip():
                    print(f"âš ï¸ URL ëˆ„ë½ - ê±´ë„ˆëœ€: {row_data['id']}")
                    continue
                
                duplicate_count = 0  # ìƒˆ ë°ì´í„° ë°œê²¬ ì‹œ ë¦¬ì…‹
                existing_ids.add(id_last_6)  # ì¤‘ë³µ ë°©ì§€ìš© ì¶”ê°€ (ë’¤ 6ìë¦¬ë§Œ)
                
                # ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
                print(f"ğŸ” ìƒì„¸ ì •ë³´ ìˆ˜ì§‘: {id_trimmed}")
                detail_info = fetch_detail_info(row_data['url'])
                
                # ìˆ˜ì§‘ ì‹œê°„
                collected_time = format_date_time(datetime.now())
                
                # ë°ì´í„° êµ¬ì„± (ê¸°ì¡´ í…Œì´ë¸” ì»¬ëŸ¼ëª…ì— ë§ì¶¤)
                new_item = {
                    'announcement_id': row_data['id'],
                    'biz_pbanc_nm': row_data['title'],
                    'pbanc_ntrp_nm': row_data['org'],
                    'spnsr_organ_nm': row_data['supervisor'],
                    'exctv_organ_nm': row_data['executor'],
                    'extraction_date': collected_time,
                    'aply_trgt_ctnt': detail_info['supportTarget'],
                    'pbanc_ctnt': detail_info['supportContent'],
                    'attachment_urls': detail_info['attachmentLinks'],
                    'detl_pg_url': row_data['url'],
                    'status': 'ìˆ˜ì§‘ì™„ë£Œ',
                    'created_at': collected_time
                }
                
                # ë‚ ì§œ í•„ë“œëŠ” ë¹ˆ ê°’ì´ ì•„ë‹ ë•Œë§Œ ì¶”ê°€ (ì˜¬ë°”ë¥¸ ì»¬ëŸ¼ëª… ì‚¬ìš©)
                if detail_info['applicationStartDate']:
                    new_item['pbanc_rcpt_bgng_dt'] = detail_info['applicationStartDate']
                if detail_info['applicationEndDate']:
                    new_item['pbanc_rcpt_end_dt'] = detail_info['applicationEndDate']
                
                new_items.append(new_item)
                print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {row_data['title'][:30]}...")
                
                # ìš”ì²­ ê°„ ë”œë ˆì´
                time.sleep(0.1)
            
            # ë£¨í”„ ì¢…ë£Œ ì¡°ê±´ ê°œì„ : ìµœì†Œ ê²€í†  ê°œìˆ˜ + ì¤‘ë³µ íŒ¨í„´ í™•ì¸
            if total_checked >= min_check_count and duplicate_count >= max_duplicate_count:
                break
            
            # í˜ì´ì§€ ì œí•œ ì²´í¬
            if page >= max_pages:
                print(f"ğŸ“„ ìµœëŒ€ í˜ì´ì§€ ìˆ˜ ({max_pages}) ë„ë‹¬ - ìˆ˜ì§‘ ì¢…ë£Œ")
                break
                
            page += 1
            
        except Exception as e:
            print(f"âŒ í˜ì´ì§€ {page} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            break
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
    if new_items:
        print(f"\nğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì— {len(new_items)}ê°œ ì €ì¥ ì¤‘...")
        try:
            # ë°°ì¹˜ë¡œ ì‚½ì…
            batch_size = 10
            for i in range(0, len(new_items), batch_size):
                batch = new_items[i:i+batch_size]
                result = supabase.table('kstartup_complete').insert(batch).execute()
                print(f"ğŸ“ ë°°ì¹˜ {i//batch_size + 1}: {len(batch)}ê°œ ì €ì¥ ì™„ë£Œ")
                time.sleep(0.5)  # ë°°ì¹˜ ê°„ ë”œë ˆì´
            
            print(f"âœ… ì´ {len(new_items)}ê°œ ìƒˆë¡œìš´ ê³µê³  ì €ì¥ ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì˜¤ë¥˜: {e}")
    else:
        print("â„¹ï¸ ì €ì¥í•  ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    print("\n" + "="*60)
    print("ğŸ‰ K-Startup ìˆ˜ì§‘ ì™„ë£Œ")
    print(f"ğŸ“Š ì´ ê²€í† : {total_checked}ê°œ")
    print(f"ğŸ“Š ìƒˆë¡œìš´ ê³µê³ : {len(new_items)}ê°œ")
    print(f"ğŸ“‹ ìˆ˜ì§‘ ëª¨ë“œ: {collection_mode} (ìµœì†Œ {min_check_count}ê°œ ê²€í† )")
    print("="*60)

if __name__ == "__main__":
    collect_kstartup_data()