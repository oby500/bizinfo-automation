#!/usr/bin/env python3
"""
ê¸°ì—…ë§ˆë‹¹ ì²¨ë¶€íŒŒì¼ í¬ë¡¤ëŸ¬ - ì •í™•í•œ íŒŒì¼ëª… ì¶”ì¶œ ë²„ì „
div.file_nameê³¼ title ì†ì„±ì—ì„œ íŒŒì¼ëª…ì„ ì§ì ‘ ì¶”ì¶œí•˜ì—¬ ì •í™•í•œ íŒŒì¼ íƒ€ì… ê°ì§€
"""
import os
import sys
import time
import requests
from bs4 import BeautifulSoup
from urllib.parse import parse_qs, urlparse
from supabase import create_client
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import re

# ì „ì—­ ë³€ìˆ˜
lock = threading.Lock()
success_count = 0
error_count = 0
attachment_total = 0
skip_count = 0
type_fixed = 0

def extract_file_type_from_filename(filename):
    """íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì¶”ì¶œ"""
    if not filename:
        return 'UNKNOWN'
    
    filename_lower = filename.lower()
    
    if '.hwp' in filename_lower or '.hwpx' in filename_lower:
        return 'HWP'
    elif '.pdf' in filename_lower:
        return 'PDF'
    elif '.docx' in filename_lower:
        return 'DOCX'
    elif '.doc' in filename_lower:
        return 'DOC'
    elif '.xlsx' in filename_lower:
        return 'XLSX'
    elif '.xls' in filename_lower:
        return 'XLS'
    elif '.pptx' in filename_lower:
        return 'PPTX'
    elif '.ppt' in filename_lower:
        return 'PPT'
    elif '.zip' in filename_lower or '.rar' in filename_lower:
        return 'ZIP'
    elif '.jpg' in filename_lower or '.jpeg' in filename_lower:
        return 'JPG'
    elif '.png' in filename_lower:
        return 'PNG'
    elif '.gif' in filename_lower:
        return 'GIF'
    elif '.txt' in filename_lower:
        return 'TXT'
    elif '.rtf' in filename_lower:
        return 'RTF'
    else:
        return 'UNKNOWN'

def clean_filename(text):
    """íŒŒì¼ëª… ì •ë¦¬"""
    if not text:
        return None
    
    # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
    text = text.strip()
    text = re.sub(r'ë‹¤ìš´ë¡œë“œ$', '', text)
    text = re.sub(r'ë°”ë¡œë³´ê¸°.*$', '', text)
    text = re.sub(r'ìƒˆ ì°½ ì—´ê¸°$', '', text)
    text = re.sub(r'^ì²¨ë¶€íŒŒì¼\s*', '', text)
    
    return text.strip()

def get_file_type_by_signature(url, session=None):
    """íŒŒì¼ì˜ ì²˜ìŒ ëª‡ ë°”ì´íŠ¸ë¥¼ ì½ì–´ ì‹¤ì œ íƒ€ì… íŒë‹¨ (í´ë°±ìš©)"""
    if session is None:
        session = requests.Session()
    
    try:
        # íŒŒì¼ì˜ ì²˜ìŒ ë¶€ë¶„ë§Œ ë‹¤ìš´ë¡œë“œ (Range í—¤ë” ì‚¬ìš©)
        headers = {'Range': 'bytes=0-1024'}
        response = session.get(url, headers=headers, timeout=10, stream=True)
        
        # ì „ì²´ ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•œ ê²½ìš° (Range ë¯¸ì§€ì›)
        if response.status_code == 200:
            content = response.content[:1024]
        elif response.status_code == 206:  # Partial Content
            content = response.content
        else:
            return 'UNKNOWN'
        
        # íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ë¡œ íƒ€ì… íŒë‹¨
        if len(content) >= 4:
            # PDF
            if content[:4] == b'%PDF':
                return 'PDF'
            # ZIP
            elif content[:2] == b'PK':
                return 'ZIP'
            # HWP 5.0
            elif content[:4] == b'\xd0\xcf\x11\xe0' or content[:8] == b'HWP Document':
                return 'HWP'
            # HWP 3.0
            elif len(content) >= 32 and b'HWP' in content[:32]:
                return 'HWP'
        
        return 'UNKNOWN'
        
    except Exception as e:
        return 'UNKNOWN'

def process_item(data, idx, total, supabase):
    """ê°œë³„ í•­ëª© ì²˜ë¦¬"""
    global success_count, error_count, attachment_total, skip_count, type_fixed
    
    # ì´ë¯¸ ì²˜ë¦¬ëœ ë°ì´í„° ì²´í¬
    current_summary = data.get('bsns_sumry', '')
    current_attachments = data.get('attachment_urls')
    
    # ì²¨ë¶€íŒŒì¼ì´ ìˆê³  UNKNOWN/HTML/DOCì´ ìˆëŠ”ì§€ ì²´í¬
    has_problem = False
    if current_attachments:
        for att in current_attachments:
            if isinstance(att, dict):
                file_type = att.get('type')
                # DOCë„ ë¬¸ì œë¡œ ê°„ì£¼ (ëŒ€ë¶€ë¶„ HWPì—¬ì•¼ í•¨)
                if file_type in ['UNKNOWN', 'HTML', 'DOC']:
                    has_problem = True
                    break
    
    # ë¬¸ì œê°€ ì—†ê³  ìš”ì•½ë„ ì¶©ë¶„í•œ ê²½ìš° ìŠ¤í‚µ
    if current_summary and len(current_summary) >= 150 and current_attachments and not has_problem:
        with lock:
            skip_count += 1
        print(f"[{idx}/{total}] â­ï¸ ì´ë¯¸ ì²˜ë¦¬ ì™„ë£Œ")
        return False
    
    # ì„¸ì…˜ ìƒì„±
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': '*/*',
        'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
        'Connection': 'keep-alive'
    })
    
    try:
        pblanc_id = data['pblanc_id']
        pblanc_nm = data['pblanc_nm'][:50] + "..." if len(data['pblanc_nm']) > 50 else data['pblanc_nm']
        dtl_url = data.get('dtl_url')
        
        print(f"[{idx}/{total}] {pblanc_nm}")
        
        # ì´ë¯¸ ì²¨ë¶€íŒŒì¼ì´ ìˆëŠ” ê²½ìš° íƒ€ì…ë§Œ ìˆ˜ì •
        if current_attachments and has_problem:
            print(f"  [{idx}] ê¸°ì¡´ ì²¨ë¶€íŒŒì¼ íƒ€ì… ìˆ˜ì • ì¤‘...")
            
            # ìƒì„¸ í˜ì´ì§€ì—ì„œ ì‹¤ì œ íŒŒì¼ëª… ê°€ì ¸ì˜¤ê¸°
            if dtl_url:
                try:
                    response = session.get(dtl_url, timeout=15)
                    response.encoding = 'utf-8'
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    # div.file_nameì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
                    file_names_map = {}
                    file_names = soup.find_all('div', class_='file_name')
                    
                    for i, file_div in enumerate(file_names):
                        filename = file_div.get_text(strip=True)
                        filename = clean_filename(filename)
                        if filename:
                            file_names_map[i] = filename
                    
                    # title ì†ì„±ì—ì„œë„ íŒŒì¼ëª… ì¶”ì¶œ
                    download_links = soup.find_all('a', href=lambda x: x and 'atchFileId' in x)
                    for link in download_links:
                        title = link.get('title', '')
                        if title and 'ì²¨ë¶€íŒŒì¼' in title:
                            filename = re.sub(r'^ì²¨ë¶€íŒŒì¼\s*', '', title)
                            filename = re.sub(r'\s*ë‹¤ìš´ë¡œë“œ$', '', filename)
                            if filename:
                                # atchFileIdë¡œ ë§¤í•‘
                                href = link.get('href', '')
                                if 'atchFileId=' in href:
                                    atch_file_id = href.split('atchFileId=')[1].split('&')[0]
                                    file_sn = '0'
                                    if 'fileSn=' in href:
                                        file_sn = href.split('fileSn=')[1].split('&')[0]
                                    key = f"{atch_file_id}_{file_sn}"
                                    file_names_map[key] = filename
                    
                    # ê¸°ì¡´ ì²¨ë¶€íŒŒì¼ íƒ€ì… ìˆ˜ì •
                    updated_attachments = []
                    fixed_count = 0
                    
                    for i, att in enumerate(current_attachments):
                        if isinstance(att, dict):
                            new_att = att.copy()
                            
                            # ë¬¸ì œê°€ ìˆëŠ” íƒ€ì…ì¸ ê²½ìš°
                            if att.get('type') in ['UNKNOWN', 'HTML', 'DOC']:
                                # íŒŒì¼ëª… ì°¾ê¸°
                                actual_filename = None
                                
                                # 1. file_names_mapì—ì„œ ì°¾ê¸°
                                if i in file_names_map:
                                    actual_filename = file_names_map[i]
                                elif att.get('params'):
                                    key = f"{att['params'].get('atchFileId', '')}_{att['params'].get('fileSn', '0')}"
                                    if key in file_names_map:
                                        actual_filename = file_names_map[key]
                                
                                # 2. íŒŒì¼ëª…ì—ì„œ íƒ€ì… ì¶”ì¶œ
                                if actual_filename:
                                    actual_type = extract_file_type_from_filename(actual_filename)
                                    new_att['display_filename'] = actual_filename
                                    new_att['original_filename'] = actual_filename
                                else:
                                    # íŒŒì¼ ì‹œê·¸ë‹ˆì²˜ë¡œ í™•ì¸ (í´ë°±)
                                    actual_type = get_file_type_by_signature(att.get('url'), session)
                                
                                # 3. ì—¬ì „íˆ UNKNOWNì´ë©´ HWPë¡œ ê°€ì • (í•œêµ­ ê³µê³µê¸°ê´€)
                                if actual_type in ['UNKNOWN', 'HTML']:
                                    actual_type = 'HWP'
                                
                                if att.get('type') != actual_type:
                                    new_att['type'] = actual_type
                                    new_att['safe_filename'] = f"{pblanc_id}_{i+1:02d}.{actual_type.lower()}"
                                    fixed_count += 1
                                    print(f"    - {att.get('type')} â†’ {actual_type} ({actual_filename if actual_filename else 'signature'})")
                            
                            updated_attachments.append(new_att)
                        else:
                            updated_attachments.append(att)
                    
                    if fixed_count > 0:
                        # DB ì—…ë°ì´íŠ¸
                        result = supabase.table('bizinfo_complete').update({
                            'attachment_urls': updated_attachments
                        }).eq('id', data['id']).execute()
                        
                        with lock:
                            success_count += 1
                            type_fixed += fixed_count
                        
                        print(f"  [{idx}] âœ… íƒ€ì… ìˆ˜ì •: {fixed_count}ê°œ")
                        return True
                        
                except Exception as e:
                    print(f"  [{idx}] âš ï¸ í˜ì´ì§€ íŒŒì‹± ì‹¤íŒ¨: {str(e)[:30]}")
            
            print(f"  [{idx}] â­ï¸ ìˆ˜ì •í•  íƒ€ì… ì—†ìŒ")
            return False
        
        # ìƒˆë¡œ í¬ë¡¤ë§ì´ í•„ìš”í•œ ê²½ìš°
        if not dtl_url:
            print(f"  [{idx}] âš ï¸ ìƒì„¸ URL ì—†ìŒ")
            return False
        
        # ì¬ì‹œë„ ë¡œì§
        max_retries = 3
        for retry in range(max_retries):
            try:
                response = session.get(dtl_url, timeout=15)
                response.encoding = 'utf-8'
                
                if response.status_code != 200:
                    if retry < max_retries - 1:
                        time.sleep(2)
                        continue
                    with lock:
                        error_count += 1
                    return False
                
                break
            except requests.exceptions.RequestException as e:
                if retry < max_retries - 1:
                    time.sleep(3)
                    continue
                print(f"  [{idx}] âŒ ì—°ê²° ì‹¤íŒ¨")
                with lock:
                    error_count += 1
                return False
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ì²¨ë¶€íŒŒì¼ ì •ë³´ ì¶”ì¶œ
        attachments = []
        unique_files = {}
        
        # ë°©ë²• 1: file_name í´ë˜ìŠ¤ë¥¼ ê°€ì§„ div ì°¾ê¸° (ê°€ì¥ ì •í™•)
        file_names = soup.find_all('div', class_='file_name')
        
        for file_div in file_names:
            filename = file_div.get_text(strip=True)
            filename = clean_filename(filename)
            
            if filename:
                # ê°™ì€ ë¶€ëª¨ë‚˜ í˜•ì œì—ì„œ ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ê¸°
                parent = file_div.parent
                if parent:
                    download_link = parent.find('a', href=lambda x: x and 'atchFileId' in x)
                    
                    if download_link:
                        href = download_link.get('href', '')
                        
                        # atchFileId ì¶”ì¶œ
                        atch_file_id = ''
                        file_sn = '0'
                        if 'atchFileId=' in href:
                            atch_file_id = href.split('atchFileId=')[1].split('&')[0]
                        if 'fileSn=' in href:
                            file_sn = href.split('fileSn=')[1].split('&')[0]
                        
                        if atch_file_id:
                            direct_url = f"https://www.bizinfo.go.kr/cmm/fms/getImageFile.do?atchFileId={atch_file_id}&fileSn={file_sn}"
                            
                            unique_key = f"{atch_file_id}_{file_sn}"
                            if unique_key not in unique_files:
                                file_type = extract_file_type_from_filename(filename)
                                
                                attachment = {
                                    'url': direct_url,
                                    'type': file_type,
                                    'safe_filename': f"{pblanc_id}_{len(attachments)+1:02d}.{file_type.lower()}",
                                    'display_filename': filename,
                                    'original_filename': filename,
                                    'text': filename,
                                    'params': {
                                        'atchFileId': atch_file_id,
                                        'fileSn': file_sn
                                    }
                                }
                                
                                unique_files[unique_key] = attachment
                                attachments.append(attachment)
        
        # ë°©ë²• 2: title ì†ì„±ì´ ìˆëŠ” ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ê¸° (ë°±ì—…)
        if not attachments:
            download_links = soup.find_all('a', href=lambda x: x and 'atchFileId' in x)
            
            for link in download_links:
                href = link.get('href', '')
                title = link.get('title', '')  # title ì†ì„±ì— íŒŒì¼ëª…ì´ ìˆìŒ
                text = link.get_text(strip=True)
                
                # íŒŒì¼ëª… ê²°ì • (ìš°ì„ ìˆœìœ„: title > text)
                filename = None
                if title and 'ì²¨ë¶€íŒŒì¼' in title:
                    # "ì²¨ë¶€íŒŒì¼ íŒŒì¼ëª….hwp ë‹¤ìš´ë¡œë“œ" í˜•íƒœ
                    filename = re.sub(r'^ì²¨ë¶€íŒŒì¼\s*', '', title)
                    filename = re.sub(r'\s*ë‹¤ìš´ë¡œë“œ$', '', filename)
                elif title:
                    filename = title
                elif text and text != 'ë‹¤ìš´ë¡œë“œ':
                    filename = text
                
                if filename:
                    filename = clean_filename(filename)
                
                # atchFileId ì¶”ì¶œ
                atch_file_id = ''
                file_sn = '0'
                if 'atchFileId=' in href:
                    atch_file_id = href.split('atchFileId=')[1].split('&')[0]
                if 'fileSn=' in href:
                    file_sn = href.split('fileSn=')[1].split('&')[0]
                
                if atch_file_id:
                    unique_key = f"{atch_file_id}_{file_sn}"
                    
                    if unique_key not in unique_files:
                        direct_url = f"https://www.bizinfo.go.kr/cmm/fms/getImageFile.do?atchFileId={atch_file_id}&fileSn={file_sn}"
                        
                        file_type = extract_file_type_from_filename(filename) if filename else 'UNKNOWN'
                        
                        # UNKNOWNì´ë©´ HWPë¡œ ê°€ì • (í•œêµ­ ê³µê³µê¸°ê´€)
                        if file_type == 'UNKNOWN':
                            file_type = 'HWP'
                        
                        attachment = {
                            'url': direct_url,
                            'type': file_type,
                            'safe_filename': f"{pblanc_id}_{len(attachments)+1:02d}.{file_type.lower()}",
                            'display_filename': filename or f"ì²¨ë¶€íŒŒì¼_{len(attachments)+1}",
                            'original_filename': filename or text,
                            'text': text,
                            'params': {
                                'atchFileId': atch_file_id,
                                'fileSn': file_sn
                            }
                        }
                        
                        unique_files[unique_key] = attachment
                        attachments.append(attachment)
        
        # ìš”ì•½ ìƒì„±/ê°œì„ 
        if not current_summary or len(current_summary) < 150:
            summary_parts = []
            summary_parts.append(f"ğŸ“‹ {data['pblanc_nm']}")
            
            # ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ
            content_selectors = [
                'div.view_cont', 'div.content', 'div.board_view',
                'td.content', 'td.view_cont'
            ]
            
            for selector in content_selectors:
                content_area = soup.select_one(selector)
                if content_area:
                    text = content_area.get_text(separator=' ', strip=True)
                    if text and len(text) > 50:
                        content_text = ' '.join(text.split())[:400]
                        summary_parts.append(f"ğŸ“ {content_text}...")
                        break
            
            if attachments:
                file_types = list(set([a['type'] for a in attachments]))
                summary_parts.append(f"ğŸ“ ì²¨ë¶€: {', '.join(file_types)} ({len(attachments)}ê°œ)")
            
            new_summary = "\n".join(summary_parts)
        else:
            new_summary = current_summary
        
        # DB ì—…ë°ì´íŠ¸
        update_data = {}
        
        if attachments and not current_attachments:
            update_data['attachment_urls'] = attachments
            with lock:
                attachment_total += len(attachments)
        
        if len(new_summary) > len(current_summary):
            update_data['bsns_sumry'] = new_summary
        
        if update_data:
            result = supabase.table('bizinfo_complete').update(
                update_data
            ).eq('id', data['id']).execute()
            
            with lock:
                success_count += 1
            
            if attachments:
                type_counts = {}
                for att in attachments:
                    file_type = att.get('type', 'UNKNOWN')
                    type_counts[file_type] = type_counts.get(file_type, 0) + 1
                type_info = ', '.join([f"{t}:{c}" for t, c in type_counts.items()])
                print(f"  [{idx}] âœ… ì„±ê³µ (ì²¨ë¶€: {len(attachments)}ê°œ [{type_info}])")
            else:
                print(f"  [{idx}] âœ… ì„±ê³µ")
            return True
        else:
            with lock:
                skip_count += 1
            print(f"  [{idx}] â­ï¸ ë³€ê²½ì‚¬í•­ ì—†ìŒ")
            return False
        
    except Exception as e:
        with lock:
            error_count += 1
        print(f"  [{idx}] âŒ ì˜¤ë¥˜: {str(e)[:50]}")
        return False
    finally:
        session.close()

def main():
    global success_count, error_count, attachment_total, skip_count, type_fixed
    
    print("=" * 60)
    print(" ê¸°ì—…ë§ˆë‹¹ ì²¨ë¶€íŒŒì¼ ì •í™•í•œ íŒŒì¼ëª… ì¶”ì¶œ v3")
    print(" - div.file_nameì—ì„œ ì‹¤ì œ íŒŒì¼ëª… ì¶”ì¶œ")
    print(" - title ì†ì„±ì—ì„œ íŒŒì¼ëª… í™•ì¸")
    print(" - DOC/HTML â†’ ì •í™•í•œ íƒ€ì…ìœ¼ë¡œ ìˆ˜ì •")
    print("=" * 60)
    
    # Supabase ì—°ê²°
    supabase_url = os.environ.get('SUPABASE_URL')
    supabase_key = os.environ.get('SUPABASE_KEY') or os.environ.get('SUPABASE_SERVICE_KEY')
    
    if not supabase_url or not supabase_key:
        print("âŒ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    
    supabase = create_client(supabase_url, supabase_key)
    
    # ì²˜ë¦¬ ëŒ€ìƒ ì¡°íšŒ
    print("1. ì²˜ë¦¬ ëŒ€ìƒ ì¡°íšŒ ì¤‘...")
    try:
        all_targets = []
        offset = 0
        limit = 1000
        
        while True:
            response = supabase.table('bizinfo_complete').select(
                'id', 'pblanc_id', 'pblanc_nm', 'dtl_url', 'bsns_sumry', 'attachment_urls'
            ).range(offset, offset + limit - 1).execute()
            
            if not response.data:
                break
                
            all_targets.extend(response.data)
            offset += limit
            
            if len(all_targets) >= 5000:
                break
        
        # ì²˜ë¦¬ ëŒ€ìƒ ë¶„ë¥˜
        targets = []
        unknown_count = 0
        html_count = 0
        doc_count = 0
        already_done = 0
        
        for item in all_targets:
            bsns_sumry = item.get('bsns_sumry', '')
            attachment_urls = item.get('attachment_urls')
            
            # ì²¨ë¶€íŒŒì¼ì˜ íƒ€ì… ì²´í¬
            needs_fix = False
            if attachment_urls:
                for att in attachment_urls:
                    if isinstance(att, dict):
                        file_type = att.get('type')
                        if file_type == 'UNKNOWN':
                            unknown_count += 1
                            needs_fix = True
                        elif file_type == 'HTML':
                            html_count += 1
                            needs_fix = True
                        elif file_type == 'DOC':
                            doc_count += 1
                            needs_fix = True
            
            # ìˆ˜ì •ì´ í•„ìš”í•˜ê±°ë‚˜ ìš”ì•½ì´ ë¶€ì¡±í•œ ê²½ìš°
            if needs_fix or (not bsns_sumry or len(bsns_sumry) < 150) or (not attachment_urls):
                targets.append(item)
            else:
                already_done += 1
        
        print(f"âœ… ì „ì²´: {len(all_targets)}ê°œ")
        print(f"âš ï¸ UNKNOWN íƒ€ì…: {unknown_count}ê°œ")
        print(f"âš ï¸ HTML íƒ€ì…: {html_count}ê°œ")
        print(f"âš ï¸ DOC íƒ€ì…: {doc_count}ê°œ (ëŒ€ë¶€ë¶„ HWPì¼ ê°€ëŠ¥ì„±)")
        print(f"âœ… ì •ìƒ ì²˜ë¦¬: {already_done}ê°œ")
        print(f"ğŸ”§ ì²˜ë¦¬ í•„ìš”: {len(targets)}ê°œ")
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        sys.exit(1)
    
    if not targets:
        print("ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("\n2. íŒŒì¼ëª… ì¶”ì¶œ ë° íƒ€ì… ìˆ˜ì • ì‹œì‘...")
    print(f"   - div.file_nameì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ")
    print(f"   - title ì†ì„±ì—ì„œ íŒŒì¼ëª… í™•ì¸")
    print(f"   - ì˜ˆìƒ ì‹œê°„: {len(targets) // 3}ë¶„")
    print("-" * 60)
    
    start_time = time.time()
    
    # ë°°ì¹˜ ì²˜ë¦¬
    batch_size = 50
    for batch_start in range(0, len(targets), batch_size):
        batch_end = min(batch_start + batch_size, len(targets))
        batch = targets[batch_start:batch_end]
        
        print(f"\në°°ì¹˜ ì²˜ë¦¬: {batch_start+1}-{batch_end}/{len(targets)}")
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = []
            for i, data in enumerate(batch, batch_start + 1):
                future = executor.submit(process_item, data, i, len(targets), supabase)
                futures.append(future)
                time.sleep(0.3)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
            
            for future in as_completed(futures):
                future.result()
        
        if batch_end < len(targets):
            print(f"ë°°ì¹˜ ì™„ë£Œ. 3ì´ˆ ëŒ€ê¸°...")
            time.sleep(3)
    
    elapsed_time = time.time() - start_time
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print(" íŒŒì¼ëª… ì¶”ì¶œ ë° íƒ€ì… ìˆ˜ì • ì™„ë£Œ")
    print("=" * 60)
    print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"ğŸ”§ íƒ€ì… ìˆ˜ì •: {type_fixed}ê°œ íŒŒì¼")
    print(f"â­ï¸ ìŠ¤í‚µ: {skip_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {error_count}ê°œ")
    print(f"ğŸ“ ìƒˆ ì²¨ë¶€íŒŒì¼: {attachment_total}ê°œ")
    print(f"â±ï¸ ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ ({elapsed_time/60:.1f}ë¶„)")
    if success_count > 0:
        print(f"ğŸ“Š ì²˜ë¦¬ ì†ë„: {success_count/elapsed_time:.1f}ê°œ/ì´ˆ")
    print("=" * 60)

if __name__ == "__main__":
    main()
