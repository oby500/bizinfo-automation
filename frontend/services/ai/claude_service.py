# services/ai/claude_service.py
"""
Claude Sonnet 4.5 AI ì„œë¹„ìŠ¤ (Token Optimized)

ë‹´ë‹¹ ê¸°ëŠ¥:
1. ê³µê³ ë¬¸ ë¶„ì„ (Y â†’ ìê²©ìš”ê±´, í‰ê°€ê¸°ì¤€, ì‘ì„±ì „ëµ)
2. íšŒì‚¬ ë¶„ì„ (Y + Z â†’ ê°•ì , ì•½ì , ì°¨ë³„í™”)
3. ìŠ¤íƒ€ì¼ ì¶”ì²œ (ë¶„ì„ ê²°ê³¼ â†’ ìµœì  ìŠ¤íƒ€ì¼)

ëª¨ë¸: claude-sonnet-4-5-20250929
ê°€ê²©: Input $3/1M tokens, Output $15/1M tokens
ìµœì í™”: metadata.sections ê¸°ë°˜ ì¤‘ìš” ì„¹ì…˜ë§Œ ì¶”ì¶œ (53.1% í† í° ì ˆê°)
"""

from anthropic import Anthropic
from typing import Dict, Any, Optional
import json
import logging
import os
from datetime import datetime

# í”„ë¡¬í”„íŠ¸ ì„í¬íŠ¸
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from utils.prompts import (
    ANALYZE_ANNOUNCEMENT_PROMPT,
    ANALYZE_COMPANY_PROMPT,
    RECOMMEND_STYLE_PROMPT
)

logger = logging.getLogger(__name__)


class ClaudeService:
    """Claude Sonnet 4.5 AI ì„œë¹„ìŠ¤"""

    def __init__(self, api_key: Optional[str] = None):
        """
        Args:
            api_key: Anthropic API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
        """
        self.api_key = api_key or os.getenv("ANTHROPIC_API_KEY")
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY not found in environment variables")

        self.client = Anthropic(api_key=self.api_key)
        self.model = "claude-sonnet-4-5-20250929"

        # í† í° ê°€ê²© (USD per 1M tokens)
        self.input_price = 3.00
        self.output_price = 15.00

        logger.info(f"Claude service initialized with model: {self.model}")

    def analyze_announcement(
        self,
        full_text: str,
        parsed_info: Dict[str, Any],
        simple_summary: Optional[str] = None,
        detailed_summary: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ê³µê³ ë¬¸ ë¶„ì„ (Y ë¶„ì„)

        Args:
            full_text: ê³µê³ ë¬¸ ì „ì²´ í…ìŠ¤íŠ¸
            parsed_info: ê³µê³ ë¬¸ êµ¬ì¡°í™” ë°ì´í„° (JSONB)
            simple_summary: ê°„ë‹¨ ìš”ì•½ (ì„ íƒ)
            detailed_summary: ìƒì„¸ ìš”ì•½ (ì„ íƒ)

        Returns:
            {
                "ìê²©ìš”ê±´": [...],
                "í‰ê°€ê¸°ì¤€": [...],
                "ì‹¬ì‚¬ìœ„ì›_í”„ë¡œíŒŒì¼": {...},
                "í•µì‹¬í‚¤ì›Œë“œ": {...},
                "ê²½ìŸê°•ë„": {...},
                "ì‘ì„±ì „ëµ": {...},
                "_metadata": {
                    "model": "claude-sonnet-4-5-20250929",
                    "input_tokens": 1500,
                    "output_tokens": 800,
                    "cost_usd": 0.0165,
                    "cost_krw": 23
                }
            }
        """
        print("=" * 80)
        print("DEBUG: claude_service.analyze_announcement() called!")
        print("=" * 80)
        try:
            logger.info("Starting announcement analysis with Claude")

            # parsed_info íƒ€ì… í™•ì¸ ë° JSON íŒŒì‹±
            if isinstance(parsed_info, str):
                logger.info("parsed_info is string, parsing JSON...")
                try:
                    parsed_info = json.loads(parsed_info)
                except json.JSONDecodeError as e:
                    logger.warning(f"Failed to parse parsed_info as JSON: {e}")
                    parsed_info = {}

            logger.info(f"parsed_info type: {type(parsed_info)}, keys: {list(parsed_info.keys()) if isinstance(parsed_info, dict) else 'N/A'}")

            # parsed_infoì—ì„œ metadataì˜ sections ì¶”ì¶œ
            metadata = parsed_info.get("metadata", {})
            sections = metadata.get("sections", [])

            # full_textë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
            lines = full_text.split('\n') if full_text else []
            total_lines = len(lines)

            logger.info(f"Full text: {len(full_text)} chars, {total_lines} lines")

            # ì¤‘ìš” ì„¹ì…˜ ì¶”ì¶œ (critical ë° high importance)
            important_sections = []
            extracted_texts = []

            for section in sections:
                importance = section.get("i", "")
                if importance in ["critical", "high"]:
                    line_range = section.get("l", "")
                    category = section.get("c", "")
                    keywords = section.get("k", [])

                    # ë©”íƒ€ë°ì´í„° ì €ì¥
                    important_sections.append({
                        "category": category,
                        "importance": importance,
                        "keywords": keywords,
                        "line_range": line_range
                    })

                    # line_range íŒŒì‹±í•˜ì—¬ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì˜ˆ: "1-22" â†’ lines[0:22])
                    if line_range and "-" in line_range:
                        try:
                            start, end = map(int, line_range.split("-"))
                            if 1 <= start <= total_lines and 1 <= end <= total_lines:
                                # ì¤„ ë²ˆí˜¸ëŠ” 1-based, Python ì¸ë±ìŠ¤ëŠ” 0-based
                                section_text = '\n'.join(lines[start-1:end])
                                extracted_texts.append(f"[{category or 'section'}]\n{section_text}")
                        except (ValueError, IndexError) as e:
                            logger.warning(f"Failed to parse line range '{line_range}': {e}")
                            continue

            sections_str = json.dumps(important_sections, ensure_ascii=False, indent=2)

            # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê²°í•© (í† í° ìµœì í™”)
            optimized_text = '\n\n'.join(extracted_texts) if extracted_texts else full_text[:5000]

            original_length = len(full_text)
            optimized_length = len(optimized_text)
            reduction_pct = (1 - optimized_length / original_length) * 100 if original_length > 0 else 0

            logger.info(f"Token optimization: {len(important_sections)} important sections extracted")
            logger.info(f"Text reduction: {original_length} â†’ {optimized_length} chars ({reduction_pct:.1f}% reduced)")

            # í”„ë¡¬í”„íŠ¸ ìƒì„± (optimized_text ì‚¬ìš©)
            prompt = ANALYZE_ANNOUNCEMENT_PROMPT.format(
                full_text=optimized_text,
                simple_summary=simple_summary or "(ì—†ìŒ)",
                detailed_summary=detailed_summary or "(ì—†ìŒ)",
                parsed_info_content_map=sections_str
            )

            logger.debug(f"Prompt length: {len(prompt)} characters")

            # Claude API í˜¸ì¶œ
            response = self.client.messages.create(
                model=self.model,
                max_tokens=16384,  # ìƒì„¸í•œ JSON ì‘ë‹µì„ ìœ„í•´ ì¦ê°€
                temperature=0.3,  # ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ë‚®ì€ temperature
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )

            # ì‘ë‹µ íŒŒì‹±
            analysis_text = response.content[0].text
            logger.debug(f"Response length: {len(analysis_text)} characters")

            # í† í° ì‚¬ìš©ëŸ‰ ë¨¼ì € ë¡œê¹… (JSON íŒŒì‹± ì „ì— í™•ì¸)
            input_tokens = response.usage.input_tokens
            output_tokens = response.usage.output_tokens
            cost_usd = self._calculate_cost(input_tokens, output_tokens)
            cost_krw = int(cost_usd * 1400)  # 1 USD = 1400 KRW

            # ğŸ” í† í° ì‚¬ìš©ëŸ‰ ìƒì„¸ ë¡œê¹…
            logger.info(f"=" * 80)
            logger.info(f"Claude Token Usage:")
            logger.info(f"  Input tokens:  {input_tokens:,}")
            logger.info(f"  Output tokens: {output_tokens:,} / {16384:,} (max)")
            logger.info(f"  Used: {output_tokens / 16384 * 100:.1f}%")
            logger.info(f"  Response length: {len(analysis_text):,} chars")
            logger.info(f"  Cost: ${cost_usd:.4f} (â‚©{cost_krw:,})")
            logger.info(f"=" * 80)

            # JSON ì¶”ì¶œ (```json ... ``` ì œê±°)
            analysis_json = self._extract_json(analysis_text)

            # â­ í•„ìˆ˜ í•„ë“œ ê²€ì¦ (ê³¼ì œëª©ë¡, í•„ìˆ˜ì •ë³´)
            if "ê³¼ì œëª©ë¡" not in analysis_json:
                logger.warning("âš ï¸ AI did not return 'ê³¼ì œëª©ë¡' field! Adding empty array.")
                analysis_json["ê³¼ì œëª©ë¡"] = []

            if "í•„ìˆ˜ì •ë³´" not in analysis_json:
                logger.warning("âš ï¸ AI did not return 'í•„ìˆ˜ì •ë³´' field! Adding default values.")
                analysis_json["í•„ìˆ˜ì •ë³´"] = [
                    "íšŒì‚¬ëª…", "ì„¤ë¦½ì—°ë„", "ëŒ€í‘œìëª…",
                    "ì£¼ìš” ì‚¬ì—… ë‚´ìš©", "ë§¤ì¶œì•¡", "ì§ì› ìˆ˜", "ê¸°ìˆ ë ¥ ì¦ë¹™",
                    "íŠ¹í—ˆ ë³´ìœ  í˜„í™©", "ì¬ë¬´ ìƒíƒœ", "ì‚¬ì—… ëª©ì "
                ]
            elif len(analysis_json["í•„ìˆ˜ì •ë³´"]) < 10:
                logger.warning(f"âš ï¸ AI returned only {len(analysis_json['í•„ìˆ˜ì •ë³´'])} items in 'í•„ìˆ˜ì •ë³´' (expected â‰¥10)")

            # ê³¼ì œëª©ë¡ í•„ë“œ íƒ€ì… ê²€ì¦
            if not isinstance(analysis_json["ê³¼ì œëª©ë¡"], list):
                logger.error(f"âš ï¸ 'ê³¼ì œëª©ë¡' is not a list! Type: {type(analysis_json['ê³¼ì œëª©ë¡'])}")
                analysis_json["ê³¼ì œëª©ë¡"] = []

            # í•„ìˆ˜ì •ë³´ í•„ë“œ íƒ€ì… ê²€ì¦
            if not isinstance(analysis_json["í•„ìˆ˜ì •ë³´"], list):
                logger.error(f"âš ï¸ 'í•„ìˆ˜ì •ë³´' is not a list! Type: {type(analysis_json['í•„ìˆ˜ì •ë³´'])}")
                analysis_json["í•„ìˆ˜ì •ë³´"] = [
                    "íšŒì‚¬ëª…", "ì„¤ë¦½ì—°ë„", "ëŒ€í‘œìëª…",
                    "ì£¼ìš” ì‚¬ì—… ë‚´ìš©", "ë§¤ì¶œì•¡", "ì§ì› ìˆ˜", "ê¸°ìˆ ë ¥ ì¦ë¹™",
                    "íŠ¹í—ˆ ë³´ìœ  í˜„í™©", "ì¬ë¬´ ìƒíƒœ", "ì‚¬ì—… ëª©ì "
                ]

            # ê³¼ì œëª©ë¡ ë¡œê¹…
            logger.info(f"âœ… ê³¼ì œëª©ë¡: {len(analysis_json['ê³¼ì œëª©ë¡'])}ê°œ ê³¼ì œ ê°ì§€")
            if len(analysis_json["ê³¼ì œëª©ë¡"]) > 0:
                for task in analysis_json["ê³¼ì œëª©ë¡"]:
                    logger.info(f"   - ê³¼ì œ {task.get('task_number')}: {task.get('task_name')}")

            # í•„ìˆ˜ì •ë³´ ë¡œê¹…
            logger.info(f"âœ… í•„ìˆ˜ì •ë³´: {len(analysis_json['í•„ìˆ˜ì •ë³´'])}ê°œ í•­ëª©")

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            analysis_json["_metadata"] = {
                "model": self.model,
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "cost_usd": round(cost_usd, 4),
                "cost_krw": cost_krw,
                "analyzed_at": datetime.now().isoformat()
            }

            logger.info(f"Analysis completed. Tokens: {input_tokens}+{output_tokens}, Cost: ${cost_usd:.4f}")

            return analysis_json

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Claude response as JSON: {str(e)}")
            logger.error(f"Raw response: {analysis_text[:500]}...")
            raise ValueError(f"Claude ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

        except Exception as e:
            logger.error(f"Announcement analysis failed: {str(e)}")
            raise

    def analyze_company(
        self,
        announcement_analysis: Dict[str, Any],
        company_info: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        íšŒì‚¬ ë¶„ì„ (Z ë¶„ì„)

        Args:
            announcement_analysis: ê³µê³  ë¶„ì„ ê²°ê³¼
            company_info: íšŒì‚¬ ì •ë³´ (Z)

        Returns:
            {
                "ê°•ì ë¶„ì„": [...],
                "ì•½ì ë¶„ì„": [...],
                "ì°¨ë³„í™”í¬ì¸íŠ¸": [...],
                "ë¦¬ìŠ¤í¬ì²´í¬": {...},
                "ìµœì¢…ì „ëµ": {...},
                "_metadata": {...}
            }
        """
        try:
            logger.info("Starting company analysis with Claude")

            # JSON ì§ë ¬í™”
            announcement_json = json.dumps(announcement_analysis, ensure_ascii=False, indent=2)
            company_json = json.dumps(company_info, ensure_ascii=False, indent=2)

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = ANALYZE_COMPANY_PROMPT.format(
                announcement_analysis=announcement_json,
                company_info=company_json
            )

            logger.debug(f"Prompt length: {len(prompt)} characters")

            # Claude API í˜¸ì¶œ
            response = self.client.messages.create(
                model=self.model,
                max_tokens=16384,  # ìƒì„¸í•œ JSON ì‘ë‹µì„ ìœ„í•´ ì¦ê°€ (ê³µê³ ë¶„ì„ê³¼ ë™ì¼)
                temperature=0.3,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )

            # ì‘ë‹µ íŒŒì‹±
            analysis_text = response.content[0].text
            logger.debug(f"Response length: {len(analysis_text)} characters")

            # JSON ì¶”ì¶œ
            analysis_json = self._extract_json(analysis_text)

            # í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ê³„ì‚°
            input_tokens = response.usage.input_tokens
            output_tokens = response.usage.output_tokens
            cost_usd = self._calculate_cost(input_tokens, output_tokens)
            cost_krw = int(cost_usd * 1400)

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            analysis_json["_metadata"] = {
                "model": self.model,
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "cost_usd": round(cost_usd, 4),
                "cost_krw": cost_krw,
                "analyzed_at": datetime.now().isoformat()
            }

            logger.info(f"Company analysis completed. Tokens: {input_tokens}+{output_tokens}, Cost: ${cost_usd:.4f}")

            return analysis_json

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Claude response as JSON: {str(e)}")
            raise ValueError(f"Claude ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

        except Exception as e:
            logger.error(f"Company analysis failed: {str(e)}")
            raise

    def recommend_style(
        self,
        announcement_analysis: Dict[str, Any],
        company_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ìŠ¤íƒ€ì¼ ì¶”ì²œ (Standard, Premium ì „ìš©)

        Args:
            announcement_analysis: ê³µê³  ë¶„ì„ ê²°ê³¼
            company_analysis: íšŒì‚¬ ë¶„ì„ ê²°ê³¼

        Returns:
            {
                "recommended_style": "data",
                "analysis": [
                    {
                        "style": "data",
                        "score": 85,
                        "pros": [...],
                        "cons": [...]
                    },
                    ...
                ],
                "final_recommendation": {
                    "style": "data",
                    "reason": "...",
                    "expected_improvement": "..."
                },
                "_metadata": {...}
            }
        """
        try:
            logger.info("Starting style recommendation with Claude")

            # JSON ì§ë ¬í™”
            announcement_json = json.dumps(announcement_analysis, ensure_ascii=False, indent=2)
            company_json = json.dumps(company_analysis, ensure_ascii=False, indent=2)

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = RECOMMEND_STYLE_PROMPT.format(
                announcement_analysis=announcement_json,
                company_analysis=company_json
            )

            logger.debug(f"Prompt length: {len(prompt)} characters")

            # Claude API í˜¸ì¶œ
            response = self.client.messages.create(
                model=self.model,
                max_tokens=2048,
                temperature=0.3,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )

            # ì‘ë‹µ íŒŒì‹±
            recommendation_text = response.content[0].text
            logger.debug(f"Response length: {len(recommendation_text)} characters")

            # JSON ì¶”ì¶œ
            recommendation_json = self._extract_json(recommendation_text)

            # í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ê³„ì‚°
            input_tokens = response.usage.input_tokens
            output_tokens = response.usage.output_tokens
            cost_usd = self._calculate_cost(input_tokens, output_tokens)
            cost_krw = int(cost_usd * 1400)

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            recommendation_json["_metadata"] = {
                "model": self.model,
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "cost_usd": round(cost_usd, 4),
                "cost_krw": cost_krw,
                "analyzed_at": datetime.now().isoformat()
            }

            logger.info(f"Style recommendation completed. Tokens: {input_tokens}+{output_tokens}, Cost: ${cost_usd:.4f}")

            return recommendation_json

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Claude response as JSON: {str(e)}")
            raise ValueError(f"Claude ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

        except Exception as e:
            logger.error(f"Style recommendation failed: {str(e)}")
            raise

    def _repair_truncated_json(self, json_str: str) -> str:
        """
        ì˜ë¦°(truncated) JSONì„ ë³µêµ¬í•˜ëŠ” ê·¼ë³¸ì  í•´ê²° ë¡œì§

        Claude APIê°€ max_tokens í•œë„ì— ë„ë‹¬í•˜ê±°ë‚˜ ì‘ë‹µì´ ì¤‘ê°„ì— ì˜ë ¸ì„ ë•Œ,
        Unterminated string, unclosed brackets ë“±ì˜ ì˜¤ë¥˜ë¥¼ ë³µêµ¬í•©ë‹ˆë‹¤.

        Args:
            json_str: ì˜ë¦° JSON ë¬¸ìì—´

        Returns:
            ë³µêµ¬ëœ JSON ë¬¸ìì—´
        """
        import re

        if not json_str:
            return json_str

        repaired = json_str.rstrip()

        # 1. ë¯¸ì™„ì„± ë¬¸ìì—´ ë‹«ê¸° (ë”°ì˜´í‘œ ê°œìˆ˜ ì²´í¬)
        quote_count = 0
        in_escape = False
        last_quote_pos = -1

        for i, char in enumerate(repaired):
            if in_escape:
                in_escape = False
                continue
            if char == '\\':
                in_escape = True
                continue
            if char == '"':
                quote_count += 1
                last_quote_pos = i

        # ë”°ì˜´í‘œê°€ í™€ìˆ˜ë©´ ë¬¸ìì—´ì´ ì•ˆ ë‹«íŒ ê²ƒ
        if quote_count % 2 == 1:
            # ì´ìŠ¤ì¼€ì´í”„ ì•ˆëœ ë°±ìŠ¬ë˜ì‹œë¡œ ëë‚˜ë©´ ì œê±°
            if repaired.endswith('\\') and not repaired.endswith('\\\\'):
                repaired = repaired[:-1]
            # ë‹«ëŠ” ë”°ì˜´í‘œ ì¶”ê°€
            repaired += '"'
            logger.info(f"[JSONë³µêµ¬] ë¯¸ì™„ì„± ë¬¸ìì—´ ë‹«ê¸° ì™„ë£Œ (ìœ„ì¹˜: {last_quote_pos})")

        # 2. trailing comma ì œê±° (JSONì—ì„œ í—ˆìš©ë˜ì§€ ì•ŠìŒ)
        repaired = re.sub(r',\s*$', '', repaired)
        repaired = re.sub(r',\s*([}\]])', r'\1', repaired)

        # 3. ë¯¸ì™„ì„± í‚¤-ê°’ ìŒ ì •ë¦¬
        # "key": ë¡œ ëë‚˜ë©´ null ì¶”ê°€
        repaired = re.sub(r'("[\w_]+"\s*:\s*)$', r'\1null', repaired)
        # "key": " ë¡œ ëë‚˜ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ë‹«ê¸°
        repaired = re.sub(r'("[\w_]+"\s*:\s*")$', r'\1"', repaired)

        # 4. ë¯¸ì™„ì„± ë°°ì—´/ê°ì²´ ë‹«ê¸°
        open_braces = repaired.count('{') - repaired.count('}')
        open_brackets = repaired.count('[') - repaired.count(']')

        # ë¨¼ì € ë°°ì—´ ë‹«ê¸°, ê·¸ ë‹¤ìŒ ê°ì²´ ë‹«ê¸°
        if open_brackets > 0:
            repaired += ']' * open_brackets
            logger.info(f"[JSONë³µêµ¬] ë¯¸ì™„ì„± ë°°ì—´ {open_brackets}ê°œ ë‹«ê¸° ì™„ë£Œ")
        if open_braces > 0:
            repaired += '}' * open_braces
            logger.info(f"[JSONë³µêµ¬] ë¯¸ì™„ì„± ê°ì²´ {open_braces}ê°œ ë‹«ê¸° ì™„ë£Œ")

        return repaired

    def _extract_json(self, text: str) -> Dict[str, Any]:
        """
        Claude ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ (ê°•í™”ëœ ì—ëŸ¬ ë³µêµ¬ ë¡œì§)

        Args:
            text: Claude ì‘ë‹µ í…ìŠ¤íŠ¸ (```json ... ``` í¬í•¨ ê°€ëŠ¥)

        Returns:
            íŒŒì‹±ëœ JSON ë”•ì…”ë„ˆë¦¬
        """
        import re

        # ```json ... ``` ì œê±° (ë§ˆì§€ë§‰ ``` ì°¾ê¸° ê°œì„ )
        if "```json" in text:
            start = text.find("```json") + 7
            # ë§ˆì§€ë§‰ ```ë¥¼ ì°¾ì•„ì•¼ í•¨
            end = text.rfind("```")
            if end > start:
                json_str = text[start:end].strip()
            else:
                json_str = text[start:].strip()
        elif "```" in text:
            # ```ë§Œ ìˆëŠ” ê²½ìš°
            start = text.find("```") + 3
            end = text.rfind("```")
            if end > start:
                json_str = text[start:end].strip()
            else:
                json_str = text[start:].strip()
        else:
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì´ ì—†ëŠ” ê²½ìš°
            json_str = text.strip()

        try:
            # 1ë‹¨ê³„: ê¸°ë³¸ JSON íŒŒì‹± ì‹œë„
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            logger.warning(f"JSON íŒŒì‹± 1ì°¨ ì‹¤íŒ¨ (ìœ„ì¹˜: {e.pos}): {str(e)}")

            # ì—ëŸ¬ ìœ„ì¹˜ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ë¡œê¹…
            error_pos = e.pos if e.pos else 0
            context_start = max(0, error_pos - 100)
            context_end = min(len(json_str), error_pos + 100)
            logger.error(f"ì—ëŸ¬ ìœ„ì¹˜ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸:\n{json_str[context_start:context_end]}")

            try:
                # 1.5ë‹¨ê³„: ì˜ë¦° JSON ë³µêµ¬ ì‹œë„ (Unterminated string ë“±)
                logger.info("[ê·¼ë³¸í•´ê²°] ì˜ë¦°(truncated) JSON ë³µêµ¬ ì‹œë„ ì¤‘...")
                repaired_json = self._repair_truncated_json(json_str)
                if repaired_json != json_str:
                    logger.info(f"[ê·¼ë³¸í•´ê²°] JSON ë³µêµ¬ ì™„ë£Œ - ì›ë³¸: {len(json_str)}ì, ë³µêµ¬: {len(repaired_json)}ì")
                    try:
                        result = json.loads(repaired_json)
                        logger.info("[ê·¼ë³¸í•´ê²°] ë³µêµ¬ëœ JSON íŒŒì‹± ì„±ê³µ!")
                        return result
                    except json.JSONDecodeError as repair_error:
                        logger.warning(f"[ê·¼ë³¸í•´ê²°] ë³µêµ¬ëœ JSONë„ íŒŒì‹± ì‹¤íŒ¨: {str(repair_error)}")
                        # ë³µêµ¬ ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨í•˜ë©´ ê¸°ì¡´ ë¡œì§ìœ¼ë¡œ ì§„í–‰
                        pass

                # 2ë‹¨ê³„: JSON ë³µêµ¬ ì‹œë„ - ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì œ í•´ê²°
                logger.info("JSON ë³µêµ¬ ì‹œë„ ì¤‘ (ë©€í‹°ë¼ì¸ ë¬¸ìì—´ ì´ìŠ¤ì¼€ì´í”„)...")
                fixed_json = json_str

                # ì „ëµ: JSON í‚¤-ê°’ ìŒì—ì„œ ê°’ ë¶€ë¶„ì˜ ë¬¸ìì—´ì„ ì°¾ì•„ì„œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
                # "key": "value" íŒ¨í„´ ë§¤ì¹­ (valueëŠ” ë©€í‹°ë¼ì¸ ê°€ëŠ¥)
                def fix_string_value(match):
                    key = match.group(1)  # í‚¤ ì´ë¦„
                    value = match.group(2)  # ê°’ (ë”°ì˜´í‘œ í¬í•¨)

                    # ê°’ì´ ë¬¸ìì—´ì¸ ê²½ìš° (ë”°ì˜´í‘œë¡œ ì‹œì‘)
                    if value.startswith('"'):
                        # ë¬¸ìì—´ ë‚´ìš© ì¶”ì¶œ (ì‹œì‘/ë ë”°ì˜´í‘œ ì œì™¸)
                        try:
                            # ì´ë¯¸ ì˜¬ë°”ë¥´ê²Œ ì´ìŠ¤ì¼€ì´í”„ëœ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
                            json.loads(value)
                            return match.group(0)
                        except:
                            # ì´ìŠ¤ì¼€ì´í”„ í•„ìš”
                            string_content = value[1:-1] if value.endswith('"') else value[1:]

                            # ë°±ìŠ¬ë˜ì‹œë¥¼ ë¨¼ì € ì´ìŠ¤ì¼€ì´í”„ (ë‹¤ë¥¸ ì´ìŠ¤ì¼€ì´í”„ë¥¼ ë°©í•´í•˜ì§€ ì•Šë„ë¡)
                            string_content = string_content.replace('\\', '\\\\')
                            # ê·¸ ë‹¤ìŒ ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„
                            string_content = string_content.replace('"', '\\"')
                            # ê°œí–‰ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
                            string_content = string_content.replace('\n', '\\n')
                            # íƒ­ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
                            string_content = string_content.replace('\t', '\\t')
                            # ìºë¦¬ì§€ ë¦¬í„´ ì´ìŠ¤ì¼€ì´í”„
                            string_content = string_content.replace('\r', '\\r')

                            return f'"{key}": "{string_content}"'

                    return match.group(0)

                # íŒ¨í„´: "í‚¤": "ê°’" (ê°’ì€ ë©€í‹°ë¼ì¸ ê°€ëŠ¥, non-greedy)
                # re.DOTALLì„ ì‚¬ìš©í•˜ì—¬ .ì´ ê°œí–‰ ë¬¸ìë„ ë§¤ì¹­í•˜ë„ë¡
                fixed_json = re.sub(
                    r'"([^"]+)"\s*:\s*("(?:[^"\\]|\\.)*?"?)',
                    fix_string_value,
                    fixed_json,
                    flags=re.DOTALL
                )

                # trailing comma ì œê±° (JSONì—ì„œ í—ˆìš©ë˜ì§€ ì•ŠìŒ)
                fixed_json = re.sub(r',(\s*[}\]])', r'\1', fixed_json)

                return json.loads(fixed_json)

            except json.JSONDecodeError as e2:
                logger.warning(f"JSON ë³µêµ¬ 2ì°¨ ì‹¤íŒ¨: {str(e2)}")

                try:
                    # 3ë‹¨ê³„: ì£¼ì„ ì œê±° ì‹œë„
                    lines = []
                    for line in fixed_json.split('\n'):
                        # // ì£¼ì„ ì œê±°
                        if '//' in line:
                            line = line[:line.index('//')]
                        lines.append(line)

                    cleaned_json = '\n'.join(lines)
                    return json.loads(cleaned_json)

                except Exception as e3:
                    # ìµœì¢… ì‹¤íŒ¨ - ìƒì„¸í•œ ì—ëŸ¬ ë¡œê¹…
                    logger.error("=" * 80)
                    logger.error("JSON íŒŒì‹± ìµœì¢… ì‹¤íŒ¨")
                    logger.error("=" * 80)
                    logger.error(f"ì›ë³¸ ì‘ë‹µ ê¸¸ì´: {len(text)} ë¬¸ì")
                    logger.error(f"ì¶”ì¶œëœ JSON ê¸¸ì´: {len(json_str)} ë¬¸ì")
                    logger.error(f"ì›ë³¸ ì‘ë‹µ (ì²˜ìŒ 500ì):\n{text[:500]}")
                    logger.error(f"ì¶”ì¶œëœ JSON (ì²˜ìŒ 1000ì):\n{json_str[:1000]}")
                    logger.error(f"ì¶”ì¶œëœ JSON (ë§ˆì§€ë§‰ 500ì):\n{json_str[-500:]}")

                    # ìµœì¢… ì—ëŸ¬ ë°œìƒ
                    raise ValueError(
                        f"Claude ì‘ë‹µì—ì„œ JSONíŒŒì‹± ì‹¤íŒ¨: {str(e)}\n"
                        f"ì—ëŸ¬ ìœ„ì¹˜: line {e.lineno if hasattr(e, 'lineno') else 'N/A'}, "
                        f"column {e.colno if hasattr(e, 'colno') else 'N/A'}, "
                        f"char {e.pos if e.pos else 'N/A'}"
                    )

    def analyze_applications_for_upgrade(
        self,
        applications: list[Dict[str, Any]],
        announcement_analysis: Dict[str, Any],
        company_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Standard í‹°ì–´: 3ê°œ ì‹ ì²­ì„œ ë¶„ì„ â†’ 1ê°œ ì—…ê·¸ë ˆì´ë“œ ì¶”ì²œ

        Args:
            applications: 3ê°œ ê¸°ë³¸ ì‹ ì²­ì„œ (data, story, balanced)
            announcement_analysis: ê³µê³  ë¶„ì„ ê²°ê³¼
            company_analysis: íšŒì‚¬ ë¶„ì„ ê²°ê³¼

        Returns:
            {
                "best_application_index": 1,
                "upgrade_strategy": {
                    "strengths": [...],
                    "weaknesses": [...],
                    "improvements": [...]
                },
                "upgrade_prompt": "...",
                "_metadata": {...}
            }
        """
        try:
            logger.info("Starting Standard tier application analysis for upgrade")

            # ì‹ ì²­ì„œ ìš”ì•½
            apps_summary = []
            for i, app in enumerate(applications):
                apps_summary.append({
                    "index": i,
                    "style": app.get("style", "unknown"),
                    "content_preview": app.get("content", "")[:500]  # ì²« 500ìë§Œ
                })

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = f"""ë‹¹ì‹ ì€ ì •ë¶€ ì§€ì›ì‚¬ì—… ì‹ ì²­ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ 3ê°œì˜ ì‹ ì²­ì„œë¥¼ ë¶„ì„í•˜ê³ , **ê°€ì¥ ìš°ìˆ˜í•œ 1ê°œ**ë¥¼ ì„ íƒí•œ ë’¤, ê·¸ê²ƒì„ ë”ìš± ê°œì„ í•  ì „ëµì„ ì œì‹œí•˜ì„¸ìš”.

## ê³µê³  ë¶„ì„
{json.dumps(announcement_analysis, ensure_ascii=False, indent=2)}

## íšŒì‚¬ ë¶„ì„
{json.dumps(company_analysis, ensure_ascii=False, indent=2)}

## 3ê°œ ì‹ ì²­ì„œ
{json.dumps(apps_summary, ensure_ascii=False, indent=2)}

## ìš”êµ¬ì‚¬í•­
1. 3ê°œ ì‹ ì²­ì„œ ì¤‘ **ê°€ì¥ ìš°ìˆ˜í•œ 1ê°œ**ë¥¼ ì„ íƒ (best_application_index: 0, 1, 2)
2. ì„ íƒí•œ ì‹ ì²­ì„œì˜ ê°•ì , ì•½ì , ê°œì„  ë°©í–¥ì„ ë¶„ì„
3. GPT-4oê°€ ì—…ê·¸ë ˆì´ë“œ ìƒì„±ì— ì‚¬ìš©í•  êµ¬ì²´ì ì¸ í”„ë¡¬í”„íŠ¸ ì‘ì„±

## ì¶œë ¥ í˜•ì‹ (JSON)
```json
{{
  "best_application_index": 1,
  "upgrade_strategy": {{
    "strengths": ["ê°•ì  1", "ê°•ì  2", "ê°•ì  3"],
    "weaknesses": ["ì•½ì  1", "ì•½ì  2"],
    "improvements": ["ê°œì„  ë°©í–¥ 1", "ê°œì„  ë°©í–¥ 2", "ê°œì„  ë°©í–¥ 3"]
  }},
  "upgrade_prompt": "GPT-4oì—ê²Œ ì „ë‹¬í•  êµ¬ì²´ì ì¸ ì—…ê·¸ë ˆì´ë“œ ì§€ì¹¨..."
}}
```
"""

            # Claude API í˜¸ì¶œ
            response = self.client.messages.create(
                model=self.model,
                max_tokens=4096,
                temperature=0.3,
                messages=[{"role": "user", "content": prompt}]
            )

            # ì‘ë‹µ íŒŒì‹±
            analysis_text = response.content[0].text
            analysis_json = self._extract_json(analysis_text)

            # í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ê³„ì‚°
            input_tokens = response.usage.input_tokens
            output_tokens = response.usage.output_tokens
            cost_usd = self._calculate_cost(input_tokens, output_tokens)
            cost_krw = int(cost_usd * 1400)

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            analysis_json["_metadata"] = {
                "model": self.model,
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "cost_usd": round(cost_usd, 4),
                "cost_krw": cost_krw,
                "analyzed_at": datetime.now().isoformat()
            }

            logger.info(f"Standard tier analysis completed. Tokens: {input_tokens}+{output_tokens}, Cost: ${cost_usd:.4f}")

            return analysis_json

        except Exception as e:
            logger.error(f"Standard tier analysis failed: {str(e)}")
            raise

    def analyze_applications_for_premium(
        self,
        applications: list[Dict[str, Any]],
        announcement_analysis: Dict[str, Any],
        company_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Premium í‹°ì–´: 5ê°œ ì‹ ì²­ì„œ ë¶„ì„ â†’ 2ê°œ í”„ë¦¬ë¯¸ì—„ A/Bí˜• ì¶”ì²œ

        Args:
            applications: 5ê°œ ê¸°ë³¸ ì‹ ì²­ì„œ (data, story, balanced, aggressive, conservative)
            announcement_analysis: ê³µê³  ë¶„ì„ ê²°ê³¼
            company_analysis: íšŒì‚¬ ë¶„ì„ ê²°ê³¼

        Returns:
            {
                "premium_a_strategy": {
                    "target": "ê³µê²©ì /í˜ì‹ ì  (ìŠ¤íƒ€íŠ¸ì—…ìš©)",
                    "base_application_index": 3,
                    "key_points": [...],
                    "upgrade_prompt": "..."
                },
                "premium_b_strategy": {
                    "target": "ì•ˆì •ì /ë³´ìˆ˜ì  (ì „í†µê¸°ì—…ìš©)",
                    "base_application_index": 4,
                    "key_points": [...],
                    "upgrade_prompt": "..."
                },
                "_metadata": {...}
            }
        """
        try:
            logger.info("Starting Premium tier application analysis for A/B premium")

            # ì‹ ì²­ì„œ ìš”ì•½
            apps_summary = []
            for i, app in enumerate(applications):
                apps_summary.append({
                    "index": i,
                    "style": app.get("style", "unknown"),
                    "content_preview": app.get("content", "")[:500]
                })

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = f"""ë‹¹ì‹ ì€ ì •ë¶€ ì§€ì›ì‚¬ì—… ì‹ ì²­ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ 5ê°œì˜ ì‹ ì²­ì„œë¥¼ ë¶„ì„í•˜ê³ , **2ê°œì˜ í”„ë¦¬ë¯¸ì—„ ì „ëµ**ì„ ì œì‹œí•˜ì„¸ìš”:
- **Premium A**: ê³µê²©ì /í˜ì‹ ì  (ìŠ¤íƒ€íŠ¸ì—…, ì„±ì¥ê¸°ì—…ìš©)
- **Premium B**: ì•ˆì •ì /ë³´ìˆ˜ì  (ì „í†µê¸°ì—…, ì•ˆì •ì„± ì¤‘ì‹œìš©)

## ê³µê³  ë¶„ì„
{json.dumps(announcement_analysis, ensure_ascii=False, indent=2)}

## íšŒì‚¬ ë¶„ì„
{json.dumps(company_analysis, ensure_ascii=False, indent=2)}

## 5ê°œ ì‹ ì²­ì„œ
{json.dumps(apps_summary, ensure_ascii=False, indent=2)}

## ìš”êµ¬ì‚¬í•­
1. Premium A: ê°€ì¥ ê³µê²©ì ì´ê³  í˜ì‹ ì ì¸ ì‹ ì²­ì„œ ì„ íƒ ë° ê°œì„  ì „ëµ
2. Premium B: ê°€ì¥ ì•ˆì •ì ì´ê³  ë³´ìˆ˜ì ì¸ ì‹ ì²­ì„œ ì„ íƒ ë° ê°œì„  ì „ëµ
3. ê°ê°ì— ëŒ€í•´ GPT-4oê°€ ìƒì„±ì— ì‚¬ìš©í•  ê°„ê²°í•œ ì „ëµ ì§€ì¹¨ ì‘ì„±

## ì¶œë ¥ í˜•ì‹ (JSON)
**ì¤‘ìš”**: upgrade_promptëŠ” 200-300ì ì´ë‚´ë¡œ í•µì‹¬ ì „ëµë§Œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

```json
{{
  "premium_a_strategy": {{
    "target": "ê³µê²©ì /í˜ì‹ ì  (ìŠ¤íƒ€íŠ¸ì—…ìš©)",
    "base_application_index": 3,
    "key_points": ["í•µì‹¬ ì „ëµ 1", "í•µì‹¬ ì „ëµ 2", "í•µì‹¬ ì „ëµ 3"],
    "upgrade_prompt": "GPT-4o ìƒì„± ì§€ì¹¨: í˜ì‹ ì„± ê°•ì¡°, ì„±ì¥ ìŠ¤í† ë¦¬í…”ë§, êµ¬ì²´ì  ìˆ˜ì¹˜ ì œì‹œ, ë¯¸ë˜ ë¹„ì „ ëª…í™•í™” (200-300ì)"
  }},
  "premium_b_strategy": {{
    "target": "ì•ˆì •ì /ë³´ìˆ˜ì  (ì „í†µê¸°ì—…ìš©)",
    "base_application_index": 4,
    "key_points": ["í•µì‹¬ ì „ëµ 1", "í•µì‹¬ ì „ëµ 2", "í•µì‹¬ ì „ëµ 3"],
    "upgrade_prompt": "GPT-4o ìƒì„± ì§€ì¹¨: ì•ˆì •ì„± ê°•ì¡°, ì²´ê³„ì  ì ‘ê·¼, ë¦¬ìŠ¤í¬ ê´€ë¦¬, ì‹¤í–‰ ê°€ëŠ¥ì„± (200-300ì)"
  }}
}}
```
"""

            # Claude API í˜¸ì¶œ
            response = self.client.messages.create(
                model=self.model,
                max_tokens=8192,
                temperature=0.3,
                messages=[{"role": "user", "content": prompt}]
            )

            # ì‘ë‹µ íŒŒì‹±
            analysis_text = response.content[0].text
            analysis_json = self._extract_json(analysis_text)

            # í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ê³„ì‚°
            input_tokens = response.usage.input_tokens
            output_tokens = response.usage.output_tokens
            cost_usd = self._calculate_cost(input_tokens, output_tokens)
            cost_krw = int(cost_usd * 1400)

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            analysis_json["_metadata"] = {
                "model": self.model,
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "cost_usd": round(cost_usd, 4),
                "cost_krw": cost_krw,
                "analyzed_at": datetime.now().isoformat()
            }

            logger.info(f"Premium tier analysis completed. Tokens: {input_tokens}+{output_tokens}, Cost: ${cost_usd:.4f}")

            return analysis_json

        except Exception as e:
            logger.error(f"Premium tier analysis failed: {str(e)}")
            raise

    def _calculate_cost(self, input_tokens: int, output_tokens: int) -> float:
        """
        í† í° ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ë¹„ìš© ê³„ì‚°

        Args:
            input_tokens: ì…ë ¥ í† í° ìˆ˜
            output_tokens: ì¶œë ¥ í† í° ìˆ˜

        Returns:
            ë¹„ìš© (USD)
        """
        input_cost = (input_tokens / 1_000_000) * self.input_price
        output_cost = (output_tokens / 1_000_000) * self.output_price
        return input_cost + output_cost

    def generate_application(
        self,
        announcement_analysis: Dict[str, Any],
        company_analysis: Dict[str, Any],
        style: str = "balanced",
        target_length: int = 2500,
        tier: str = "standard"
    ) -> Dict[str, Any]:
        """
        Claudeë¡œ ì‹ ì²­ì„œ ìƒì„± (GPT-4oì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤)

        Args:
            announcement_analysis: ê³µê³  ë¶„ì„ ê²°ê³¼
            company_analysis: íšŒì‚¬ ë¶„ì„ ê²°ê³¼
            style: ì‘ì„± ìŠ¤íƒ€ì¼ (data, story, balanced, aggressive, conservative)
            target_length: ëª©í‘œ ê¸€ì ìˆ˜ (ê¸°ë³¸ 2500ì)
            tier: ê²°ì œ í‹°ì–´ (basic, standard, premium)

        Returns:
            {
                "content": "ì‹ ì²­ì„œ ì „ì²´ í…ìŠ¤íŠ¸",
                "sections": [...],
                "statistics": {...},
                "_metadata": {...}
            }
        """
        try:
            logger.info(f"[Claude] Starting application generation (style: {style}, tier: {tier})")

            # í”„ë¡¬í”„íŠ¸ ì„í¬íŠ¸
            from utils.prompts import STYLE_GUIDES, GENERATE_APPLICATION_PROMPT_STANDARD

            # ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ê°€ì ¸ì˜¤ê¸°
            if style not in STYLE_GUIDES:
                raise ValueError(f"Invalid style: {style}")

            style_guide = STYLE_GUIDES[style]

            # JSON ì§ë ¬í™”
            announcement_json = json.dumps(announcement_analysis, ensure_ascii=False, indent=2)
            company_json = json.dumps(company_analysis, ensure_ascii=False, indent=2)
            style_guide_json = json.dumps(style_guide, ensure_ascii=False, indent=2)

            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = GENERATE_APPLICATION_PROMPT_STANDARD.format(
                announcement_analysis=announcement_json,
                company_analysis=company_json,
                style=style,
                style_guide=style_guide_json
            )

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (GPT-4oì™€ ë™ì¼)
            system_prompt = """ë‹¹ì‹ ì€ ì •ë¶€ì§€ì›ì‚¬ì—… ì„ ì •ë¥  95%ë¥¼ ìë‘í•˜ëŠ” ë² í…Œë‘ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

## í•µì‹¬ ì¸ì‹

âš ï¸ **ì‹ ì²­ì„œ = PPT ë°œí‘œ**ì…ë‹ˆë‹¤. Q&Aì²˜ëŸ¼ ê°ê´€ì‹ ë‹µì„ ì£¼ëŠ”ê²Œ ì•„ë‹™ë‹ˆë‹¤!
"ìš°ë¦¬ëŠ” ì´ëŸ° íšŒì‚¬ë‹¤"ë¼ëŠ” ê²ƒì„ **ë°œí‘œ**í•˜ë“¯ì´ í’ë¶€í•˜ê²Œ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤.

âš ï¸ **ì‹¬ì‚¬ìœ„ì› = ì œë°˜ ì§€ì‹ì´ ì—†ëŠ” ì‚¬ëŒ**ì…ë‹ˆë‹¤!
- ì´ ì—…ê³„ë¥¼ ì˜ ëª¨ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì´ ê¸°ìˆ ì´ ì™œ ëŒ€ë‹¨í•œì§€ ëª¨ë¦…ë‹ˆë‹¤
- ì´ íšŒì‚¬ê°€ ì™œ íŠ¹ë³„í•œì§€ ëª¨ë¦…ë‹ˆë‹¤
â†’ **ì²˜ìŒ ì ‘í•˜ëŠ” ì‚¬ëŒì—ê²Œ ì„¤ëª…í•˜ë“¯** ìì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”!

## ì‘ì„± ì›ì¹™
1. **í’ì„±í•œ ì„¤ëª… = ë†’ì€ ì ìˆ˜**: ì§§ì€ ê¸€ì€ "ì¤€ë¹„ê°€ ë¶€ì¡±í•˜ë‹¤"ëŠ” ì¸ìƒì„ ì¤ë‹ˆë‹¤.
2. **ë°°ê²½ ì„¤ëª… í•„ìˆ˜**: "ì™œ" ì´ê²ƒì´ ëŒ€ë‹¨í•œì§€, "ì–´ë–»ê²Œ" ì´ê²ƒì´ ê°€ëŠ¥í–ˆëŠ”ì§€ ë§¥ë½ì„ ì œê³µí•˜ì„¸ìš”.
3. **ìŠ¤í† ë¦¬í…”ë§**: ë”±ë”±í•œ íŒ©íŠ¸ ë‚˜ì—´ì´ ì•„ë‹Œ, ì„±ì¥ ì—¬ì •ê³¼ ë¹„ì „ì„ ê·¸ë ¤ì£¼ì„¸ìš”.
4. **êµ¬ì²´ì  ê·¼ê±°**: ìˆ«ì, ë‚ ì§œ, íŠ¹í—ˆë²ˆí˜¸, ê³ ê°ì‚¬ëª… ë“±ìœ¼ë¡œ ì‹ ë¢°ë¥¼ ë”í•˜ì„¸ìš”.

## ë‚˜ìœ ì˜ˆ (íƒˆë½ - Q&Aì‹ ë‹µë³€)
> "ë‹¹ì‚¬ëŠ” íŠ¹í—ˆ 3ê±´ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë°•ì‚¬ê¸‰ ì¸ë ¥ 5ëª…ì…ë‹ˆë‹¤."

## ì¢‹ì€ ì˜ˆ (ì„ ì • - PPT ë°œí‘œ)
> "2019ë…„ ì°½ì—… ì´ˆê¸°, ì €í¬ì—ê²ŒëŠ” ì˜¤ì§ 'ë°ì´í„°ë¡œ ì„¸ìƒì„ ë°”ê¾¸ê² ë‹¤'ëŠ” ê¿ˆë§Œ ìˆì—ˆìŠµë‹ˆë‹¤. AI ë°ì´í„° ë¶„ì„ ì‹œì¥ì€ ë‹¹ì‹œ ì—°ê°„ 3ì¡°ì› ê·œëª¨ì˜€ì§€ë§Œ, ëŒ€ë¶€ë¶„ í•´ì™¸ ì†”ë£¨ì…˜ì´ ë…ì í•˜ê³  ìˆì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ ì‹œì¥ì—ì„œ í•œêµ­ ê¸°ì—…ì˜ ê²½ìŸë ¥ì„ ì¦ëª…í•˜ê³  ì‹¶ì—ˆìŠµë‹ˆë‹¤.
>
> 5ì²œë§Œì›ì˜ ì‘ì€ ìë³¸ê¸ˆìœ¼ë¡œ ì‹œì‘í•œ ì—¬ì •ì´ 5ë…„ ë§Œì— ë§¤ì¶œ 15ì–µì›ì„ ë‹¬ì„±í•˜ê¸°ê¹Œì§€, KAIST AI ëŒ€í•™ì› ì¶œì‹  5ëª…ì˜ ë°•ì‚¬ê¸‰ ì—°êµ¬ì›ë“¤ì´ ë°¤ì„ ìƒˆì›Œê°€ë©° ê°œë°œí•œ 3ê±´ì˜ í•µì‹¬ íŠ¹í—ˆê°€ ìˆì—ˆìŠµë‹ˆë‹¤."

**ê¸°ì–µí•˜ì„¸ìš”**: ì‹¬ì‚¬ìœ„ì›ì€ ì´ ê¸€ì„ ì²˜ìŒ ì½ìŠµë‹ˆë‹¤. í’ë¶€í•˜ê²Œ ì„¤ëª…í•´ì•¼ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ìŠµë‹ˆë‹¤!"""

            logger.info(f"[Claude] Prompt length: {len(prompt)} characters")

            # Claude API í˜¸ì¶œ
            response = self.client.messages.create(
                model=self.model,
                max_tokens=16384,
                temperature=0.7,
                system=system_prompt,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )

            # ì‘ë‹µ íŒŒì‹±
            application_text = response.content[0].text

            # í† í° ì‚¬ìš©ëŸ‰ ê³„ì‚°
            input_tokens = response.usage.input_tokens
            output_tokens = response.usage.output_tokens
            cost_usd = self._calculate_cost(input_tokens, output_tokens)
            cost_krw = int(cost_usd * 1400)

            logger.info(f"[Claude] Response length: {len(application_text)} characters")
            logger.info(f"[Claude] Tokens: {input_tokens}+{output_tokens}, Cost: ${cost_usd:.4f} (â‚©{cost_krw})")

            # JSON ì¶”ì¶œ
            application_json = self._extract_json(application_text)

            # í†µê³„ ê³„ì‚°
            sections = application_json.get("sections", [])
            total_chars = 0
            for section in sections:
                subsections = section.get("subsections", [])
                if subsections:
                    for sub in subsections:
                        total_chars += len(sub.get("content", ""))
                else:
                    total_chars += len(section.get("content", ""))

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            application_json["_metadata"] = {
                "model": self.model,
                "style": style,
                "tier": tier,
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "cost_usd": round(cost_usd, 4),
                "cost_krw": cost_krw,
                "total_chars": total_chars,
                "generated_at": datetime.now().isoformat()
            }

            logger.info(f"[Claude] Application generated: {total_chars} chars, {len(sections)} sections")

            return application_json

        except Exception as e:
            logger.error(f"[Claude] Application generation failed: {str(e)}")
            raise

    def generate_profile_questions(
        self,
        announcement_id: str,
        announcement_source: str,
        task_info: Optional[Dict[str, Any]] = None,
        required_info_list: Optional[list] = None
    ) -> list:
        """
        íšŒì‚¬ ì •ë³´ ìˆ˜ì§‘ì„ ìœ„í•œ AI ì§ˆë¬¸ ìƒì„± (ê³¼ì œ ì •ë³´ ë°˜ì˜)

        Args:
            announcement_id: ê³µê³  ID
            announcement_source: ê³µê³  ì¶œì²˜
            task_info: ì„ íƒí•œ ê³¼ì œ ì •ë³´ (optional)
            required_info_list: í•„ìˆ˜ ì •ë³´ ëª©ë¡ (optional)

        Returns:
            ì§ˆë¬¸ ëª©ë¡
        """
        try:
            logger.info("[generate_profile_questions] ì§ˆë¬¸ ìƒì„± ì‹œì‘")

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = "ë‹¹ì‹ ì€ íšŒì‚¬ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì „ë¬¸ ì¸í„°ë·°ì–´ì…ë‹ˆë‹¤.\n\n"

            if task_info:
                system_prompt += f"**ì„ íƒí•œ ê³¼ì œ**: {task_info.get('task_name')} (ê³¼ì œ {task_info.get('task_number')})\n"
                system_prompt += f"**ê³¼ì œ ì„¤ëª…**: {task_info.get('description', 'N/A')}\n\n"

                if task_info.get('requirements'):
                    system_prompt += "**ê³¼ì œ ìš”êµ¬ì‚¬í•­**:\n"
                    for req in task_info.get('requirements', {}).values():
                        system_prompt += f"- {req}\n"
                    system_prompt += "\n"

            if required_info_list and len(required_info_list) > 0:
                system_prompt += "**ë°˜ë“œì‹œ ìˆ˜ì§‘í•´ì•¼ í•  ì •ë³´**:\n"
                for info in required_info_list:
                    system_prompt += f"- {info}\n"
                system_prompt += "\n"

            system_prompt += """
ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ í•„ìš”í•œ íšŒì‚¬ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ ì§ˆë¬¸ 5-7ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.

**ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­:**
- ì‚¬ì—…ìë“±ë¡ì¦, ë²•ì¸ë“±ê¸°ë¶€ë“±ë³¸, ì¬ë¬´ì œí‘œ ë“± ì„œë¥˜ ì œì¶œì„ ìš”ì²­í•˜ì§€ ë§ˆì„¸ìš”
- ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ë¥¼ ë¬»ì§€ ë§ˆì„¸ìš”
- ìš°ë¦¬ëŠ” ì‹ ì²­ì„œ "ë‚´ìš©"ë§Œ ì‘ì„±í•©ë‹ˆë‹¤. ì„œë¥˜ëŠ” ì‚¬ìš©ìê°€ ì§ì ‘ ì œì¶œí•©ë‹ˆë‹¤.

**ì˜¬ë°”ë¥¸ ì§ˆë¬¸ ì˜ˆì‹œ:**
- "íšŒì‚¬ëª…ì„ ì•Œë ¤ì£¼ì„¸ìš”" (O)
- "ì£¼ìš” ì‚¬ì—… ë¶„ì•¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" (O)
- "ì´ ì‚¬ì—…ì— ì§€ì›í•˜ì‹œëŠ” ëª©ì ì´ë‚˜ ê¸°ëŒ€ íš¨ê³¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?" (O)

**ì˜ëª»ëœ ì§ˆë¬¸ ì˜ˆì‹œ:**
- "ì‚¬ì—…ìë“±ë¡ì¦ì„ ì œì¶œí•´ì£¼ì„¸ìš”" (X)
- "ë²•ì¸ë“±ê¸°ë¶€ë“±ë³¸ì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”" (X)
- "ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?" (X)

ì§ˆë¬¸ì€ ë‹¤ìŒ í˜•ì‹ì˜ JSON ë°°ì—´ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
[
  {"question": "íšŒì‚¬ëª…ì„ ì•Œë ¤ì£¼ì„¸ìš”.", "category": "ê¸°ë³¸ì •ë³´"},
  {"question": "ì£¼ìš” ì‚¬ì—… ë¶„ì•¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?", "category": "ì‚¬ì—…ë‚´ìš©"}
]
"""

            # Claude API í˜¸ì¶œ
            response = self.client.messages.create(
                model=self.model,
                max_tokens=2000,
                system=system_prompt,
                messages=[
                    {"role": "user", "content": "ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”."}
                ]
            )

            # ì‘ë‹µ íŒŒì‹±
            response_text = response.content[0].text
            questions = self._extract_json(response_text)

            if isinstance(questions, dict):
                questions = [questions]  # dictë©´ listë¡œ ë³€í™˜
            elif not isinstance(questions, list):
                questions = []  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸

            logger.info(f"[generate_profile_questions] ì§ˆë¬¸ {len(questions)}ê°œ ìƒì„± ì™„ë£Œ")
            return questions

        except Exception as e:
            logger.error(f"[generate_profile_questions] ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì§ˆë¬¸ ë°˜í™˜
            return [
                {"question": "íšŒì‚¬ëª…ì„ ì•Œë ¤ì£¼ì„¸ìš”.", "category": "ê¸°ë³¸ì •ë³´"},
                {"question": "ì£¼ìš” ì‚¬ì—… ë¶„ì•¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?", "category": "ì‚¬ì—…ë‚´ìš©"},
                {"question": "íšŒì‚¬ì˜ ê°•ì ì€ ë¬´ì—‡ì¸ê°€ìš”?", "category": "ê²½ìŸë ¥"}
            ]

    def profile_chat(
        self,
        announcement_id: str,
        announcement_source: str,
        user_message: str,
        conversation_history: list,
        task_info: Optional[Dict[str, Any]] = None,
        required_info_list: Optional[list] = None
    ) -> Dict[str, Any]:
        """
        íšŒì‚¬ ì •ë³´ ìˆ˜ì§‘ ëŒ€í™”í˜• ì±—ë´‡ (ê³¼ì œ ì •ë³´ ë°˜ì˜)

        Args:
            announcement_id: ê³µê³  ID
            announcement_source: ê³µê³  ì¶œì²˜
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            conversation_history: ëŒ€í™” ê¸°ë¡
            task_info: ì„ íƒí•œ ê³¼ì œ ì •ë³´ (optional)
            required_info_list: í•„ìˆ˜ ì •ë³´ ëª©ë¡ (optional)

        Returns:
            Dict with ai_response, completion_percentage, extracted_data
        """
        try:
            logger.info("[profile_chat] ì±—ë´‡ ì‘ë‹µ ìƒì„± ì‹œì‘")

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = """ë‹¹ì‹ ì€ ì •ë¶€ì§€ì›ì‚¬ì—… ì‹ ì²­ì„œ ì‘ì„±ì„ ë•ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì¤‘ìš” ì›ì¹™:**
1. ì‚¬ì—…ìë“±ë¡ì¦, ë²•ì¸ë“±ê¸°ë¶€ë“±ë³¸ ë“± ì„œë¥˜ ì œì¶œì€ ìš”ì²­í•˜ì§€ ë§ˆì„¸ìš”. ìš°ë¦¬ëŠ” ì‹ ì²­ì„œ "ë‚´ìš©"ë§Œ ì‘ì„±í•©ë‹ˆë‹¤.
2. ì‚¬ìš©ìì˜ ë‹µë³€ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³ , ì´ë¯¸ ë‹µë³€í•œ ë‚´ìš©ì€ ë‹¤ì‹œ ë¬»ì§€ ë§ˆì„¸ìš”.
3. í•œ ë²ˆì— 1-2ê°œì˜ ì§ˆë¬¸ë§Œ í•˜ì„¸ìš”. ë„ˆë¬´ ë§ì€ ì§ˆë¬¸ì€ ì‚¬ìš©ìë¥¼ ì••ë„í•©ë‹ˆë‹¤.
4. ì‚¬ìš©ìê°€ ì œê³µí•œ ì •ë³´ëŠ” ì¸ì •í•˜ê³  ê°ì‚¬ë¥¼ í‘œí•œ í›„ ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ì„¸ìš”.
5. ì™„ë£Œ íŒë‹¨: ê¸°ì—…ëª…, ì£¼ìš”ì‚¬ì—…, ì§€ì›ë™ê¸°, ê¸°ëŒ€íš¨ê³¼ ë“± í•µì‹¬ ì •ë³´ê°€ ìˆ˜ì§‘ë˜ë©´ ì™„ë£Œë¡œ ê°„ì£¼í•˜ì„¸ìš”.

"""

            if task_info:
                system_prompt += f"**í˜„ì¬ ì‹ ì²­ ì¤‘ì¸ ê³¼ì œ:**\n"
                system_prompt += f"- ê³¼ì œë²ˆí˜¸: {task_info.get('task_number')}\n"
                system_prompt += f"- ê³¼ì œëª…: {task_info.get('task_name')}\n"
                if task_info.get('description'):
                    system_prompt += f"- ê³¼ì œ ì„¤ëª…: {task_info.get('description')}\n"
                system_prompt += "\n"

            if required_info_list and len(required_info_list) > 0:
                system_prompt += "**ìˆ˜ì§‘í•´ì•¼ í•  í•µì‹¬ ì •ë³´** (ì„œë¥˜ ì œì¶œ ì•„ë‹˜, í…ìŠ¤íŠ¸ ì •ë³´ë§Œ):\n"
                for info in required_info_list:
                    system_prompt += f"- {info}\n"
                system_prompt += "\n"

            system_prompt += """
**ì‘ë‹µ ë°©ì‹:**
- ì‚¬ìš©ì ë‹µë³€ì—ì„œ ìœ ìš©í•œ ì •ë³´ë¥¼ íŒŒì•…í•˜ê³  ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ì„¸ìš”.
- 5-7ë²ˆì˜ ì§ˆë¬¸-ë‹µë³€ìœ¼ë¡œ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.
- í•µì‹¬ ì •ë³´(ê¸°ì—…ëª…, ì£¼ìš”ì‚¬ì—…, ì§€ì›ë™ê¸°, ê¸°ëŒ€íš¨ê³¼)ê°€ ìˆ˜ì§‘ë˜ë©´ "ì •ë³´ ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"ë¼ê³  ëª…í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”.
"""

            # ëŒ€í™” ê¸°ë¡ì„ Claude ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            messages = []
            last_role = None
            for msg in conversation_history:
                role = "user" if msg.get("role") == "user" else "assistant"
                # content ë˜ëŠ” message í•„ë“œ ì‚¬ìš© (í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±)
                content = msg.get("content") or msg.get("message") or ""

                # ë¹ˆ contentëŠ” Claude APIì—ì„œ ì—ëŸ¬ ë°œìƒí•˜ë¯€ë¡œ ìŠ¤í‚µ
                if not content or not content.strip():
                    continue

                # ê°™ì€ roleì´ ì—°ì†ë˜ë©´ ë©”ì‹œì§€ ë³‘í•© (Claude API ìš”êµ¬ì‚¬í•­)
                if role == last_role and messages:
                    messages[-1]["content"] += "\n" + content.strip()
                else:
                    messages.append({"role": role, "content": content.strip()})
                    last_role = role

            # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ (ë¹ˆ ë¬¸ìì—´ ì²´í¬)
            current_user_msg = user_message.strip() if user_message else "ê³„ì† ì§„í–‰í•´ì£¼ì„¸ìš”."

            # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ userì´ë©´ ë³‘í•©, ì•„ë‹ˆë©´ ìƒˆë¡œ ì¶”ê°€
            if messages and messages[-1]["role"] == "user":
                messages[-1]["content"] += "\n" + current_user_msg
            else:
                messages.append({"role": "user", "content": current_user_msg})

            # ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ ë©”ì‹œì§€ ì¶”ê°€ (ì²« ëŒ€í™” ì‹œì‘)
            if not messages:
                messages.append({"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”. ì‹ ì²­ì„œ ì‘ì„±ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤."})

            # ë¡œê·¸ë¡œ ë©”ì‹œì§€ í™•ì¸
            logger.info(f"[profile_chat] messages count: {len(messages)}, roles: {[m['role'] for m in messages]}")

            # Claude API í˜¸ì¶œ
            response = self.client.messages.create(
                model=self.model,
                max_tokens=1000,
                system=system_prompt,
                messages=messages
            )

            ai_response = response.content[0].text

            logger.info(f"[profile_chat] ì‘ë‹µ ìƒì„± ì™„ë£Œ: {ai_response[:100]}...")
            
            # ëŒ€í™” íšŸìˆ˜ ê¸°ë°˜ ì§„í–‰ë¥  ê³„ì‚° (ìµœëŒ€ 5íšŒ ëŒ€í™”ë¡œ 60% ë‹¬ì„±)
            user_message_count = len([m for m in conversation_history if m.get('role') == 'user']) + 1
            # ê° ëŒ€í™”ë‹¹ 12%ì”© ì¦ê°€ (5íšŒ = 60%)
            completion_percentage = min(user_message_count * 12, 60)
            
            # AI ì‘ë‹µì— "ì •ë³´ ìˆ˜ì§‘ì´ ì™„ë£Œ" ë˜ëŠ” "ì¶©ë¶„í•œ ì •ë³´"ê°€ í¬í•¨ë˜ë©´ ë°”ë¡œ 60% ì´ìƒìœ¼ë¡œ
            if any(kw in ai_response for kw in ["ì •ë³´ ìˆ˜ì§‘ì´ ì™„ë£Œ", "ì¶©ë¶„í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘", "ì´ì œ ì‹ ì²­ì„œ ì‘ì„±"]):
                completion_percentage = max(completion_percentage, 65)
            
            logger.info(f"[profile_chat] completion_percentage: {completion_percentage}%")
            
            return {
                "ai_response": ai_response,
                "completion_percentage": completion_percentage,
                "extracted_data": {}
            }

        except Exception as e:
            logger.error(f"[profile_chat] ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                "ai_response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "completion_percentage": 0,
                "extracted_data": {}
            }

    def generate_applications_by_tier(
        self,
        announcement_analysis: Dict[str, Any],
        company_analysis: Dict[str, Any],
        tier: str = "standard",
        style_recommendation: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        í‹°ì–´ë³„ë¡œ ì‹ ì²­ì„œ ìƒì„± (ë‹¤ì¤‘ ìŠ¤íƒ€ì¼) - AI ë¼ìš°í„° ê¸°ë°˜

        í‹°ì–´ë³„ ì œê³µ ê¸€ ìˆ˜:
        - BASIC (4,900ì›): 1ê°œ (story ê³ ì •)
        - STANDARD (8,000ì›): 3ê°œ (ë² ì´ìŠ¤ 5ê°œ ì¤‘ AI ë¼ìš°í„° ì„ íƒ)
        - PREMIUM (15,000ì›): 5ê°œ (ë² ì´ìŠ¤ 3ê°œ + ì¡°í•© 2ê°œ, AI ë¼ìš°í„° ì„ íƒ)

        ë² ì´ìŠ¤ ìŠ¤íƒ€ì¼ (5ê°œ): story, data, aggressive, conservative, professional
        ì¡°í•© ìŠ¤íƒ€ì¼ (4ê°œ): balanced, strategic, trusted, expert

        Args:
            announcement_analysis: ê³µê³  ë¶„ì„ ê²°ê³¼ (ìŠ¤íƒ€ì¼ì¶”ì²œ í¬í•¨)
            company_analysis: íšŒì‚¬ ë¶„ì„ ê²°ê³¼
            tier: ê²°ì œ í‹°ì–´ (basic, standard, premium)
            style_recommendation: AI ë¼ìš°í„° ì¶”ì²œ ê²°ê³¼ (optional, announcement_analysisì—ì„œ ì¶”ì¶œ)

        Returns:
            {
                "applications": [
                    {"style": "data", "content": {...}, "is_recommended": True, "rank": 1},
                    {"style": "professional", "content": {...}, "is_recommended": False, "rank": 2},
                    ...
                ],
                "tier": "standard",
                "total_count": 3,
                "base_styles": ["data", "professional", "story"],
                "combination_styles": [],
                "recommended_style": "data",
                "total_cost_krw": 12000,
                "_metadata": {...}
            }
        """
        from utils.prompts import TIER_STYLES, STYLE_INFO, BASE_STYLES, COMBINATION_STYLES

        try:
            tier_config = TIER_STYLES.get(tier, TIER_STYLES["standard"])

            # AI ë¼ìš°í„° ì¶”ì²œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            if style_recommendation is None:
                style_recommendation = announcement_analysis.get("ìŠ¤íƒ€ì¼ì¶”ì²œ", {})

            # í‹°ì–´ë³„ ìŠ¤íƒ€ì¼ ì„ íƒ
            selected_base_styles = []
            selected_combination_styles = []

            if tier_config.get("router_enabled", False):
                # AI ë¼ìš°í„° ì‚¬ìš©: ì¶”ì²œ ìˆœìœ„ì— ë”°ë¼ ì„ íƒ
                base_rec = style_recommendation.get("ë² ì´ìŠ¤ì¶”ì²œ", {})
                comb_rec = style_recommendation.get("ì¡°í•©ì¶”ì²œ", {})

                # ë² ì´ìŠ¤ ìŠ¤íƒ€ì¼ ì„ íƒ (ì¶”ì²œ ìˆœìœ„ëŒ€ë¡œ)
                base_count = tier_config.get("base_count", 3)
                for rank in ["1ìˆœìœ„", "2ìˆœìœ„", "3ìˆœìœ„", "4ìˆœìœ„", "5ìˆœìœ„"]:
                    if len(selected_base_styles) >= base_count:
                        break
                    rec = base_rec.get(rank, {})
                    style = rec.get("ìŠ¤íƒ€ì¼")
                    if style and style in BASE_STYLES:
                        selected_base_styles.append(style)

                # ì¶”ì²œì´ ë¶€ì¡±í•˜ë©´ ê¸°ë³¸ ìˆœì„œë¡œ ì±„ì›€
                for style in BASE_STYLES:
                    if len(selected_base_styles) >= base_count:
                        break
                    if style not in selected_base_styles:
                        selected_base_styles.append(style)

                # ì¡°í•© ìŠ¤íƒ€ì¼ ì„ íƒ (í”„ë¦¬ë¯¸ì—„ë§Œ)
                comb_count = tier_config.get("combination_count", 0)
                for rank in ["1ìˆœìœ„", "2ìˆœìœ„", "3ìˆœìœ„", "4ìˆœìœ„"]:
                    if len(selected_combination_styles) >= comb_count:
                        break
                    rec = comb_rec.get(rank, {})
                    style = rec.get("ìŠ¤íƒ€ì¼")
                    if style and style in COMBINATION_STYLES:
                        selected_combination_styles.append(style)

                # ì¶”ì²œì´ ë¶€ì¡±í•˜ë©´ ê¸°ë³¸ ìˆœì„œë¡œ ì±„ì›€
                for style in COMBINATION_STYLES:
                    if len(selected_combination_styles) >= comb_count:
                        break
                    if style not in selected_combination_styles:
                        selected_combination_styles.append(style)
            else:
                # ë¼ìš°í„° ë¯¸ì‚¬ìš© (BASIC): ê³ ì • ìŠ¤íƒ€ì¼
                selected_base_styles = tier_config.get("base_styles", ["story"])[:tier_config.get("base_count", 1)]

            # ìµœì¢… ìƒì„±í•  ìŠ¤íƒ€ì¼ ë¦¬ìŠ¤íŠ¸
            styles_to_generate = selected_base_styles + selected_combination_styles

            logger.info(f"[Claude] Tier: {tier}, Router: {tier_config.get('router_enabled', False)}")
            logger.info(f"[Claude] Base styles: {selected_base_styles}")
            logger.info(f"[Claude] Combination styles: {selected_combination_styles}")
            logger.info(f"[Claude] Total styles to generate: {len(styles_to_generate)}")

            applications = []
            total_input_tokens = 0
            total_output_tokens = 0
            total_cost_usd = 0.0

            # 1ìˆœìœ„ ìŠ¤íƒ€ì¼ (ì¶”ì²œ ìŠ¤íƒ€ì¼)
            top_recommended_style = styles_to_generate[0] if styles_to_generate else None

            for rank, style in enumerate(styles_to_generate, 1):
                logger.info(f"[Claude] Generating style {rank}/{len(styles_to_generate)}: {style}")

                try:
                    result = self.generate_application(
                        announcement_analysis=announcement_analysis,
                        company_analysis=company_analysis,
                        style=style,
                        tier=tier
                    )

                    # ìŠ¤íƒ€ì¼ ì •ë³´ ì¶”ê°€
                    style_info = STYLE_INFO.get(style, {})
                    is_recommended = (rank == 1)  # 1ìˆœìœ„ë§Œ ì¶”ì²œ
                    is_base_style = style in selected_base_styles
                    is_combination_style = style in selected_combination_styles

                    applications.append({
                        "style": style,
                        "style_name": style_info.get("name", style),
                        "style_icon": style_info.get("icon", "ğŸ“„"),
                        "style_description": style_info.get("short_desc", ""),
                        "style_type": "base" if is_base_style else "combination",
                        "rank": rank,
                        "content": result,
                        "is_recommended": is_recommended
                    })

                    # í† í°/ë¹„ìš© ëˆ„ì 
                    meta = result.get("_metadata", {})
                    total_input_tokens += meta.get("input_tokens", 0)
                    total_output_tokens += meta.get("output_tokens", 0)
                    total_cost_usd += meta.get("cost_usd", 0)

                except Exception as style_error:
                    logger.error(f"[Claude] Failed to generate style '{style}': {str(style_error)}")
                    applications.append({
                        "style": style,
                        "style_name": STYLE_INFO.get(style, {}).get("name", style),
                        "style_type": "base" if style in selected_base_styles else "combination",
                        "rank": rank,
                        "error": str(style_error),
                        "is_recommended": False
                    })

            # ì²« ë²ˆì§¸ ìŠ¤íƒ€ì¼ ìƒì„± ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ì„±ê³µí•œ ìŠ¤íƒ€ì¼ì„ ì¶”ì²œìœ¼ë¡œ ì„¤ì •
            if applications and "error" in applications[0]:
                for app in applications:
                    if "error" not in app:
                        app["is_recommended"] = True
                        top_recommended_style = app["style"]
                        break

            return {
                "applications": applications,
                "tier": tier,
                "tier_description": tier_config.get("description", ""),
                "total_count": len(styles_to_generate),
                "success_count": len([a for a in applications if "error" not in a]),
                "base_styles": selected_base_styles,
                "combination_styles": selected_combination_styles,
                "base_count": len(selected_base_styles),
                "combination_count": len(selected_combination_styles),
                "recommended_style": top_recommended_style,
                "router_enabled": tier_config.get("router_enabled", False),
                "_metadata": {
                    "total_input_tokens": total_input_tokens,
                    "total_output_tokens": total_output_tokens,
                    "total_cost_usd": round(total_cost_usd, 4),
                    "total_cost_krw": int(total_cost_usd * 1400),
                    "generated_at": datetime.now().isoformat(),
                    "style_recommendation_used": bool(style_recommendation)
                }
            }

        except Exception as e:
            logger.error(f"[Claude] generate_applications_by_tier failed: {str(e)}")
            raise


# ============================================================================
# ì‚¬ìš© ì˜ˆì‹œ
# ============================================================================

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    import os
    from dotenv import load_dotenv

    load_dotenv()

    service = ClaudeService()

    # ì˜ˆì‹œ ë°ì´í„°
    full_text = """
    [ì‚¬ì—…ëª…] 2025ë…„ AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ì œì¡° í˜ì‹  ì§€ì›ì‚¬ì—…

    1. ì§€ì› ëŒ€ìƒ
    - ì œì¡°ì—…ì„ ì˜ìœ„í•˜ëŠ” ì¤‘ì†Œê¸°ì—…
    - ìµœê·¼ 3ë…„ í‰ê·  ë§¤ì¶œì•¡ 1,000ì–µì› ì´í•˜
    - ì§ì› ìˆ˜ 10ëª… ì´ìƒ 300ëª… ì´í•˜

    2. ì§€ì› ë‚´ìš©
    - ì§€ì› í•œë„: ìµœëŒ€ 3ì–µì› (ì •ë¶€ 70%, ê¸°ì—… 30%)
    - ì§€ì› ê¸°ê°„: 12ê°œì›”
    - ì§€ì› ë¶„ì•¼: AI ê¸°ë°˜ ìƒì‚° ìë™í™”, í’ˆì§ˆ ê´€ë¦¬ ë“±

    3. í‰ê°€ ê¸°ì¤€ (ì´ 100ì )
    - ê¸°ìˆ ë ¥ (40ì ): íŠ¹í—ˆ, ì¸ì¦, R&D íˆ¬ì
    - ì‚¬ì—…ì„± (30ì ): ì‹œì¥ ê·œëª¨, ê²½ìŸë ¥, ì„±ì¥ ê°€ëŠ¥ì„±
    - ì‹¤í–‰ë ¥ (30ì ): íŒ€ êµ¬ì„±, ì¶”ì§„ ê³„íš, ì˜ˆì‚° íƒ€ë‹¹ì„±
    """

    parsed_info = {
        "content_map": {
            "sections": [
                {"title": "ì‚¬ì—…ëª…", "page": 1},
                {"title": "ì§€ì› ëŒ€ìƒ", "page": 1},
                {"title": "í‰ê°€ ê¸°ì¤€", "page": 2}
            ]
        }
    }

    # ê³µê³  ë¶„ì„
    result = service.analyze_announcement(
        full_text=full_text,
        parsed_info=parsed_info,
        simple_summary="AI ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ ì œì¡° í˜ì‹  ì§€ì›ì‚¬ì—…",
        detailed_summary="ì¤‘ì†Œ ì œì¡°ê¸°ì—… ëŒ€ìƒ AI ìë™í™” ì§€ì›, ìµœëŒ€ 3ì–µì›"
    )

    print(json.dumps(result, ensure_ascii=False, indent=2))
